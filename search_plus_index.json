{"./":{"url":"./","title":"简介","keywords":"","body":"首页 个人的技术文档整理汇总 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-04 16:00:47 "},"category_0_Markdown_grammar.html":{"url":"category_0_Markdown_grammar.html","title":"Markdown语法","keywords":"","body":"字体加颜色 CSS样式解决 https://blog.csdn.net/heimu24/article/details/81189700 https://www.zhihu.com/question/22504694 https://blog.csdn.net/manjianchao/article/details/53668280 颜色,大小,字体   方法1: 我是黑体字 我是微软雅黑 我是华文彩云 我是红色 我是绿色 我是蓝色 我是尺寸 我是黑体，绿色，尺寸为5 浅红色文字：浅红色文字 深红色文字：深红色文字 浅绿色文字：浅绿色文字 深绿色文字：深绿色文字 浅蓝色文字：浅蓝色文字 深蓝色文字：深蓝色文字 浅黄色文字：浅黄色文字 深黄色文字：深黄色文字 浅青色文字：浅青色文字 深青色文字：深青色文字 浅紫色文字：浅紫色文字 深紫色文字：深紫色文字 方法2: 红色 加粗和斜体 **加粗** 加粗 *斜体* 斜体 添加换行符 https://www.zhihu.com/question/20134106 以下两个都有效 注意上下要空行, 否则会影响下一行内容的格式 &nbsp; 添加多个空格 注意上下要空行, 否则会影响下一行内容的格式 一个空格大小的表示 &ensp; &#8194 两个空格的大小表示 &emsp; &#8195; 不换行空格 &nbsp; &#160; 标记锚点 [显示文字](#标题) 上面的方法在我的环境并不能实现向下跳转以下是html代码的方式https://guo365.github.io/study/Markdown.html#41 * [目录1](#40) * [标题1](#41) * [标题2](#42) * [标题3](#43) * [标题4](#44) 标题1 轻轻的我走了， 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 标题2 正如我轻轻的来； 我轻轻的招手， 作别西天的云彩。 标题3 我轻轻的招手， 作别西天的云彩。 标题4 作别西天的云彩。 用html代码的方式标记标题, 并添加id, 则在\"目录\"里锚点标定这个id, 即可实现跳转 添加删除线 文字前后都加2个 ~ 号 ~~删除线示例~~ 删除线示例 添加表格 https://www.jianshu.com/p/2df05f279331https://www.runoob.com/markdown/md-table.html语法格式如下: | 一个普通标题 | 一个普通标题 | 一个普通标题 | | ------ | ------ | ------ | | 短文本 | 中等文本 | 稍微长一点的文本 | | 稍微长一点的文本 | 短文本 | 中等文本 | 效果如下: 一个普通标题 一个普通标题 一个普通标题 短文本 中等文本 稍微长一点的文本 稍微长一点的文本 短文本 中等文本 需要注意的是表头的上一行要有空格, 否则表格样式不生效   对齐方式 | 左对齐标题 | 右对齐标题 | 居中对齐标题 | | :------| ------: | :------: | | 短文本 | 中等文本 | 稍微长一点的文本 | | 稍微长一点的文本 | 短文本 | 中等文本 | 效果: 左对齐标题 右对齐标题 居中对齐标题 短文本 中等文本 稍微长一点的文本 稍微长一点的文本 短文本 中等文本   添加附件 https://www.cnblogs.com/yanh0606/p/10488356.html 附件1 效果如下: 附件1 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-08 10:17:21 "},"category_1_Programming.html":{"url":"category_1_Programming.html","title":"编程","keywords":"","body":"编程分类文章 编程分类文章的合集 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-12-28 10:38:52 "},"Programming_git_usage.html":{"url":"Programming_git_usage.html","title":"Git的使用","keywords":"","body":"官方文档https://docs.github.com/cn/free-pro-team@latest/github git for windowshttps://gitforwindows.org/ git的GUIhttps://desktop.github.com/ 手册和入门文章https://www.liaoxuefeng.com/wiki/896043488029600https://git-scm.com/book/zh/v2https://www.kancloud.cn/thinkphp/github-tips/37873http://github.phodal.com/https://blog.csdn.net/itmyhome1990/article/details/39579099   使用代理 https://gist.github.com/laispace/666dd7b27e9116faece6 git config --global https.proxy http://127.0.0.1:1080 git config --global https.proxy https://127.0.0.1:1080 git config --global --unset http.proxy git config --global --unset https.proxy 以上命令的结果写入文件Windows上的位置%userprofile%.gitconfig Linux上的位置~/.gitconfig 使用ssh的方式连接 使用http和https的连接方式,会有以下两种情况下面这个是在push过程中出现, 但通常并不影响操作结果. fatal: NotSupportedException encountered. ServicePointManager 不支持具有 socks5 方案的代理。 以下这种提示, 则是上传失败. fatal: The remote end hung up unexpectedly 如遇到以上两类提示, 其实都是该用ssh连接方式取代 https://blog.csdn.net/w410589502/article/details/53607691 操作步骤: 在server端页面添加客户端的证书key, 使用openssh的 ssh-keygen生成即可, 公钥xx.pub的内容粘贴添加到git页面上 server端去复制ssh地址, 客户端git操作连接的地址 git@服务器域名或IP:某级目录/仓库目录   自建git server Linux下的server端配置方法:https://www.jianshu.com/p/0f47fa1894e5https://www.liaoxuefeng.com/article/895923490127776 配置一个git专用的用户 配置该用户家目录下.ssh/authorized_keys, 使客户端可以ssh证书登录 使该用户对某级目录具有完全操作权限 git init --bare 某级目录/仓库目录 客户端可以首先使用 ssh -T 用户名@服务器域名或IP 来验证ssh证书登录是否成功 客户端git操作连接的地址 git@服务器域名或IP:某级目录/仓库目录 [root@docker git]# git init --bare dev Initialized empty Git repository in /docker/git/dev/ [root@docker git]# ll total 4.0K drwxr-xr-x 7 root root 4.0K Dec 27 12:47 dev [root@docker git]# ll dev/ total 32K drwxr-xr-x 2 root root 4.0K Dec 27 12:47 branches -rw-r--r-- 1 root root 66 Dec 27 12:47 config -rw-r--r-- 1 root root 73 Dec 27 12:47 description -rw-r--r-- 1 root root 23 Dec 27 12:47 HEAD drwxr-xr-x 2 root root 4.0K Dec 27 12:47 hooks drwxr-xr-x 2 root root 4.0K Dec 27 12:47 info drwxr-xr-x 4 root root 4.0K Dec 27 12:47 objects drwxr-xr-x 4 root root 4.0K Dec 27 12:47 refs D:\\Code\\private\\dev>git remote add local git@192.168.1.30:/docker/git/dev D:\\Code\\private\\dev>git remote -v git git@github.com:407474568/workplace.git (fetch) git git@github.com:407474568/workplace.git (push) gitee git@gitee.com:tanhuang1985/workplace.git (fetch) gitee git@gitee.com:tanhuang1985/workplace.git (push) local git@192.168.1.30:/docker/git/dev (fetch) local git@192.168.1.30:/docker/git/dev (push) D:\\Code\\private\\dev>git push local master _ _ | |__ ___ _ _ __| | __ _ _ _ | '_ \\ / _ \\ | | |/ _` |/ _` | | | | | | | | __/ |_| | (_| | (_| | |_| | |_| |_|\\___|\\__, |\\__,_|\\__,_|\\__, | |___/ |___/ Enumerating objects: 218, done. Counting objects: 100% (218/218), done. Delta compression using up to 16 threads Compressing objects: 100% (216/216), done. Writing objects: 100% (218/218), 49.86 KiB | 1.92 MiB/s, done. Total 218 (delta 121), reused 0 (delta 0), pack-reused 0 To 192.168.1.30:/docker/git/dev * [new branch] master -> master   非git删除文件后的恢复 https://my.oschina.net/u/2000675/blog/3126116https://www.iteye.com/blog/hbiao68-2213238 如通过操作系统而不是git rm删除文件, 在没有commit前的恢复很容易此时git status 可以看见被删除的文件已被列出通过 git reset HEAD 或 git reset HEAD . 来使指针指回到删除前的状态测试是删除的多个文件, 所以使用 . 号当前位置来进行指代同理, checkout 也是使用的 . 号接下来git push 一次即可从server端重新拉取被删除的文件 D:\\临时存储\\dev>git status On branch master Changes not staged for commit: (use \"git add/rm ...\" to update what will be committed) (use \"git restore ...\" to discard changes in working directory) deleted: wx.FlexGridSizer.py deleted: wx.GridBagSizer.py deleted: wx.GridBagSizer2.py deleted: wx.cashier_report.py deleted: wx.interface_switch.py deleted: wx.led_clock.py deleted: wx.license_plate_number_header_choice.py deleted: wx.license_plate_number_query.py deleted: wx.media_player.py no changes added to commit (use \"git add\" and/or \"git commit -a\") D:\\临时存储\\dev>git reset HEAD Unstaged changes after reset: D wx.FlexGridSizer.py D wx.GridBagSizer.py D wx.GridBagSizer2.py D wx.cashier_report.py D wx.interface_switch.py D wx.led_clock.py D wx.license_plate_number_header_choice.py D wx.license_plate_number_query.py D wx.media_player.py D:\\临时存储\\dev>git reset HEAD . Unstaged changes after reset: D wx.FlexGridSizer.py D wx.GridBagSizer.py D wx.GridBagSizer2.py D wx.cashier_report.py D wx.interface_switch.py D wx.led_clock.py D wx.license_plate_number_header_choice.py D wx.license_plate_number_query.py D wx.media_player.py D:\\临时存储\\dev>git checkout . Updated 9 paths from the index D:\\临时存储\\dev>git pull git-local master _ _ | |__ ___ _ _ __| | __ _ _ _ | '_ \\ / _ \\ | | |/ _` |/ _` | | | | | | | | __/ |_| | (_| | (_| | |_| | |_| |_|\\___|\\__, |\\__,_|\\__,_|\\__, | |___/ |___/ From 192.168.1.30:/docker/git/dev * branch master -> FETCH_HEAD Already up to date.   删除了文件, 并且错误的commit的情况下的恢复 待补充 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-18 11:04:30 "},"Programming_cmd_expirence_smmary.html":{"url":"Programming_cmd_expirence_smmary.html","title":"CMD经验汇总","keywords":"","body":"逻辑判断 http://beikeit.com/post-333.html 1、判断驱动器、文件或文件夹是否存在，用 if exist 语句；2、判断某两个字符串是否相等，用 if \"字符串1\"==\"字符串2\" 语句；3、判断某两个数值是否相等，用 if 数值1 equ 数值2 语句；4、判断某个变量是否已经被赋值，用 if defined str 语句； if语句的完整格式是这样的： if 条件表达式 (语句1) else (语句2) 它的含义是：如果条件表达式成立，那么，就执行语句1，否则，将执行语句2。 对于以上四种情形，可以分别使用如下代码： if exist d:\\test.txt (echo D盘下有test.txt存在) else (echo D盘下不存在test.txt) if \"abc\"==\"xyz\" (echo 字符串abc等于字符串xyz) else (echo 字符串abc不等于字符串xyz) if 1 equ 2 (echo 1等于2) else (echo 1不等于2) if defined str (echo 变量str已经被赋值，其值为%str%) else (echo 变量str的值为空) 判断字符串是否相等的时候，if会区分大小写，比如，单纯的if语句会认为字符串abc和字符串Abc不相同，若不想区分大小写，则需要添加 /i 开关，使用 if /i \"字符串1\"==\"字符串2\" 的格式；另外，等于符号是连续的\"==\"而非单独的\"=\"。 判断两个数值之间的大小关系，除了等于用equ之外，还有其他的关系符号，所有适用于if语句的关系符号见下表： 中文含义 关系符 英文解释 等于 equ equal 大于 gtr greater than 大于或等于 geq greater than or equal 小于 lss less than 小于或等于 leq less than or equal 不等于 neq no equal if语句还有一个精简格式：if 条件表达式 语句，它的含义是：如果条件表达式成立，将执行语句，否则，什么也不做 变量赋值 http://blog.csdn.net/wuqinfei_cs/article/details/9331869 参看set /?的帮助即可 在 SET 命令中添加了两个新命令行开关: SET /A expression SET /P variable=[promptString] /A 命令行开关指定等号右边的字符串为被评估的数字表达式。/P 命令行开关允许将变量数值设成用户输入的一行输入。读取输入行之前，显示指定的 promptString。promptString 可以是空的。 if语句中执行多条命令 在if语句的那一行后打左括号，后面换行来分割多条命令 cmd输出空行与后台执行 后台执行start /b采用此方式，cmd窗口可继续执行其他命令，同时有回显的会显示出来，但cmd窗口关闭后，程序会终止 echo输出空行http://www.jb51.net/article/30987.htm用echo输出空行至少有十种方法： echo= echo, echo; echo+ echo/ echo[ echo] echo: echo. echo\\ pause 这十种方法可以分为三组，每组的效率依次递减 cmd计算时间差 http://conducer.blog.51cto.com/841262/1377650 @echo off set a=%time% echo. echo 开始时间：%a% rem ===============插入代码段或调用脚本==================== ping -n 3 127.0.0.1 rem ===============插入代码段或调用脚本==================== set b=%time% echo. echo 结束时间：%b% echo. set /a h1=%a:~0,2% set /a m1=1%a:~3,2%-100 set /a s1=1%a:~6,2%-100 set /a h2=%b:~0,2% set /a m2=1%b:~3,2%-100 set /a s2=1%b:~6,2%-100 if %h2% LSS %h1% set /a h2=%h2%+24 set /a ts1=%h1%*3600+%m1%*60+%s1% set /a ts2=%h2%*3600+%m2%*60+%s2% set /a ts=%ts2%-%ts1% set /a h=%ts%/3600 set /a m=(%ts%-%h%*3600)/60 set /a s=%ts%%%60 echo 耗时%h%小时%m%分%s%秒 pause >nul exit Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-08 10:17:21 "},"Programming_Shell_expirence_smmary.html":{"url":"Programming_Shell_expirence_smmary.html","title":"Shell经验汇总","keywords":"","body":"导航 目录 杂项 Shell正则 Shell里的细节 Shell比较运算符 Shell输出的格式控制 杂项 动态变量 https://www.cnblogs.com/bugutian/p/12030428.htmlhttps://blog.csdn.net/qinyushuang/article/details/44115531用到eval, 来将变量获得的字符串(变量名称), 作为运算对象实例 for item_name in Manufacturer Product_Name Version Serial_Number UUID SKU_Number Family do tmp=$(eval echo '$'${item_name}) printf \"| %-14s | %-60s |\\n\" \"$item_name\" \"${tmp}\" done printf \" %s \\n\" \"${table_header}\" tmp变量 的取值是 \"Manufacturer Product_Name ...\"中的一个那么echo '$'${item_name}的输出就是形如$Manufacturer再通过eval 命令将其当作运算对象执行, 就可以得到相应变量存储的值需要注意的是, eval 这种命令也有存在SQL注入漏洞的不当使用的风险, 需要限制其的运行条件 Shell正则 关于正则表达式分组及后向引用 http://wiki.jikexueyuan.com/project/unix/regular-expressions.htmlhttp://www.cnblogs.com/jcli/p/4088514.htmlhttp://kodango.com/sed-and-awk-notes-part-3 字符 描述 ^ 匹配一行的起始 $ 匹配一行的结尾 . 匹配任何的单个字符 * 匹配零个或多个以前出现的字符 [chars] 为了匹配任何字符串的字符。您可以使用-字符来表示字符的范围。 表达式 描述 /a.c/ 匹配包含字符串如a+c，a-c，abc, match, 还有 a3c /a*c/ 匹配相同的字符串还有字符串比如ace，yacc，以及arctic /[tT]he/ 匹配字符The和the /^$/ 匹配空白行 /^.*$/ 不管任何情况，都匹配一整行 / */ 匹配一个或多个空格 /^$/ 匹配空行 集 描述 [a-z] 匹配一个小写字母 [A-Z] 匹配一个大写字母 [a-zA-Z] 匹配一个字母 [0-9] 匹配数字 [a-zA-Z0-9] 匹配单个字母或数字 一个实例:为了取/etc/redhat-release中的版本号,在描述数字0-9出现的次数 {1} ,花括号和小括号需要用到转义符 awk来实现正则表达式取不匹配grep -v 在多个关键字时总不太灵光awk可以这样用awk '!/关键字1 | 关键字2/{print}'! 一定要配合单引号'',否则报错 sed正则表达式匹配,各种括号的转义和不转义http://blog.csdn.net/zl87758539/article/details/77481679[ ] 需要匹配的时候，需要转义(这个是叛徒) echo \"[ ]\"|sed 's/\\[.*\\]/aaa/g' ( ) 需要匹配的时候，不要转义   $echo \"( )\"|sed 's/( )/c/g' { } 需要匹配的时候，不要转义   $echo \"{ }\"|sed 's/{ }/c/g' 当需要匹配数字，字母等使用中括号时候：不要转义但使用大括号作为特殊字符时候，需要转义。 $echo \"333\"|sed 's/[0-9]\\{3\\}/ccc/g' 当需要适配符，需要使用\\1来替换正则表达式的对应参数时： 不能写(regrexxxx) 要写(regrexxxx) $echo \"{1234567}\"|sed 's/{([0-9])}/\\1/g' 与此对应的还有 +和 在做为特别字符时候+必须转义为+1才有效，而*则不需要。 举个例子： echo \"ccc\"| sed 's/c*/aaa/g' #正确 echo \"ccc\"| sed 's/c\\*/aaa/g' #错误 echo \"ccc\"| sed 's/c+/aaa/g' #错误 echo \"ccc\"| sed 's/c\\+/aaa/g' #正确 grep中正则表达式的细节 在grep和sed中，\\t和\\s都是无效的，要表示制表符和空格，只能直接敲入tab和空格键，这个在shell脚本中还好说，在命令行模式下就比较麻烦了，因为tab默认是会智能补全命令的，所以要在按tab之前按下ctrl+v ，就可以把tab打出来了。 egrep和grep -E是等效的，egrep相比grep对正则表达式有了一些扩展支持，具体包括一下几点（其实这些特性grep是可以用的，只不过要在元字符前面加上转义符，比如用到+时，应敲入+）：+：匹配一个或多个先前的字符。如：’[a-z]+able’，匹配一个或多个小写字母后跟able的串，如loveable,enable,disable等。?：匹配零个或多个先前的字符。如：’gr?p’匹配gr后跟一个或没有字符，然后是p的行。a|b|c :匹配a或b或c。如：grep|sed匹配grep或sed():分组符号，如：love(able|rs)ov+匹配loveable或lovers，匹配一个或多个v。x{m},x{m,},x{m,n}:作用同x{m},x{m,},x{m,n} grep还支持一些POSIX字符类，也一并记录如下吧，虽然平时应该不大可能用到： POSIX字符 含义 [:alnum:] 文字数字字符 [:alpha:] 文字字符 [:digit:] 数字字符 [:graph:] 非空字符（非空格、控制字符） [:lower:] 小写字符 [:cntrl:] 控制字符 [:print:] 非空字符（包括空格） [:punct:] 标点符号 [:space:] 所有空白字符（新行，空格，制表符） [:upper:] 大写字符 [:xdigit:] 十六进制数字（0-9，a-f，A-F） 回到页首 Shell里的细节 http://blog.csdn.net/yorkingalan/article/details/7055518http://mprc.pku.edu.cn/mentors/training/TrainingCourses/material/ShellProgramming.HTMhttp://lq2419.blog.51cto.com/1365130/1238880 调试执行bash -x 脚本名 xargs引用管道前的结果 find . -name \"*\" | xargs -i cp {} /home/users/ 在shell脚本中导入外部函数https://blog.csdn.net/xiemeikj/article/details/5521067 . scripts_name source scripts_name 以上两种方式都能调用在其他脚本中定义的函数 shell脚本获取自身所在路径和名字https://xvcat.com/post/1096https://aimuke.github.io/linux/2019/04/29/how-to-get-abusolute-path/ $(cd `dirname $0`; pwd)/$0 命令执行结果赋值给变量形如： head -c 100 /dev/urandom | tr -dc A-Z | head -c 4 生成4个随机大写字母，结果想赋值给变量，在shell中如何表示？ $(head -c 100 /dev/urandom | tr -dc A-Z | head -c 4) shell四则运算http://www.cnblogs.com/chengmo/archive/2010/09/30/1839556.html做除法用存变量的形式还是比较好使 var=$(echo \"$numerator/$denominator\"|bc) shell去重的几种方法 使用uniq/sort删除重复行注意：单纯uniq是不行的。sort -k2n file | uniq > a.out当file中的重复行不再一起的时候，uniq没法删除所有的重复行。经过排序后，所有相同的行都在相邻，因此uniq可以正常删除重复行。 使用用sort+awk命令注意：单纯awk同样不行，原因同上。sort -k2n file | awk '{if ($0!=line) print;line=$0}'也可以使用 awk '!i[$1]++' log; 用sort+sed命令，同样需要sort命令先排序。sort -k2n file | sed '$!N; /^(.*)\\n\\1$/!P; D' if条件判断之组合判断（与、或、非）https://blog.51cto.com/dngood/675325在使用与 或 非条件判断时出现[: : integer expression expected并且-a -o 的写法与中括号 [ ] 里面的格式都正确时解决办法: 所有字符 与逻辑运算符直接用“空格”分开，不能连到一起。 [[]] 运算符只是[]运算符的扩充。能够支持符号运算不需要转义符，它还是以字符串比较大小。里面支持逻辑运算符：|| && http://wuyelan.blog.51cto.com/6118147/1530277组合条件测试是指可以将多个条件组合起来进行判断，条件和条件之间有逻辑关系。例如判断一个数是否大于3，并且小于9，这里大于3是一个条件，小于9也是一个条件，这两个条件必须同时满足。同时满足即为逻辑关系。通常逻辑关系有以下几种：与：-a，当指定多个条件时，默认为与关系或：-o非：!，这是个单目操作符 示例 #!/bin/bash if [ $1 ==\"memory\" -o $1 == \"Memory\" ]; then #### 这里不再使用模式匹配了，而采用-o或关系来进行组合条件判断 free -m else cat /proc/uptime fi 上面的逻辑关系，是针对条件组合的情况，两个或多个命令的运行结果也可以组合判断，其逻辑关系有如下几种：&&: 与||：或!: 非 重定向1>/dev/null 2>&1 含义http://blog.csdn.net/ithomer/article/details/9288353 /dev/null ：代表空设备文件 > ：代表重定向到哪里，例如：echo \"123\" > /home/123.txt 1 ：表示stdout标准输出，系统默认值是1，所以\">/dev/null\"等同于\"1>/dev/null\" 2 ：表示stderr标准错误 & ：表示等同于的意思，2>&1，表示2的输出重定向等同于1 1 > /dev/null 2>&1 语句含义：1 > /dev/null 首先表示标准输出重定向到空设备文件，也就是不输出任何信息到终端，说白了就是不显示任何信息。2>&1 接着，标准错误输出重定向（等同于）标准输出，因为之前标准输出已经重定向到了空设备文件，所以标准错误输出也重定向到空设备文件。 cmd >a 2>a 和 cmd >a 2>&1 为什么不同？cmd >a 2>a ：stdout和stderr都直接送往文件 a ，a文件会被打开两遍，由此导致stdout和stderr互相覆盖。cmd >a 2>&1 ：stdout直接送往文件a ，stderr是继承了FD1的管道之后，再被送往文件a 。a文件只被打开一遍，就是FD1将其打开。 Linux下批量复制文件到多个文件夹http://blog.sina.com.cn/s/blog_45e860c10100ni1a.htmlmkdir建以1,2,3,4,5个文件夹名把所有ini后缀的文件拷贝到12345文件夹得集合F中,命令如下 for F in 1 2 3 4 5 ;do cp *.ini $F ;done 想要每步骤都显示出来,在cp后面加上-vf for F in 1 2 3 4 5;do cp -vf *.ini $F ;done 正则表达式的标签分组，后向引用的细节 http://wiki.jikexueyuan.com/project/unix/regular-expressions.html对字符串分组拆分，并后向的引用，用一对小括号 () 来划分一个分组notepad++的实现： Shell中的实现（难点在于转移符 \\ 的使用，分组标签 () 要用 \\ 转义，以及出现次数 {} 也要用 \\ 转移，）： Shell里单双括号运算的解释单括号运算符号： a=$(date) 等同于 a=`date` 双括号运算符: a=$((1+2)) 等同于： a=`expr 1 + 2` 指定范围的随机数生成获取F范围【1-F】内的随机数echo $((RANDOM%F+1)) 例：获取50范围【1-50】的随机数 echo $((RANDOM%50+1)) grep -q 用于if 逻辑判断-q 参数，本意是 Quiet; do not write anything to standard output. Exit immediately with zero status if any match is found, even if an error was detected. 中文意思为，安静模式，不打印任何标准输出。如果有匹配的内容则立即返回状态值0。 例： #### cat a.txt nihao nihaooo hello #### if grep -q hello a.txt ; then echo yes;else echo no; fi yes #### if grep -q word a.txt; then echo yes; else echo no; fi no grep通过以下参数控制上下文grep -C 5 foo file 显示file文件中匹配foo字串那行以及上下5行grep -B 5 foo file 显示foo及前5行grep -A 5 foo file 显示foo及后5行 对时间的计算date +%s -d '各种时间格式'将给定的时间格式转换成时间戳 时间加减这里处理方法，是将基础的时间转变为时间戳，然后，需要增加或者改变时间，变成 秒。 如：1990-01-01 01:01:01 加上 1小时 20分处理步骤：将基础时间转为时间戳 time1=$(date +%s -d '1990-01-01 01:01:01') echo $time1 631126861 【时间戳】 将增加时间变成秒 [root@localhost ~]#### time2=$((1*60*60+20*60)) [root@localhost ~]#### echo $time2 4800 两个时间相加，计算出结果时间 time1=$(($time1+$time2)) time1=$(date +%Y-%m-%d\\ %H:%M:%S -d \"1970-01-01 UTC $time1 seconds\"); echo $time1 1990-01-01 02:21:01 时间差计算方法 如：2010-01-01 与 2009-01-01 11:11:11 时间差原理：同样转成时间戳，然后计算天，时，分，秒 time1=$(($(date +%s -d '2010-01-01') - $(date +%s -d '2009-01-01 11:11:11'))); echo time1 将time1 / 60 秒，就变成分了。 时间戳反转年月日时分秒 date -d @时间戳 \"+%Y-%m-%d %T\" break和continue的准确用法http://c.biancheng.net/cpp/view/7010.html 比较运算http://blog.csdn.net/yf210yf/article/details/92071471.整数比较 -eq 等于,如:if [ \"$a\" -eq \"$b\" ] -ne 不等于,如:if [ \"$a\" -ne \"$b\" ] -gt 大于,如:if [ \"$a\" -gt \"$b\" ] -ge 大于等于,如:if [ \"$a\" -ge \"$b\" ] -lt 小于,如:if [ \"$a\" -lt \"$b\" ] -le 小于等于,如:if [ \"$a\" -le \"$b\" ] 大于(需要双括号),如:((\"$a\" > \"$b\")) >= 大于等于(需要双括号),如:((\"$a\" >= \"$b\")) 小数比较使用AWK 2.字符串比较= 等于,如:if [ \"$a\" = \"$b\" ]== 等于,如:if [ \"$a\" == \"$b\" ],与=等价 注意, 比较两个字符串是否相等的办法是：if [ \"$test\"x = \"test\"x ]; then这里的关键有几点：1 使用单个等号2 注意到等号两边各有一个空格：这是unix shell的要求3 注意到\"$test\"x最后的x，这是特意安排的，因为当$test为空的时候，上面的表达式就变成了x = testx，显然是不相等的。而如果没有这个x，表达式就会报错：[: =: unary operator expected 注意:==的功能在[[]]和[]中的行为是不同的,如下:[[ $a == z ]] #### 如果$a以\"z\"开头(模式匹配)那么将为true[[ $a == \"z\" ]] #### 如果$a等于z*(字符匹配),那么结果为true [ $a == z ] #### File globbing 和word splitting将会发生[ \"$a\" == \"z\" ] #### 如果$a等于z*(字符匹配),那么结果为true 获取字符串变量的一部分echo ${variable:x:y}x - 起始位置y - 长度例子: 在shell中计算浮点数的处理bash 不支持浮点运算，如果需要进行浮点运算，需要借助bc,awk 处理1、借助bc处理示例：计算5.01-4*2.0，得到的结果为-2.99 $ c=$(echo \"5.01-4*2.0\"|bc) $ echo $c 2、借助awk处理示例：计算7.01*5-4.01，得到的结果为31.05 $ c=$(awk 'BEGIN{print 7.01*5-4.01 }') $ echo $c 注：在shell 中$() 与 ``等效。 中间包含命令语句执行，返回执行结果。 在shell中创建字典 declare -A dic dic=([cms]=\"192.168.0.2\" [api]=\"192.168.0.3\" [web]=\"192.168.0.4\") http://blog.csdn.net/jeremy_yangt/article/details/49100773 #必须先声明 declare -A dic dic=([key1]=\"value1\" [key2]=\"value2\" [key3]=\"value3\") #打印指定key的value echo ${dic[\"key1\"]} #打印所有key值 echo ${!dic[*]} #打印所有value echo ${dic[*]} #遍历key值 for key in $(echo ${!dic[*]}) do echo \"$key : ${dic[$key]}\" done echo \"shell定义数组\" #数组 list=(\"value1\" \"value2\" \"value3\") #打印指定下标 echo ${list[1]} #打印所有下标 echo ${!list[*]} #打印数组下标 echo ${list[*]} #数组增加一个元素 list=(\"${list[@]}\" \"value3\") for循环遇到空格切分换行的问题解决https://blog.csdn.net/m0_37549859/article/details/78238062重定义换行符可以解决, shell的内置变量$IFS OLDIFS=$IFS IFS=$'\\n' 中间代码块 IFS=$OLDIFS for ... in ...和 while read ...之间的区别http://blog.itpub.net/22664653/viewspace-1175858/真正导致for ... in ... 和while read ...区别在于shell中变量存储多行数据的形式在shell中输入多行变量,换行符并没有以\\n形式存储,虽然显示的是多行,但实际上数据还是一行.如果你在变量中输入换行符\\n,那么echo要能使换行符起作用,则需要使用-e参数,否则还是\\n文本形式.所以 while read ...一次性读完了他演示的例子的数据,因为本来就只有一行而 for ... in ... 之所以进行了换行,那是因为遇到空格进行的切分的图示说明 所以,结论就是,如果读文件,for...in...和while read ...并没有什么区别.变量存储就会有区别.简单就是最好的原则,尽量从文件中读取. shell中处理换行符\\n在文本解析中,需要替换换行符的场景比较常见但非贪婪模式,如 .*? 在sed中并不好使 受下面帖子的启发http://blog.xg98.com/article.asp?id=549http://bbs.chinaunix.net/thread-3745188-1-1.htmlhttps://segmentfault.com/q/1010000002416121 总结目前一个可行的流程 1) tr命令 对\\n做无脑替换,需注意tr是1对1替换,举例 tr 'abc' '123' ,那么它执行的是a变1,b变2,c变32) sed 去找标志位,在标志位后加一些原文本绝不会出现的词组----是为第3步作准备3) awk 利用它的输入 / 输出 行 / 列符重定义的功能,将第2步加的词组作为行结束标志,替换回\\n,因为是额外添加的,则这些是可以牺牲的,在awk作行分割时被替换掉也不会影响原文. 回到页首 Shell比较运算符 https://blog.csdn.net/ithomer/article/details/6836382 常用的运算符 运算符 描述 示例 文件比较运算符 -e filename 如果 filename 存在，则为真 [ -e /var/log/syslog ] -d filename 如果 filename 为目录，则为真 [ -d /tmp/mydir ] -f filename 如果 filename 为常规文件，则为真 [ -f /usr/bin/grep ] -L filename 如果 filename 为符号链接，则为真 [ -L /usr/bin/grep ] -r filename 如果 filename 可读，则为真 [ -r /var/log/syslog ] -w filename 如果 filename 可写，则为真 [ -w /var/mytmp.txt ] -x filename 如果 filename 可执行，则为真 [ -L /usr/bin/grep ] filename1 -nt filename2 如果 filename1 比 filename2 新，则为真 [ /tmp/install/etc/services -nt /etc/services ] filename1 -ot filename2 如果 filename1 比 filename2 旧，则为真 [ /boot/bzImage -ot arch/i386/boot/bzImage ] 字符串比较运算符 （请注意引号的使用，这是防止空格扰乱代码的好方法） -z string 如果 string 长度为零，则为真 [ -z \"$myvar\" ] -n string 如果 string 长度非零，则为真 [ -n \"$myvar\" ] string1 = string2 如果 string1 与 string2 相同，则为真 [ \"$myvar\" = \"one two three\" ] string1 != string2 如果 string1 与 string2 不同，则为真 [ \"$myvar\" != \"one two three\" ] 算术比较运算符 num1 -eq num2 等于 [ 3 -eq $mynum ] num1 -ne num2 不等于 [ 3 -ne $mynum ] num1 -lt num2 小于 [ 3 -lt $mynum ] num1 -le num2 小于或等于 [ 3 -le $mynum ] num1 -gt num2 大于 [ 3 -gt $mynum ] num1 -ge num2 大于或等于 [ 3 -ge $mynum ] 回到页首 Shell输出的格式控制 颜色、闪烁等 #!/bin/bash #### #下面是字体输出颜色及终端格式控制 #字体色30-37 echo -e \"\\033[30m黑色字\\033[0m\" echo -e \"\\033[31m红色字\\033[0m\" echo -e \"\\033[32m绿色字\\033[0m\" echo -e \"\\033[33m黄色字\\033[0m\" echo -e \"\\033[34m蓝色字\\033[0m\" echo -e \"\\033[35m紫色字\\033[0m\" echo -e \"\\033[36m天蓝字\\033[0m\" echo -e \"\\033[37m白色字\\033[0m\" #字背景颜色范围:40-47 echo -e \"\\033[40;37m黑底白字\\033[0m\" echo -e \"\\033[41;30m红底黑字\\033[0m\" echo -e \"\\033[42;34m绿底蓝字\\033[0m\" echo -e \"\\033[43;34m黄底蓝字\\033[0m\" echo -e \"\\033[44;30m蓝底黑字\\033[0m\" echo -e \"\\033[45;30m紫底黑字\\033[0m\" echo -e \"\\033[46;30m天蓝底黑字\\033[0m\" echo -e \"\\033[47;34m白底蓝字\\033[0m\" #..... #控制选项说明 #\\033[0m关闭所有属性 #\\033[1m设置高亮度 #\\033[4m下划线 echo -e \"\\033[4;31m下划线红字\\033[0m\" #闪烁 echo -e \"\\033[5;34m红字在闪烁\\033[0m\" #反影 echo -e \"\\033[8m消隐\\033[0m \" #### #\\033[30m-\\033[37m设置前景色 #\\033[40m-\\033[47m设置背景色 #\\033[nA光标上移n行 #\\033[nB光标下移n行 echo -e \"\\033[4A光标上移4行\\033[0m\" #\\033[nC光标右移n行 #\\033[nD光标左移n行 #\\033[y;xH设置光标位置 #\\033[2J清屏 #\\033[K清除从光标到行尾的内容 echo -e \"\\033[K清除光标到行尾的内容\\033[0m\" #\\033[s保存光标位置 #\\033[u恢复光标位置 #\\033[?25|隐藏光标 #\\033[?25h显示光标 echo -e \"\\033[?25l隐藏光标\\033[0m\" echo -e \"\\033[?25h显示光标\\033[0m\" #下面的这个例子是字体不停的闪烁。 #!/bin/bash #### a=30 b=41 while true do echo -e \"\\033[${a}m光辉女郎\\033[0m\" echo -e \"\\033[${a}m的吗西亚\\033[0m\" echo -e \"\\033[${a}m洛克萨斯\\033[0m\" a=$(($(($a%7))+30)) b=$(($(($b%7))+40)) #每次让字体颜色在30-37转换 #每次让背景颜色在40-47转换 echo -e \"\\033[4A\\033[0m\" done Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-22 12:33:35 "},"Programming_Shell_awk.html":{"url":"Programming_Shell_awk.html","title":"Shell的awk","keywords":"","body":"awk 筛选数据输出 针对数据文件，利用awk 判断符合条件的数据，并筛选出结果数据，输入到对应的文件中。 awk '{if ($7>5) print}' A|less ###筛选A文件中第七列大于5的数据，显示所有符合的结果 awk '{if ($6>5 && $7>5) print}' A|less ###筛选A文件中第六列和七列都大于5的数据，显示所有符合的结果 awk '{if ($6>5 || $7>5) print}' A|less ###筛选A文件中第六列或七列都大于5的数据，显示所有符合的结果 awk '{if ($7>5) print}' A|less>B ###筛选A文件中第七列大于5的数据，并将符合的结果输入到B文件中 排除筛选的例子https://www.cnblogs.com/chenwenyan/p/8580654.htmlhttps://segmentfault.com/q/1010000006687483以下两种方式都能实现排除以\"NAME\"为关键字, 且限定在行首或者第一列 [root@storage ~]# zpool list NAME SIZE ALLOC FREE CKPOINT EXPANDSZ FRAG CAP DEDUP HEALTH ALTROOT SAS-4T-group01 40.0T 18.2T 21.8T - - 0% 45% 1.00x DEGRADED - my-pool 21.8T 8.32T 13.5T - - 0% 38% 1.00x ONLINE - [root@storage ~]# zpool list | awk '!/^NAME/{print $1}' SAS-4T-group01 my-pool [root@storage ~]# zpool list | awk '{if($1!=\"NAME\"){print $1}}' SAS-4T-group01 my-pool [root@storage ~]# awk进行浮点计算 https://blog.51cto.com/radish/1736900典型示例: echo \"$A $B $C $D\" | awk '{printf (\"%.2f\\n\",$1*$2/$3-$4)}' awk以传参形式接收, 等同shell的函数调用,格式控制由prinft 来完成 也支持科学计数法的形式 [wangdong@centos715-node1 uncomp]$ echo \"6.8923e+08\" | awk '{printf (\"%.0f\\n\",$1)}' 689230000 传参变量的用法 [wangdong@centos715-node1 ~]$ A=5 [wangdong@centos715-node1 ~]$ B=16 [wangdong@centos715-node1 ~]$ C=29 [wangdong@centos715-node1 ~]$ D=6 [wangdong@centos715-node1 ~]$ echo \"$A $B $C $D\" | awk '{printf (\"%.2f\\n\",$1*$2/$3-$4)}' -3.24 [wangdong@centos715-node1 ~]$ echo \"$A $B $C $D\" | awk '{printf (\"%.2f\\n\",$1/$4)}' 0.83 [wangdong@centos715-node1 ~]$ echo \"$A $B $C $D\" | awk '{printf (\"%.3f\\n\",$1/$4)}' 0.833 awk中RS,ORS,FS,OFS 的作用 http://blog.51yip.com/shell/1151.html一，RS与ORS1，RS是记录分隔符，默认的分隔符是\\n，具体用法看下 [root@krlcgcms01 mytest]# cat test1 //测试文件 111 222 333 444 555 666 2，RS默认分割符是 \\n [root@krlcgcms01 mytest]# awk '{print $0}' test1 //awk 'BEGIN{RS=\"\\n\"}{print $0}' test1 这二个是一样的 111 222 333 444 555 666 其实你可以把上面test1文件里的内容理解为，111 222\\n333 444\\n555 6666，利用\\n进行分割。看下一个例子3，自定义RS分割符 [zhangy@localhost test]$ echo \"111 222|333 444|555 666\"|awk 'BEGIN{RS=\"|\"}{print $0,RT}' 111 222 | 333 444 | 555 666 结合上面一个例子，就很容易理解RS的用法了。 4，RS也可能是正则表达式 [zhangy@localhost test]$ echo \"111 222a333 444b555 666\"|awk 'BEGIN{RS=\"[a-z]+\"}{print $1,RS,RT}' 111 [a-z]+ a 333 [a-z]+ b 555 [a-z]+ 从例3和例4，我们可以发现一点，当RT是利用RS匹配出来的内容。如果RS是某个固定的值时，RT就是RS的内容。 5，RS为空时 [zhangy@localhost test]$ cat -n test2 1 111 222 2 3 333 444 4 333 444 5 6 7 555 666 [zhangy@localhost test]$ awk 'BEGIN{RS=\"\"}{print $0}' test2 111 222 333 444 333 444 555 666 [zhangy@localhost test]$ awk 'BEGIN{RS=\"\";}{print \"\"}' test2 //这个例子看着比较明显 从这个例子，可以看出当RS为空时，awk会自动以多行来做为分割符。 6，ORS记录输出分符符，默认值是\\n 把ORS理解成RS反过程，这样更容易记忆和理解，看下面的例子。 [zhangy@localhost test]$ awk 'BEGIN{ORS=\"\\n\"}{print $0}' test1 //awk '{print $0}' test1二者是一样的 111 222 333 444 555 666 [zhangy@localhost test]$ awk 'BEGIN{ORS=\"|\"}{print $0}' test1 111 222|333 444|555 666| 二，FS与OFS 1，FS指定列分割符 [zhangy@localhost test]$ echo \"111|222|333\"|awk '{print $1}' 111|222|333 [zhangy@localhost test]$ echo \"111|222|333\"|awk 'BEGIN{FS=\"|\"}{print $1}' 111 2，FS也可以用正则 [zhangy@localhost test]$ echo \"111||222|333\"|awk 'BEGIN{FS=\"[|]+\"}{print $1}' 111 3，FS为空的时候 [zhangy@localhost test]$ echo \"111|222|333\"|awk 'BEGIN{FS=\"\"}{NF++;print $0}' 1 1 1 | 2 2 2 | 3 3 3 当FS为空的时候，awk会把一行中的每个字符，当成一列来处理。 4，RS被设定成非\\n时，\\n会成FS分割符中的一个 [zhangy@localhost test]$ cat test1 111 222 333 444 555 666 [zhangy@localhost test]$ awk 'BEGIN{RS=\"444\";}{print $2,$3}' test1 222 333 666 222和333之间是有一个\\n的，当RS设定成444后，222和333被认定成同一行的二列了，其实按常规思想是二行的一列才对。 5，OFS列输出分隔符 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{print $1,$2}' test1 111|222 333|444 555|666 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{print $1 OFS $2}' test1 111|222 333|444 555|666 test1只有二列，如果100列，都写出来太麻烦了吧。 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{print $0}' test1 111 222 333 444 555 666 [zhangy@localhost test]$ awk 'BEGIN{OFS=\"|\";}{NF=NF;print $0}' test1 111|222 333|444 555|666 为什么第二种方法中的OFS生效呢？个人觉得，awk觉查到列有所变化时，就会让OFS生效，没变化直接输出了。 AWK ：8个强大的内置变量 http://blog.chinaunix.net/uid-28903506-id-5211480.html AWK的内置变量有两种类型：（1）. 一种是值可以被修改的变量，例如域分隔符、记录分隔符等。（2）. 另一种是被用在处理文本的过程中（记录处理的状态）或是用于统计，例如记录数、域的个数等。 FS 输入域分隔符变量awk 从输入中读取和处理每一行，默认是以空格作为分隔符，同时设置变量$1、$2等等。FS 变量的作用是作为每一个记录中的域分隔符。FS 的设置有两种方式：（1）通过 -F 命令行选项 $ awk -F 'FS' 'commands' inputfilename （2）直接按照普通变量的赋值方式 $ awk 'BEGIN{FS=\"FS\";}' 注意： （1）FS 可以被设置为任意的单个字符或正则表达式。（2）FS 可以变更任意次，他会一直保持值，直到被显式的修改。如果你需要修改域分隔符，最好在读取一行之前，这样变更就能作用于读取的行。 OFS 输入域分隔符变量OFS 作用类似于FS，不过他作用于输出文本，默认值是单个空格字符。 $ awk -F':' '{print $3,$4;}' /etc/passwd 41 41 100 101 print 语句中的连接符“,”用于使用OFS值来连接两个参数，如果变更OFS设置： $ awk -F':' 'BEGIN{OFS=\"=\";} {print $3,$4;}' /etc/passwd 41=41 100=101 RS 输入记录分隔符变量RS用于定义一行，而AWK默认即是一行接一行读取的。来看一个存储学生分数的文件（记录间以两个换行符分隔，而每一个域通过一个换行符分隔）： $cat student.txt Jones 2143 78 84 77 Gondrol 2321 56 58 45 RinRao 2122 38 37 65 如果要获取学生姓名和第一个分数值，可以使用以下awk脚本： $cat student.awk BEGIN { RS=\"\\n\\n\"; FS=\"\\n\"; } { print $1,$2; } $ awk -f student.awk student.txt Jones 2143 Gondrol 2321 RinRao 2122 在以上脚本中，因为RS变量被设置为两个换行符，所以awk读取每一个学生的详细信息作为一个记录。FS 值为换行符，所以记录中的每一行是一个域。 ORS 输出记录分隔符变量 ORS类似RS，他作用于输出。输出时打印每一条记录的同时会打印这个定界符。 $ awk 'BEGIN{ORS=\"=\";} {print;}' student-marks Jones 2143 78 84 77=Gondrol 2321 56 58 45=RinRao 2122 38 37 65= NR 记录个数变量NR 给出已处理的记录数或行号。下面这个例子中，NR变量保存行号，在awk脚本的END部分，NR变量可以告诉你一个文件中的记录总数。 $ awk '{print \"Processing Record - \",NR;}END {print NR, \"Students Records are processed\";}' student-marks Processing Record - 1 Processing Record - 2 Processing Record - 3 3 Students Records are processed （注：）在处理多个文件时，情况有所不同，NR值会累加，例如第一个文件有10个记录，当处理到第二个文件的第2个记录时，NR值为12 NF 域个数变量NF给出一个记录中域的总数。NF在判断一个记录中是否所有的域均存在时非常有用。 修改下上面的学生信息文件（第三个记录的第三个分数没有了）： $cat student-marks Jones 2143 78 84 77 Gondrol 2321 56 58 45 RinRao 2122 38 37 看下面脚本的输出： $ awk '{print NR,\"->\",NF}' student-marks 1 -> 5 2 -> 5 3 -> 4 FILENAME 当前输入文件名变量FILENAME 变量给出正在被读取的文件名。awk是可以接受多个输入文件来处理的。 $ awk '{print FILENAME}' student-marks student-marks student-marks student-marks 在上面的实例中，在处理文件的每一条记录时，都打印FILENAME，也就是 student-marks。 FNR 当前输入文件记录个数变量 当awk从多个文件读取时，NR变量将给出所有相关文件的记录总数，而 FNR 给出的是每个输入文件的记录数。 $awk '{print FILENAME, NR, FNR;}' student-marks bookdetails student-marks 1 1 student-marks 2 2 student-marks 3 3 bookdetails 4 1 bookdetails 5 2 bookdetails 6 3 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-18 11:04:30 "},"Programming_Python_dynamic_create_variable.html":{"url":"Programming_Python_dynamic_create_variable.html","title":"Python-语法糖-动态生成变量","keywords":"","body":"https://muyuuuu.github.io/2020/01/07/python-create-and-call-variables-batches/https://www.cnblogs.com/dcb3688/p/4347688.html 在编程中一定会有遇到操作一组变量的情况, 这时候如果有一个简化的操作显然强于逐个复制粘贴例如序列化命名的变量: user_var1, user_var2, user_var3 ....以此类推 在Python里的操作方法, 有函数方法和类方法之分 函数方法 当python在使用变量时，会按照下面的步骤去搜索： 1、函数或类的局部变量。2、全局变量。3、内置变量。以上三个步骤，其中一下步骤找到对应的变量，就不会再往下找。如果在这三个步骤都找不到，就会抛出异常。 使用 locals() 方法 for i in range(3): locals() ['x' + str(i)] = i for j in range(3): print(locals() ['x' + str(j)]) print(x0) x 就是变量名称的前缀部分 迭代器生成的0, 1, 2作为变量的后半部分 从而得到x0, x1, x2 三个变量 类方法 locals() 作为python解释器的内置方法, 在函数式编程是可以满足的, 在面向对象编程上则不可行. 面向对象编程上的一种方法是, 使用字典, 这个字典作为实例属性 class test(object): def __init__(self): self.d = {} for i in range(3): self.d['x' + str(i)] = i def run(self): for i in range(3): a = self.d['x' + str(i)] print(a) asd = test() asd.run() Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-08 10:17:21 "},"Programming_Python_reflection_and_introspection.html":{"url":"Programming_Python_reflection_and_introspection.html","title":"Python-反射与自省","keywords":"","body":"反射与自省(内省) 内省-维基百科https://zh.wikipedia.org/wiki/%E5%86%85%E7%9C%81_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6) 反射-维基百科https://zh.wikipedia.org/wiki/%E5%8F%8D%E5%B0%84_(%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6) 基本概念https://www.cnblogs.com/Yunya-Cnblogs/p/13114684.htmlhttps://www.cnblogs.com/huxi/archive/2011/01/02/1924317.html 操作https://www.cnblogs.com/vipchenwei/p/6991209.html 在python中, 通过4个内置函数进行 getattr(object, name[, default]) hasattr(object, name) setattr(object, name, value) delattr(object, name) Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-20 12:59:39 "},"Programming_Python_hotchpotch.html":{"url":"Programming_Python_hotchpotch.html","title":"Python-杂集","keywords":"","body":"致我从不用心记的Python时间格式处理 https://juejin.cn/post/6844903859257622541https://www.cnblogs.com/xuchunlin/p/5920549.htmlhttps://blog.csdn.net/google19890102/article/details/51355282https://blog.csdn.net/mighty13/article/details/78147357 关于strptime, Python的Doc已经说得很明确了, 在大规模使用的情况下, 应避免使用它--性能问题https://python3-cookbook.readthedocs.io/zh_CN/latest/c03/p15_convert_strings_into_datetimes.html假设日期格式是 YYYY-MM-DD它的意思是让你直接构建datietime格式的数据 from datetime import datetime def parse_ymd(s): year_s, mon_s, day_s = s.split('-') return datetime(int(year_s), int(mon_s), int(day_s)) 究竟strptime会比直接构建datietime格式数据的方式慢上多少?以下测试在AMD Ryzen 3700X 处理器上执行, 每个测试项循环100万次 >>> start_time = time.time() >>> a = \"2011-09-28 10:00:00\" >>> for i in range(1000000): ... var = time.strptime(a,'%Y-%m-%d %H:%M:%S') ... >>> end_time = time.time() >>> print(str(end_time - start_time) + \"秒\") 7.145048141479492秒 >>> >>> >>> >>> start_time = time.time() >>> a = \"2011-09-28 10:00:00\" >>> for i in range(1000000): ... var = datetime.strptime(a,'%Y-%m-%d %H:%M:%S') ... >>> end_time = time.time() >>> print(str(end_time - start_time) + \"秒\") 7.07616662979126秒 >>> >>> >>> >>> start_time = time.time() >>> a = \"2011-09-28 10:00:00\" >>> for i in range(1000000): ... year_s, mon_s, day_s = a.split(' ')[0].split('-') ... var = datetime(int(year_s), int(mon_s), int(day_s)) ... >>> end_time = time.time() >>> print(str(end_time - start_time) + \"秒\") 0.8247499465942383秒 >>> 由此可见与官方文档所说的相差7倍多大致一致并且不管datetime还是time下strptime函数, 性能并没有太明显的区别 time模块下的函数作用 strptime()函数将时间转换成时间数组 mktime()函数将时间数组转换成时间戳 #coding:UTF-8 import time dt = \"2016-05-05 20:28:54\" #转换成时间数组 timeArray = time.strptime(dt, \"%Y-%m-%d %H:%M:%S\") #转换成时间戳 timestamp = time.mktime(timeArray) print timestamp 字符串转时间戳 #设a为字符串 import time a = \"2011-09-28 10:00:00\" #中间过程，一般都需要将字符串转化为时间数组 time.strptime(a,'%Y-%m-%d %H:%M:%S') >>time.struct_time(tm_year=2011, tm_mon=9, tm_mday=27, tm_hour=10, tm_min=50, tm_sec=0, tm_wday=1, tm_yday=270, tm_isdst=-1) #将\"2011-09-28 10:00:00\"转化为时间戳 time.mktime(time.strptime(a,'%Y-%m-%d %H:%M:%S')) >>1317091800.0 #将时间戳转化为localtime x = time.localtime(1317091800.0) time.strftime('%Y-%m-%d %H:%M:%S',x) >>2011-09-27 10:50:00 数字型的时间戳转为Python内的时间戳格式 例如: 1612236538用到time.localtime ---> 把数字转为时间元组 >>> time.localtime(1612236538) time.struct_time(tm_year=2021, tm_mon=2, tm_mday=2, tm_hour=11, tm_min=28, tm_sec=58, tm_wday=1, tm_yday=33, tm_isdst=0) 时间元组不可做运算 >> time.localtime(1612236538) - time.localtime(1612236539) Traceback (most recent call last): File \"\", line 1, in TypeError: unsupported operand type(s) for -: 'time.struct_time' and 'time.struct_time' >>> 如果是再将这个时间戳转到\"YYYY-MM-DD HH:MM:SS\"格式 >>> time_format = time.localtime(1612236538) >>> time.strftime(\"%Y-%m-%d %H:%M:%S\", time_format) '2021-02-02 11:28:58' >>> Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-02-08 10:33:16 "},"category_2_Linux.html":{"url":"category_2_Linux.html","title":"Linux","keywords":"","body":"Linux分类文章 Linux分类文章的合集 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-09-15 10:13:15 "},"Linux_hotchpotch.html":{"url":"Linux_hotchpotch.html","title":"Linux上的杂集","keywords":"","body":"内存做ramdisk https://blog.csdn.net/weixin_37871174/article/details/75084619 以下操作不存在侵入性, 诸如编译内核参数等. #!/bin/bash # 指定大小,单位是KB size=$((8*1024*1024)) modprobe brd rd_nr=1 rd_size=${size} max_part=0 # 假设新增的是ram0, 如普通块设备一样格式化使用 mkfs.xfs /dev/ram0 # 开机启动RAMDISK, 示例 echo \"options brd rd_nr=1 rd_size=${size} max_part=0\" >> /etc/modprobe.d/ramdisk.conf echo \"mkfs.ext4 /dev/ram0\" >> /etc/rc.d/rc.local echo \"mount /dev/ram0 /ramdisk\" >> /etc/rc.d/rc.local chmod +x /etc/rc.d/rc.local # 卸载ramdisk, 先卸文件系统 umount /dev/ram0 modprobe -r brd 查找sar -d 里面显示设备名称与熟知的设备名称的对应关系 文章链接 两个命令用来查找对应关系 cat /proc/partitions dmsetup ls 不能本地console / 远程ssh登录的检查项 检查/etc/pam.d/login 是否有异常项检查/etc/securetty 这里面的是允许登录的交互方式, 如果被注释掉,则root不能登录检查/etc/passwd 用户shell 是否nologin从/var/log/messages 和 /var/log/secure 里查找提示 nmcli命令操作网卡配置 最终操作结果还是写入 /etc/sysconfig/network-scripts/ 下, 但红帽主导使用这个命令行工具 再一个它以各种profile的形式管理,也便于在多种类型的配置中快速切换文章链接文章链接文章链接文章链接 # 添加bonding接口 nmcli connection add con-name bond0 type bond ifname bond0 mode active-backup # 为bonding0接口添加从属接口 nmcli con add type bond-slave ifname ens33 master bond0 nmcli con add type bond-slave ifname ens37 master bond0 # 启动bonding网卡需要先启动从属网卡。 nmcli connection up bond-slave-ens33 nmcli connection up bond-slave-ens37 # 添加一个新配置文件:bond0, 对应接口名称:bond0 nmcli connection add con-name bond0 ifname bond0 autoconnect yes type ethernet ipv4.method manual ipv4.addresses 192.168.0.102/24 gw4 192.168.0.1 # 启动bond0网卡 nmcli con up bond0 # 修改已有的配置文件 nmcli connection modify \"bond0\" autoconnect yes type ethernet ipv4.method manual ipv4.addresses 192.168.0.102/24 gw4 192.168.0.1 # 启停某个接口 nmcli con down bond0 nmcli con up bond0 因机器异常关闭导致xfs文件系统损坏的不能启动 文章链接错误大概显示如下： xfs metadata I/O error(dm-0) blocked ox.... ... Entering emergence mode...... ~# ~# 此时需要作的就是修复dm-0, 如下：xfs_repair -L /dev/dm-0 /etc/fstab 文件详解 文章链接 其实 /etc/fstab (filesystem table) 就是将我们利用 mount 命令进行挂载时， 将所有的选项与参数写入到这个文件中就是了。除此之外， /etc/fstab 还加入了 dump 这个备份用命令的支持！ 与启动时是否进行文件系统检验 fsck 等命令有关。 挂载设备 : 不是我们通常理解的文件系统，而是指设备（硬盘及其分区，DVD光驱等）。它告知我们设备（分区）的名字，这是你在命令行中挂载（mount）、卸载（umount）设备时要用到的。 挂载点：告诉我们设备挂载到哪里。 文件系统类型：Linux支持许多文件系统。 要得到一个完整的支持名单查找mount man-page。典型 的名字包括这些：ext2, ext3, reiserfs, xfs, jfs,iso9660, vfat, ntfs, swap和auto, 'auto' 不是一个文件系统，而是让mount命令自动判断文件类型，特别对于可移动设备，软盘，DVD驱动器，这样做是很有必要的，因为可能每次挂载的文件类型不一致。 文件系统参数：这部分是最有用的设置！！！ 它能使你所挂载的设备在开机时自动加载、使中文显示不出现乱码、限制对挂载分区读写权限。它是与mount命令的用法相关的，要想得到一个完整的列表，参考mount manpage. 备份命令：dump utility用来决定是否做备份的. dump会检查entry并用数字来决定是否对这个文件系统进行备份。允许的数字是0和1。如果是0，dump就会忽略这个文件系统，如果是1，dump就会作一个备份。大部分的用户是没有安装dump的，所以对他们而言这个entry应该写为0。 是否以fsck检验扇区：启动的过程中，系统默认会以fsck检验我们的 filesystem 是否完整 (clean)。 不过，某些 filesystem 是不需要检验的，例如内存置换空间 (swap) ，或者是特殊文件系统例如 /proc 与 /sys 等等。fsck会检查这个头目下的数字来决定检查文件系统的顺序，允许的数字是0, 1, 和2。0 是不要检验， 1 表示最早检验(一般只有根目录会配置为 1)， 2 也是要检验，不过1会比较早被检验啦！一般来说,根目录配置为1,其他的要检验的filesystem都配置为 2 就好了。 常用参数： noatime 关闭atime特性，提高性能，这是一个很老的特性，放心关闭，还能减少loadcycle defaults 使用默认设置。等于rw,suid,dev,exec,auto,nouser,async，具体含义看下面的解释。 自动与手动挂载: auto 在启动或在终端中输入mount -a时自动挂载 noauto 设备（分区）只能手动挂载 读写权限: ro 挂载为只读权限 rw 挂载为读写权限 可执行: exec 是一个默认设置项，它使在那个分区中的可执行的二进制文件能够执行 noexec 二进制文件不允许执行。千万不要在你的root分区中用这个选项！！！ I/O同步: sync 所有的I/O将以同步方式进行 async 所有的I/O将以非同步方式进行 户挂载权限: user 允许任何用户挂载设备。 Implies noexec,nosuid,nodev unless overridden. nouser 只允许root用户挂载。这是默认设置。 临时文件执行权限： suid Permit the operation of suid, and sgid bits. They are mostly used to allow users on a computer system to execute binary executables with temporarily elevated privileges in order to perform a specific task. nosuid Blocks the operation of suid, and sgid bits. 处理NETSTAT中获取不到PID的进程 文章链接说是运行时间长(一年半载)的进程可能会遇到这种现象 在常规手段都找不到的情况下,还有可能是内核线程,所以没有PID 查看方式rpcinfo -p localhost NFS服务对应的端口及iptables配置 文章链接NFS主要用到的端口有：111- portmapper， 875 - rquotad，892-mountd，2049-nfs，udp：32769-nlockmgr，tcp：32803-nlockmgr，把这些端口加入到iptables规则中即可。配置过程如下：1、首先修改NFS配置文件(/etc/sysconfig/nfs)，加入以上端口：将#RQUOTAD_PORT=875，#LOCKD_TCPPORT=32803，#LOCKD_UDPPORT=32769，#MOUNTD_PORT=892，前面的4个#去掉，保存文件退出2、重启nfs服务 service nfs restart3、查看服务运行的相关端口情况，使用 rpcinfo -p program vers proto port service 100000 4 tcp 111 portmapper 100000 3 tcp 111 portmapper 100000 2 tcp 111 portmapper 100000 4 udp 111 portmapper 100000 3 udp 111 portmapper 100000 2 udp 111 portmapper 100024 1 udp 35093 status 100024 1 tcp 53692 status 100005 1 udp 892 mountd 100005 1 tcp 892 mountd 100005 2 udp 892 mountd 100005 2 tcp 892 mountd 100005 3 udp 892 mountd 100005 3 tcp 892 mountd 100003 2 tcp 2049 nfs 100003 3 tcp 2049 nfs 100003 4 tcp 2049 nfs 100227 2 tcp 2049 nfs_acl 100227 3 tcp 2049 nfs_acl 100003 2 udp 2049 nfs 100003 3 udp 2049 nfs 100003 4 udp 2049 nfs 100227 2 udp 2049 nfs_acl 100227 3 udp 2049 nfs_acl 100021 1 udp 32769 nlockmgr 100021 3 udp 32769 nlockmgr 100021 4 udp 32769 nlockmgr 100021 1 tcp 32803 nlockmgr 100021 3 tcp 32803 nlockmgr 100021 4 tcp 32803 nlockmgr 4、修改/etc/sysconfig/iptables，加入端口 -A INPUT -p tcp -m tcp --dport 111 -j ACCEPT -A INPUT -p udp -m udp --dport 111 -j ACCEPT -A INPUT -p tcp -m tcp --dport 2049 -j ACCEPT -A INPUT -p udp -m udp --dport 2049 -j ACCEPT -A INPUT -p tcp -m tcp --dport 892 -j ACCEPT -A INPUT -p udp -m udp --dport 892 -j ACCEPT -A INPUT -p tcp -m tcp --dport 875 -j ACCEPT -A INPUT -p udp -m udp --dport 875 -j ACCEPT -A INPUT -p tcp -m tcp --dport 32768 -j ACCEPT -A INPUT -p udp -m udp --dport 32768 -j ACCEPT -A INPUT -p tcp -m tcp --dport 32803 -j ACCEPT Linux查看进程运行的完整路径方法 通过ps及top命令查看进程信息时，只能查到相对路径，查不到的进程的详细信息，如绝对路径等。这时，我们需要通过以下的方法来查看进程的详细信息：Linux在启动一个进程时，系统会在/proc下创建一个以PID命名的文件夹，在该文件夹下会有我们的进程的信息，其中包括一个名为exe的文件即记录了绝对路径，通过ll或ls –l命令即可查看。ll /proc/PIDcwd符号链接的是进程运行目录；exe符号连接就是执行程序的绝对路径；cmdline就是程序运行时输入的命令行命令；environ记录了进程运行时的环境变量；fd目录下是进程打开或使用的文件的符号连接。 修改rsyslog的时间格式 文章链接 默认时间格式为\"Jun 28 10:07:09\",年份信息无法获知修改rsyslog.conf中的配置,可以结合man rsyslog.conf中的信息 以rsyslog为例:文件位置 /etc/rsyslog.conf$ActionFileDefaultTemplate 声明rsyslog使用哪个格式模板$template CustomFormat 创建了一个自定义格式的模板CustomFormat是模板的名称 # Use default timestamp format $template CustomFormat,\"%timestamp:::date-rfc3339% %HOSTNAME% %syslogtag% %msg%\\n\" #$ActionFileDefaultTemplate RSYSLOG_TraditionalFileFormat $ActionFileDefaultTemplate CustomFormat 配置sftp 文章链接 在sshd的配置文件,默认 /etc/sshd_config这里我们使用系统自带的 internal-sftp 服务即可满足需求 #Subsystem sftp /usr/libexec/openssh/sftp-server Subsystem sftp internal-sftp Subsystem Subsystem 是说 ssh 的子模块 这里启用的即为 sftp 模块，我们使用系统自带的 internal-sftp 来提供此服务，其实配置到这你即可以使用帐号 ssh 登录，也可以使用 ftp 客户端 sftp 登录。 EOF块中使变量不被引用方法 /etc/fstab中带空格的路径问题 写入/etc/fstab中的路径,如果有空格,用引号,以及用\\转义都是行不通的,会提示/etc/fstab列表中语法有错误 [mntent]: line 9 in /etc/fstab is bad [mntent]: line 10 in /etc/fstab is bad 而正解是,空格用\\040代替 wget下载目录 文章链接 wget -r -p -np -k -P ~/tmp/ http://Java-er.com -P 表示下载到哪个目录 -r 表示递归下载 -np 表示不下载旁站连接. -k 表示将下载的网页里的链接修改为本地链接. -p 获得所有显示网页所需的元素 额外的 -c 断点续传 -nd 递归下载时不创建一层一层的目录，把所有的文件下载到当前目录 -L 递归时不进入其它主机，如wget -c -r www.xxx.org/ -A 指定要下载的文件样式列表，多个样式用逗号分隔 -i 后面跟一个文件，文件内指明要下载的URL wget使用代理 文章链接 方法一 在环境变量中设置代理 export http_proxy=http://127.0.0.1:8087 方法二、使用配置文件 为wget使用代理，可以直接修改/etc/wgetrc，也可以在主文件夹下新建.wgetrc，并编辑相应内容，本文采用后者。 将/etc/wgetrc中与proxy有关的几行复制到~/.wgetrc，并做如下修改： # You can set the default proxies for Wget to use for http, https, and ftp. # They will override the value in the environment. https_proxy = http://127.0.0.1:8087/ http_proxy = http://127.0.0.1:8087/ ftp_proxy = http://127.0.0.1:8087/ # If you do not want to use proxy at all, set this to off. use_proxy = on 这里 use_proxy = on 开启了代理，如果不想使用代理，每次都修改此文件未免麻烦，我们可以在命令中使用-Y参数来临时设置：-Y, --proxy=on/off 打开或关闭代理 方法三 使用-e参数 wget本身没有专门设置代理的命令行参数，但是有一个\"-e\"参数，可以在命令行上指定一个原本出现在\".wgetrc\"中的设置。于是可以变相在命令行上指定代理：-e, --execute=COMMAND 执行`.wgetrc'格式的命令例如： wget -c -r -np -k -L -p -e \"http_proxy=http://127.0.0.1:8087\" http://www.subversion.org.cn/svnbook/1.4/ 这种方式对于使用一个临时代理尤为方便。 SuSE和rhel添加删除磁盘不重启的方法 SuSE：使用自带脚本：rescan-scsi-bus.sh ： 添加磁盘以后执行该脚本可以看到添加的磁盘rescan-scsi-bus.sh -r ： 删除磁盘以后执行可以剔除磁盘以上脚本如果没有可以安装包：sg3_utils以上的方法可以在rhel里面使用，rpm包也是一样的，但是rescan-scsi-bus.sh -r 这个命令在rhel官方资料里面写了有bug，不建议使用 RHEL：echo \"- - -\" > /sys/class/scsi_host/hostx/scanhostx表示在/sys/class/scsi_host有多个host开头的文件，映射的磁盘至操作系统可能是通过host0或者其他的hostx，如果执行host0的没有继续执行其余的hostxecho \"1\" > /sys/block/sdx/device/deletesdx表示要删除的磁盘，比如sdb 用screen来保持需前台活跃的程序 类似于比如wget需长时间下载，或是一个长时间执行脚本需要等待结果，在SSH断开后重连依然能接续上的场景 用screen来实现如没有则 yum -y install screen使用方法：输入screen，进入screen的会话窗口，但与shell基本相同（用户配置文件没有加载）此时执行需要执行的程序按ctrl+A之后再按D键，出现[detached] 此时可以断开SSH连接，screen仍在运行。 重连SSH，输入screen -r将恢复screen中的内容。 退出screen，输入exit，将显示[screen is terminating] 命令置于前台后台 用&将执行的命令置于后台后，重新唤回前台的方法，fg或是% 查询与终止当前用户会话 查看自己当前所用的会话（不需要终止的会话）输入tty显示：/dev/pts/5 终止不需要的会话pkill -9 -t pts/1pkill -9 -t pts/2pkill -9 -t pts/3pkill -9 -t pts/4-t 参数：需要终止的会话的TTY 关于tar: Removing leading `/’ from member names 文章链接首先应该明确：*nix系统中，使用tar对文件打包时，一般不建议使用绝对路径。 通常是在两台环境相似的机器上进行同步复制的时候，才有需要使用绝对路径进行打包。使用绝对路径打包时如果不指定相应的参数，tar会产生一句警告信息：tar: Removing leading `/’ from member names并且实际产生的压缩包会将绝对路径转化为相对路径。 比如： 这样的一个压缩包，如果我们再去解开，就会当前目录（也即此例中的“~”）下再新建出“./home/robin/” 两级目录。对于这样的压缩包，解压方法是使用参数 “-C”指解压的目录为根目录（“/”）：tar -xzvf robin.tar.gz -C / 更为可靠的方法是在打包和解开的时候都使用参数 -P IP反查主机名、MAC地址 用nmap对局域网扫描一遍，然后查看arp缓存表就可以知道局域内ip对应的mac了。nmap比较强大也可以直接扫描mac地址和端口。执行扫描之后就可以 cat /proc/net/arp查看arp缓存表了。 进行ping扫描，打印出对扫描做出响应的主机：$ nmap -sP 192.168.1.0/24 仅列出指定网络上的每台主机，不发送任何报文到目标主机：$ nmap -sL 192.168.1.0/24 探测目标主机开放的端口，可以指定一个以逗号分隔的端口列表(如-PS 22，23，25，80)：$ nmap -PS 192.168.1.234 使用UDP ping探测主机：$ nmap -PU 192.168.1.0/24 使用频率最高的扫描选项（SYN扫描,又称为半开放扫描），它不打开一个完全的TCP连接，执行得很快：$ nmap -sS 192.168.1.0/24 配置永久静态路由 文章链接使用不附带任何选项的 ip route 命令显示 IP 路由表。例如： ~]$ ip route default via 192.168.122.1 dev ens9 proto static metric 1024 192.168.122.0/24 dev ens9 proto kernel scope link src 192.168.122.107 192.168.122.0/24 dev eth0 proto kernel scope link src 192.168.122.126 要在主机地址中添加一个静态路由，即 IP 地址，请作为 root 运行以下命令： ip route add 192.0.2.1 via 10.0.0.1 [dev ifname] 其中 192.0.2.1 是用点分隔的十进制符号中的 IP 地址，10.0.0.1 是下一个跃点，ifname 是进入下一个跃点的退出接口。要在网络中添加一个静态路由，即代表 IP 地址范围的 IP 地址，请作为 root 运行以下命令： ip route add 192.0.2.0/24 via 10.0.0.1 [dev ifname] 其中 192.0.2.1 是用点分隔的十进制符号中目标网络的 IP 地址，10.0.0.1 是网络前缀。网络前缀是在子网掩码中启用的位元。这个网络地址/网络前缀长度格式有时是指无类别域际路由选择（CIDR）表示法。可在 /etc/sysconfig/network-scripts/route-interface 文件中为每个接口保存其静态路由配置。例如：接口 eth0 的静态路由可保存在 /etc/sysconfig/network-scripts/route-eth0 文件中。route-interface 文件有两种格式：ip 命令参数和网络/子网掩码指令，如下所述。有关 ip route 命令的详情，请查看 ip-route(8) man page。 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-12-01 09:50:14 "},"Linux_kernel_parameter.html":{"url":"Linux_kernel_parameter.html","title":"内核参数","keywords":"","body":"默认的配置文件位置/etc/sysctl.conf 【本机性能类】 https://www.ibm.com/support/knowledgecenter/zh/SSEPGG_10.5.0/com.ibm.db2.luw.qb.server.doc/doc/t0008238.htmlipcs -l 可以查看以下两组参数的当前值, 各种数据库的安装程序可能会自动以公式计算并修改sysctl.conf 文件以设置下列值 /proc/sys/kernel/shmmax该文件表示内核所允许的最大共享内存段的大小（bytes）。缺省设置：33554432建议设置：物理内存 * 50%实际可用最大共享内存段大小=shmmax * 98%，其中大约2%用于共享内存结构。可以通过设置shmmax，然后执行ipcs -l来验证。 /proc/sys/kernel/shmall该文件表示在任何给定时刻，系统上可以使用的共享内存的总量（bytes）。缺省设置：2097152 kernel.msgmnb = 65536kernel.msgmax = 65536设置最大内存共享段大小byteskernel.shmmax = 68719476736kernel.shmall = 4294967296 /proc/sys/fs/file-maxThis file defines a system-wide limit on the number of open files for all processes. (See also setrlimit(2), which can be used by a process to set the per-process limit, RLIMIT_NOFILE, on the number of files it may open.) If you get lots of error messages about running out of file handles, try increasing this value即file-max是设置 系统所有进程一共可以打开的文件数量 。同时一些程序可以通过setrlimit调用，设置每个进程的限制。如果得到大量使用完文件句柄的错误信息，是应该增加这个值。也就是说，这项参数是系统级别的。fs.file-max = 819200 /proc/sys/net/core/netdev_max_backlog进入包的最大设备队列.默认是1000,对重负载服务器而言,该值太低,可调整到16384 / 32768 / 65535该文件表示在每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。进入包的最大设备队列.默认是1000,对重负载服务器而言,该值太低,可调整到16384.net.core.netdev_max_backlog = 32768 listen()的默认参数,挂起请求的最大数量.默认是128.对繁忙的服务器,增加该值有助于网络性能.可调整到8192 / 16384 / 32768net.core.somaxconn = 16384 /proc/sys/net/core/optmem_max每个socket buffer的最大补助缓存大小,默认10K(10240),也可调整到20k(20480),但建议保留net.core.optmem_max = 10240 /proc/sys/net/ipv4/tcp_wmemTCP写buffer,可参考的优化值:873200 / 1746400 / 3492800 / 6985600该文件包含3个整数值，分别是：min，default，maxMin：为TCP socket预留用于发送缓冲的内存最小值。每个TCP socket都可以使用它。Default：为TCP socket预留用于发送缓冲的内存数量，默认情况下该值会影响其它协议使用的net.core.wmem中default的 值，一般要低于net.core.wmem中default的值。Max：为TCP socket预留用于发送缓冲的内存最大值。该值不会影响net.core.wmem_max，今天选择参数SO_SNDBUF则不受该值影响。默认值为 128K。缺省设置：4096 16384 131072建议设置：873200 1746400 3492800net.ipv4.tcp_wmem = 873200 1746400 3492800 /proc/sys/net/ipv4/tcp_rmemTCP读buffer,可参考的优化值:873200 / 1746400 / 3492800 / 6985600该文件包含3个整数值，分别是：min，default，maxMin：为TCP socket预留用于接收缓冲的内存数量，即使在内存出现紧张情况下TCP socket都至少会有这么多数量的内存用于接收缓冲。Default：为TCP socket预留用于接收缓冲的内存数量，默认情况下该值影响其它协议使用的 net.core.wmem中default的 值。该值决定了在tcp_adv_win_scale、tcp_app_win和tcp_app_win的默认值情况下，TCP 窗口大小为65535。Max：为TCP socket预留用于接收缓冲的内存最大值。该值不会影响 net.core.wmem中max的值，今天选择参数 SO_SNDBUF则不受该值影响。缺省设置：4096 87380 174760建议设置：873200 1746400 3492800net.ipv4.tcp_rmem = 873200 1746400 3492800 /proc/sys/net/core/wmem_defaulttcp 的内存是基于系统的内存自动计算的该文件指定了发送套接字缓冲区大小的缺省值（以字节为单位）。缺省设置：110592/proc/sys/net/core/wmem_max该文件指定了发送套接字缓冲区大小的最大值（以字节为单位）。缺省设置：131071缺省socket写buffer,可参考的优化值:873200 / 1746400 / 3492800net.core.wmem_default = 1746400最大socket写buffer,可参考的优化值:1746400 / 3492800 / 6985600net.core.wmem_max = 3492800缺省socket读buffer,可参考的优化值:873200 / 1746400 / 3492800net.core.rmem_default = 1746400最大socket读buffer,可参考的优化值:1746400 / 3492800 / 6985600net.core.rmem_max = 3492800 【网络协议工作机制类】 决定检查过期多久邻居条目内核维护的arp表过于庞大, 发生抖动, 因此导致了这种情况,几个内核ARP参数gc_stale_time决定检查一次相邻层记录的有效性的周期。当相邻层记录失效时，将在给它发送数据前，再解析一次。缺省值是60秒。gc_thresh1存在于ARP高速缓存中的最少层数，如果少于这个数，垃圾收集器将不会运行。缺省值是128。gc_thresh2保存在 ARP 高速缓存中的最多的记录软限制。垃圾收集器在开始收集前，允许记录数超过这个数字 5 秒。缺省值是 512。gc_thresh3保存在 ARP 高速缓存中的最多记录的硬限制，一旦高速缓存中的数目高于此，垃圾收集器将马上运行。缺省值是1024。比如arp -an|wc -l的结果是300左右, 那么应当调高gc_thresh各项数值,防止抖动的发生 echo \"net.ipv4.neigh.default.gc_thresh1 = 512\" >> sysctl.conf echo \"net.ipv4.neigh.default.gc_thresh2 = 2048\" >> sysctl.conf echo \"net.ipv4.neigh.default.gc_thresh3 = 4096\" >> sysctl.conf net.ipv4.neigh.default.gc_stale_time=120 使用arp_announce / arp_ignore解决ARP映射问题https://www.jianshu.com/p/734640384fdaarp_ignore和arp_announce参数都和ARP协议相关，主要用于控制系统返回arp响应和发送arp请求时的动作。这两个参数很重要，特别是在LVS的DR场景下，它们的配置直接影响到DR转发是否正常。首先看一下Linux内核文档中对于它们的描述：arp_ignore - INTEGERDefine different modes for sending replies in response toreceived ARP requests that resolve local target IP addresses 0 - (default): reply for any local target IP address, configured on any interface1 - reply only if the target IP address is local address configured on the incoming interface2 - reply only if the target IP address is local address configured on the incoming interface and both with the sender's IP address are part from same subnet on this interface3 - do not reply for local addresses configured with scope host, only resolutions for global and link addresses are replied4-7 - reserved8 - do not reply for all local addresses The max value from conf/{all,interface}/arp_ignore is used when ARP request is received on the {interface}arp_ignore参数的作用是控制系统在收到外部的arp请求时，是否要返回arp响应。arp_ignore参数常用的取值主要有0，1，2，3~8较少用到：0：响应任意网卡上接收到的对本机IP地址的arp请求（包括环回网卡上的地址），而不管该目的IP是否在接收网卡上。1：只响应目的IP地址为接收网卡上的本地地址的arp请求。2：只响应目的IP地址为接收网卡上的本地地址的arp请求，并且arp请求的源IP必须和接收网卡同网段。3：如果ARP请求数据包所请求的IP地址对应的本地地址其作用域（scope）为主机（host），则不回应ARP响应数据包，如果作用域为全局（global）或链路（link），则回应ARP响应数据包。4~7：保留未使用8：不回应所有的arp请求 避免放大攻击,如果你ping子网的子网地址，所有的机器都应该予以回应。这可能成为非常好用的拒绝服务攻击工具。设置为1来忽略这些子网广播消息。net.ipv4.icmp_echo_ignore_broadcasts = 1开启恶意icmp错误消息保护net.ipv4.icmp_ignore_bogus_error_responses = 1/proc/sys/net/ipv4/icmp_echo_ignore_all/proc/sys/net/ipv4/icmp_echo_ignore_broadcasts该文件表示内核是否忽略所有的ICMP ECHO请求，或忽略广播和多播请求。0， 响应请求1， 忽略请求缺省设置：０建议设置：1 arp_announce的作用是控制系统在对外发送arp请求时，如何选择arp请求数据包的源IP地址。（比如系统准备通过网卡发送一个数据包a，这时数据包a的源IP和目的IP一般都是知道的，而根据目的IP查询路由表，发送网卡也是确定的，故源MAC地址也是知道的，这时就差确定目的MAC地址了。而想要获取目的IP对应的目的MAC地址，就需要发送arp请求。arp请求的目的IP自然就是想要获取其MAC地址的IP，而arp请求的源IP是什么呢？ 可能第一反应会以为肯定是数据包a的源IP地址，但是这个也不是一定的，arp请求的源IP是可以选择的，控制这个地址如何选择就是arp_announce的作用）arp_announce参数常用的取值有0，1，2。0：允许使用任意网卡上的IP地址作为arp请求的源IP，通常就是使用数据包a的源IP。1：尽量避免使用不属于该发送网卡子网的本地地址作为发送arp请求的源IP地址。2：忽略IP数据包的源IP地址，选择该发送网卡上最合适的本地地址作为arp请求的源IP地址。sysctl.conf中包含all和eth/lo（具体网卡）的arp_ignore参数，取其中较大的值生效。net.ipv4.conf.default.arp_announce = 2net.ipv4.conf.all.arp_announce=2net.ipv4.conf.lo.arp_announce=2 表示开启SYN Cookies。当出现SYN等待队列溢出时，启用cookies来处理，可防范少量SYN攻击，默认为0，表示关闭。14) /proc/sys/net/ipv4/tcp_syncookies该文件表示是否打开TCP同步标签(syncookie)，内核必须打开了 CONFIG_SYN_COOKIES项进行编译。 同步标签(syncookie)可以防止一个套接字在有过多试图连接到达时引起过载。缺省设置：0net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_tw_recycle = 1表示开启TCP连接中TIME-WAIT sockets的快速回收，默认为0，表示关闭。Enable fast recycling of TIME-WAIT sockets. Enabling this option is not recommended since this causes problems when working with NAT (Network Address Translation).启用TIME-WAIT状态sockets的快速回收，这个选项不推荐启用。在NAT(Network Address Translation)网络下，会导致大量的TCP连接建立错误。net.ipv4.tcp_tw_reuse = 1与其功能相似的参数net.ipv4.tcp_tw_reuse，手册里稍微有点描述，如下：tcp_tw_reuse (Boolean; default: disabled; since Linux 2.4.19 / 2.6)Allow to reuse TIME-WAIT sockets for new connections when it is safe from protocol viewpoint. It should not be changed without advice/request of technical experts.从协议设计上来看，对于TIME-WAIT状态的sockets重用到新的TCP连接上来说，是安全的。（用于客户端时的配置）表示开启重用,允许将TIME-WAIT sockets重新用于新的TCP连接,默认为0,表示关闭 表示如果套接字由本端要求关闭，这个参数决定了它保持在FIN-WAIT-2状态的时间。/proc/sys/net/ipv4/tcp_fin_timeout对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。默认值为 60 秒。过去在2.2版本的内核中是 180 秒。您可以设置该值，但需要注意，如果您的机器为负载很重的web服务器，您可能要冒内存被大量无效数据报填满的风险，FIN-WAIT-2 sockets 的危险性低于 FIN-WAIT-1，因为它们最多只吃 1.5K的内存，但是它们存在时间更长。另外参考 tcp_max_orphans。缺省设置：60（秒）net.ipv4.tcp_fin_timeout = 30 限制仅仅是为了防止简单的DoS 攻击/proc/sys/net/ipv4/tcp_max_orphans系统所能处理不属于任何进程的TCP sockets最大数量。假如超过这个数量，那么不属于任何进程的连接会被立即reset，并同时显示警告信息。之所以要设定这个限制，纯粹为了抵御那些简单的 DoS 攻击，千万不要依赖这个或是人为的降低这个限制。缺省设置：8192net.ipv4.tcp_max_orphans = 3276800 表示用于向外连接的端口范围。缺省情况下过窄：32768到61000/proc/sys/net/ipv4/ip_local_port_rangenet.ipv4.ip_local_port_range = 10000 65535 表示SYN队列的长度，RHEL 7.7 默认为128，加大队列长度为8192，可以容纳更多等待连接的网络连接数。/proc/sys/net/ipv4/tcp_max_syn_backlog进入SYN包的最大请求队列.默认1024.对重负载服务器,增加该值显然有好处.可调整到16384.对于那些依然还未获得客户端确认的连接请求，需要保存在队列中最大数目。对于超过 128Mb 内存的系统，默认值是 1024，低于 128Mb 的则为 128。如果服务器经常出现过载，可以尝试增加这个数字。警告！假如您将此值设为大于1024，最好修改 include/net/tcp.h 里面的 TCP_SYNQ_HSIZE，以保持TCP_SYNQ_HSIZE*16 0)或者bytes-bytes/2^(-tcp_adv_win_scale)(如果tcp_adv_win_scale 128Mb 32768-610000)则系统将忽略所有发送给自己的ICMP ECHO请求或那些广播地址的请求。缺省设置：1024net.ipv4.tcp_max_syn_backlog = 16384 /proc/sys/net/ipv4/tcp_timestamps该文件表示是否启用以一种比超时重发更精确的方法（请参阅 RFC 1323）来启用对 RTT 的计算；为了实现更好的性能应该启用这个选项。缺省设置：1net.ipv4.tcp_timestamps = 0 表示系统同时保持TIME_WAIT套接字的最大数量，如果超过这个数字，TIME_WAIT套接字将立刻被清除并打印警告信息。默认为180000，建议减小，避免TIME_WAIT状态过多消耗整个服务器的资源，但也不能太小，跟你后端的处理速度有关，如果速度快可以小，速度慢则适当加大，否则高负载会有请求无法响应或非常慢。/proc/sys/net/ipv4/tcp_max_tw_buckets系统在同时所处理的最大timewait sockets 数目。如果超过此数的话，time-wait socket 会被立即砍除并且显示警告信息。之所以要设定这个限制，纯粹为了抵御那些简单的 DoS 攻击，千万不要人为的降低这个限制，不过，如果网络条件需要比默认值更多，则可以提高它(或许还要增加内存)。RHEL 7.7 缺省设置：8192net.ipv4.tcp_max_tw_buckets = 8192 /proc/sys/net/ipv4/tcp_sack该文件表示是否启用有选择的应答（Selective Acknowledgment），这可以通过有选择地应答乱序接收到的报文来提高性能（这样可以让发送者只发送丢失的报文段）；（对于广域网通信来说）这 个选项应该启用，但是这会增加对 CPU 的占用。缺省设置：1net.ipv4.tcp_sack = 1 /proc/sys/net/ipv4/tcp_window_scaling该文件表示设置tcp/ip会话的滑动窗口大小是否可变。参数值为布尔值，为1时表示可变，为0时表示不可变。tcp/ip通常使用的窗口最大可达到 65535 字节，对于高速网络，该值可能太小，这时候如果启用了该功能，可以使tcp/ip滑动窗口大小增大数个数量级，从而提高数据传输的能力。缺省设置：1net.ipv4.tcp_window_scaling = 1 以下3个参数与TCP KeepAlive有关.单位为秒,默认值是tcp_keepalive_time = 7200tcp_keepalive_probes = 9tcp_keepalive_intvl = 75/proc/sys/net/ipv4/tcp_keepalive_intvl该文件表示发送TCP探测的频率，乘以tcp_keepalive_probes表示断开没有相应的TCP连接的时间。缺省设置：75（秒）意思是如果某个TCP连接在idle 2个小时后,内核才发起probe.如果probe 9次(每次75秒)不成功,内核才彻底放弃,认为该连接已失效.对服务器而言,显然上述值太大.可调整到 net.ipv4.tcp_keepalive_time = 1200net.ipv4.tcp_keepalive_probes = 3net.ipv4.tcp_keepalive_intvl = 30表示当keepalive起用的时候，TCP发送keepalive消息的频度。缺省是2小时，改为20分钟。 表示开启SYN Cookies,当出现SYN等待队列溢出时,启用cookies来处理,可防范少量SYN攻击,默认为0,表示关闭net.ipv4.tcp_syncookies = 1 表示开启TCP连接中TIME-WAIT sockets的快速回收,默认为0,表示关闭 其它的一些设置net.ipv4.route.gc_timeout = 100 内核放弃建立连接之前发送SYNACK 包的数量/proc/sys/net/ipv4/tcp_syn_retries该文件表示本机向外发起TCP SYN连接超时重传的次数，不应该高于255；该值仅仅针对外出的连接，对于进来的连接由tcp_retries1控制。缺省设置：5net.ipv4.tcp_syn_retries = 2net.ipv4.tcp_synack_retries = 2 /proc/sys/net/ipv4/tcp_retries1该文件表示放弃回应一个TCP连接请求前进行重传的次数。缺省设置：3net.ipv4.tcp_retries1 = 3 该文件表示放弃在已经建立通讯状态下的一个TCP数据包前进行重传的次数。TCP失败重传次数,默认值15,意味着重传15次才彻底放弃.可减少到5,以尽早释放内核资源/proc/sys/net/ipv4/tcp_retries2缺省设置：15net.ipv4.tcp_retries2 = 5 core文件名中添加pid作为扩展名---RHEL 7.7 默认值已是此值kernel.core_uses_pid = 1 rp_filter参数用于控制系统是否开启对数据包源地址的校验---RHEL 7.7 默认值已是此值https://www.jianshu.com/p/717e6cd9d2bb首先看一下Linux内核文档documentation/networking/ip-sysctl.txt中的描述：rp_filter - INTEGER0 - No source validation.1 - Strict mode as defined in RFC3704 Strict Reverse Path Each incoming packet is tested against the FIB and if the interface is not the best reverse path the packet check will fail. By default failed packets are discarded.2 - Loose mode as defined in RFC3704 Loose Reverse Path Each incoming packet's source address is also tested against the FIBand if the source address is not reachable via any interface the packet check will fail.Current recommended practice in RFC3704 is to enable strict mode to prevent IP spoofing from DDos attacks. If using asymmetric routing or other complicated routing, then loose mode is recommended.The max value from conf/{all,interface}/rp_filter is used when doing source validation on the {interface}. Default value is 0. Note that some distributions enable itin startup scripts.即rp_filter参数有三个值，0、1、2，具体含义：0：不开启源地址校验。1：开启严格的反向路径校验。对每个进来的数据包，校验其反向路径是否是最佳路径。如果反向路径不是最佳路径，则直接丢弃该数据包。2：开启松散的反向路径校验。对每个进来的数据包，校验其源地址是否可达，即反向路径是否能通（通过任意网口），如果反向路径不同，则直接丢弃该数据包。net.ipv4.conf.all.rp_filter = 1net.ipv4.conf.default.rp_filter = 1 /proc/sys/net/ipv4/tcp_mem该文件包含3个整数值，分别是：low，pressure，highLow：当TCP使用了低于该值的内存页面数时，TCP不会考虑释放内存。Pressure：当TCP使用了超过该值的内存页面数量时，TCP试图稳定其内存使用，进入pressure模式，当内存消耗低于low值时则退出 pressure状态。High：允许所有tcp sockets用于排队缓冲数据报的页面量。一般情况下这些值是在系统启动时根据系统内存数量计算得到的。缺省设置：24576 32768 49152建议设置：78643200 104857600 157286400net.ipv4.tcp_mem = 94500000 915000000 927000000 【路由类】 开启路由转发--取决于是否充当路由器的功能需求net.ipv4.ip_forward = 1net.ipv4.conf.all.send_redirects = 1net.ipv4.conf.default.send_redirects = 1 修改防火墙表大小，默认65536net.netfilter.nf_conntrack_max=655350net.netfilter.nf_conntrack_tcp_timeout_established=1200 /proc/sys/net/ipv4/conf/*/accept_redirects如果主机所在的网段中有两个路由器，你将其中一个设置成了缺省网关，但是该网关在收到你的ip包时发现该ip包必须经过另外一个路由器，这时这个路由器就会给你发一个所谓的“重定向”icmp包，告诉将ip包转发到另外一个路由器。参数值为布尔值，1表示接收这类重定向icmp 信息，0表示忽略。在充当路由器的linux主机上缺省值为0在一般的linux主机上缺省值为1建议将其改为0以消除安全性隐患net.ipv4.conf.all.accept_redirects = 0net.ipv4.conf.default.accept_redirects = 0net.ipv4.conf.all.secure_redirects = 0net.ipv4.conf.default.secure_redirects = 0 处理无源路由的包, 或许某些路由器会启动这个设定值， 不过目前的设备很少使用到这种来源路由，你可以取消这个设定值---RHEL 7.7 默认值已是此值net.ipv4.conf.all.accept_source_route = 0net.ipv4.conf.default.accept_source_route = 0 /proc/sys/kernel/优化 1) /proc/sys/kernel/ctrl-alt-del 该文件有一个二进制值，该值控制系统在接收到ctrl+alt+delete按键组合时如何反应。这两个值分别是：零（0）值，表示捕获ctrl+alt+delete，并将其送至 init 程序；这将允许系统可以安全地关闭和重启，就好象输入shutdown命令一样。壹（1）值，表示不捕获ctrl+alt+delete，将执行非正常的关闭，就好象直接关闭电源一样。缺省设置：0建议设置：1，防止意外按下ctrl+alt+delete导致系统非正常重启。 2) /proc/sys/kernel/msgmax该文件指定了从一个进程发送到另一个进程的消息的最大长度（bytes）。进程间的消息传递是在内核的内存中进行的，不会交换到磁盘上，所以如果增加该值，则将增加操作系统所使用的内存数量。缺省设置：8192 4) /proc/sys/kernel/msgmni该文件指定消息队列标识的最大数目，即系统范围内最大多少个消息队列。缺省设置：16 5) /proc/sys/kernel/panic该文件表示如果发生“内核严重错误（kernel panic）”，则内核在重新引导之前等待的时间（以秒为单位）。零（0）秒，表示在发生内核严重错误时将禁止自动重新引导。缺省设置：0 6) /proc/sys/kernel/shmmni该文件表示用于整个系统的共享内存段的最大数目（个）。缺省设置：4096 7) /proc/sys/kernel/threads-max该文件表示内核所能使用的线程的最大数目。缺省设置：2048 8) /proc/sys/kernel/sem该文件用于控制内核信号量，信号量是System VIPC用于进程间通讯的方法。建议设置：250 32000 100 128第一列，表示每个信号集中的最大信号量数目。第二列，表示系统范围内的最大信号量总数目。第三列，表示每个信号发生时的最大系统操作数目。第四列，表示系统范围内的最大信号集总数目。所以，（第一列）*（第四列）=（第二列）以上设置，可以通过执行ipcs -l来验证。 /proc/sys/vm/优化 1) /proc/sys/vm/block_dump该文件表示是否打开Block Debug模式，用于记录所有的读写及Dirty Block写回动作。缺省设置：0，禁用Block Debug模式 2) /proc/sys/vm/dirty_background_ratio该文件表示脏数据到达系统整体内存的百分比，此时触发pdflush进程把脏数据写回磁盘。缺省设置：10 3) /proc/sys/vm/dirty_expire_centisecs该文件表示如果脏数据在内存中驻留时间超过该值，pdflush进程在下一次将把这些数据写回磁盘。缺省设置：3000（1 / 100秒） 4) /proc/sys/vm/dirty_ratio该文件表示如果进程产生的脏数据到达系统整体内存的百分比，此时进程自行把脏数据写回磁盘。缺省设置：40 5) /proc/sys/vm/dirty_writeback_centisecs该文件表示pdflush进程周期性间隔多久把脏数据写回磁盘。缺省设置：500（1 / 100秒） 6) /proc/sys/vm/vfs_cache_pressure该文件表示内核回收用于directory和inode cache内存的倾向；缺省值100表示内核将根据pagecache和swapcache，把directory和inode cache保持在一个合理的百分比；降低该值低于100，将导致内核倾向于保留directory和inode cache；增加该值超过100，将导致内核倾向于回收directory和inode cache。缺省设置：100 7) /proc/sys/vm/min_free_kbytes该文件表示强制Linux VM最低保留多少空闲内存（Kbytes）。缺省设置：724（512M物理内存） 8) /proc/sys/vm/nr_pdflush_threads该文件表示当前正在运行的pdflush进程数量，在I/O负载高的情况下，内核会自动增加更多的pdflush进程。缺省设置：2（只读） 9) /proc/sys/vm/overcommit_memory该文件指定了内核针对内存分配的策略，其值可以是0、1、2。0， 表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；否则，内存申请失败，并把错误返回给应用进程。1， 表示内核允许分配所有的物理内存，而不管当前的内存状态如何。2， 表示内核允许分配超过所有物理内存和交换空间总和的内存（参照overcommit_ratio）。缺省设置：0 10) /proc/sys/vm/overcommit_ratio该文件表示，如果overcommit_memory=2，可以过载内存的百分比，通过以下公式来计算系统整体可用内存。系统可分配内存=交换空间+物理内存*overcommit_ratio/100缺省设置：50（%） 11) /proc/sys/vm/page-cluster该文件表示在写一次到swap区的时候写入的页面数量，0表示1页，1表示2页，2表示4页。缺省设置：3（2的3次方，8页） 12) /proc/sys/vm/swapiness该文件表示系统进行交换行为的程度，数值（0-100）越高，越可能发生磁盘交换。缺省设置：60 13) legacy_va_layout该文件表示是否使用最新的32位共享内存mmap()系统调用，Linux支持的共享内存分配方式包括mmap()，Posix，System VIPC。0， 使用最新32位mmap()系统调用。1， 使用2.4内核提供的系统调用。缺省设置：0 14) nr_hugepages该文件表示系统保留的hugetlb页数。 15) hugetlb_shm_group该文件表示允许使用hugetlb页创建System VIPC共享内存段的系统组ID。 /proc/sys/fs/优化 1) /proc/sys/fs/file-max该文件指定了可以分配的文件句柄的最大数目。如果用户得到的错误消息声明由于打开文件数已经达到了最大值，从而他们不能打开更多文件，则可能需要增加该值。缺省设置：4096建议设置：65536 2) /proc/sys/fs/file-nr该文件与 file-max 相关，它有三个值：已分配文件句柄的数目已使用文件句柄的数目文件句柄的最大数目该文件是只读的，仅用于显示信息。 /proc/sys/net/core/优化 该目录下的配置文件主要用来控制内核和网络层之间的交互行为。1） /proc/sys/net/core/message_burst写新的警告消息所需的时间（以 1 / 10 秒为单位）；在这个时间内系统接收到的其它警告消息会被丢弃。这用于防止某些企图用消息“淹没”系统的人所使用的拒绝服务（Denial of Service）攻击。缺省设置：50（5秒） 2） /proc/sys/net/core/message_cost该文件表示写每个警告消息相关的成本值。该值越大，越有可能忽略警告消息。缺省设置：5 3） /proc/sys/net/core/rmem_default该文件指定了接收套接字缓冲区大小的缺省值（以字节为单位）。缺省设置：110592 4） /proc/sys/net/core/rmem_max该文件指定了接收套接字缓冲区大小的最大值（以字节为单位）。缺省设置：131071 /proc/sys/net/ipv4/优化 1) /proc/sys/net/ipv4/ip_forward该文件表示是否打开IP转发。0，禁止1，转发缺省设置：0 2) /proc/sys/net/ipv4/ip_default_ttl该文件表示一个数据报的生存周期（Time To Live），即最多经过多少路由器。缺省设置：64增加该值会降低系统性能。 3) /proc/sys/net/ipv4/ip_no_pmtu_disc该文件表示在全局范围内关闭路径MTU探测功能。缺省设置：0 4) /proc/sys/net/ipv4/route/min_pmtu该文件表示最小路径MTU的大小。缺省设置：552 5) /proc/sys/net/ipv4/route/mtu_expires该文件表示PMTU信息缓存多长时间（秒）。缺省设置：600（秒） 6) /proc/sys/net/ipv4/route/min_adv_mss该文件表示最小的MSS（Maximum Segment Size）大小，取决于第一跳的路由器MTU。缺省设置：256（bytes） IP Fragmentation 1) /proc/sys/net/ipv4/ipfrag_low_thresh/proc/sys/net/ipv4/ipfrag_low_thresh两个文件分别表示用于重组IP分段的内存分配最低值和最高值，一旦达到最高内存分配值，其它分段将被丢弃，直到达到最低内存分配值。缺省设置：196608（ipfrag_low_thresh）　　　　　262144（ipfrag_high_thresh） 2) /proc/sys/net/ipv4/ipfrag_time该文件表示一个IP分段在内存中保留多少秒。缺省设置：30（秒） INET Peer Storage 1) /proc/sys/net/ipv4/inet_peer_thresholdINET对端存储器某个合适值，当超过该阀值条目将被丢弃。该阀值同样决定生存时间以及废物收集通过的时间间隔。条目越多，存活期越低，GC 间隔越短。缺省设置：65664 2) /proc/sys/net/ipv4/inet_peer_minttl条目的最低存活期。在重组端必须要有足够的碎片(fragment)存活期。这个最低存活期必须保证缓冲池容积是否少于 inet_peer_threshold。该值以 jiffies为单位测量。缺省设置：120 3) /proc/sys/net/ipv4/inet_peer_maxttl条目的最大存活期。在此期限到达之后，如果缓冲池没有耗尽压力的话(例如：缓冲池中的条目数目非常少)，不使用的条目将会超时。该值以 jiffies为单位测量。缺省设置：600 4) /proc/sys/net/ipv4/inet_peer_gc_mintime废物收集(GC)通过的最短间隔。这个间隔会影响到缓冲池中内存的高压力。 该值以 jiffies为单位测量。缺省设置：10 5) /proc/sys/net/ipv4/inet_peer_gc_maxtime废物收集(GC)通过的最大间隔，这个间隔会影响到缓冲池中内存的低压力。 该值以 jiffies为单位测量。缺省设置：120 6) /proc/sys/net/ipv4/tcp_keepalive_time该文件表示从不再传送数据到向连接上发送保持连接信号之间所需的秒数。缺省设置：7200（2小时） 7) /proc/sys/net/ipv4/tcp_orphan_retries在近端丢弃TCP连接之前，要进行多少次重试。默认值是 7 个，相当于 50秒–16分钟，视 RTO 而定。如果您的系统是负载很大的web服务器，那么也许需要降低该值，这类 sockets 可能会耗费大量的资源。另外参考tcp_max_orphans。 8) /proc/sys/net/ipv4/tcp_abort_on_overflow当守护进程太忙而不能接受新的连接，就向对方发送reset消息，默认值是false。这意味着当溢出的原因是因为一个偶然的猝发，那么连接将恢复状态。只有在你确信守护进程真的不能完成连接请求时才打开该选项，该选项会影响客户的使用。缺省设置：0 9) /proc/sys/net/ipv4/tcp_stdurg使用 TCP urg pointer 字段中的主机请求解释功能。大部份的主机都使用老旧的BSD解释，因此如果您在 Linux 打开它，或会导致不能和它们正确沟通。缺省设置：0 10) /proc/sys/net/ipv4/tcp_fack该文件表示是否打开FACK拥塞避免和快速重传功能。缺省设置：1 11) /proc/sys/net/ipv4/tcp_dsack该文件表示是否允许TCP发送“两个完全相同”的SACK。缺省设置：1 12) /proc/sys/net/ipv4/tcp_ecn该文件表示是否打开TCP的直接拥塞通告功能。缺省设置：0 13) /proc/sys/net/ipv4/tcp_reordering该文件表示TCP流中重排序的数据报最大数量。缺省设置：3 14) /proc/sys/net/ipv4/tcp_retrans_collapse该文件表示对于某些有bug的打印机是否提供针对其bug的兼容性。缺省设置：1 15) /proc/sys/net/ipv4/tcp_app_win该文件表示保留max(window/2^tcp_app_win, mss)数量的窗口由于应用缓冲。当为0时表示不需要缓冲。缺省设置：31 16) /proc/sys/net/ipv4/tcp_adv_win_scale该文件表示计算缓冲开销bytes/2^tcp_adv_win_scale(如果tcp_adv_win_scale >; 0)或者bytes-bytes/2^(-tcp_adv_win_scale)(如果tcp_adv_win_scale 缺省设置：2 17) /proc/sys/net/ipv4/ip_nonlocal_bind该文件表示是否允许进程邦定到非本地地址。缺省设置：0 18) /proc/sys/net/ipv4/ip_dynaddr该参数通常用于使用拨号连接的情况，可以使系统动能够立即改变ip包的源地址为该ip地址，同时中断原有的tcp对话而用新地址重新发出一个syn请求 包，开始新的tcp对话。在使用ip欺骗时，该参数可以立即改变伪装地址为新的ip地址。该文件表示是否允许动态地址，如果该值非0，表示允许；如果该值 大于1，内核将通过log记录动态地址重写信息。缺省设置：0 19) /proc/sys/net/ipv4/icmp_ratelimit 20) /proc/sys/net/ipv4/icmp_ratemask 21) /proc/sys/net/ipv4/icmp_ignore_bogus_error_reponses某些路由器违背RFC1122标准，其对广播帧发送伪造的响应来应答。这种违背行为通常会被以告警的方式记录在系统日志中。如果该选项设置为True，内核不会记录这种警告信息。缺省设置：0 22) /proc/sys/net/ipv4/igmp_max_memberships该文件表示多播组中的最大成员数量。缺省设置：20 Other Configuration 1) /proc/sys/net/ipv4/*/accept_source_route是否接受含有源路由信息的ip包。参数值为布尔值，1表示接受，0表示不接受。在充当网关的linux主机上缺省值为1，在一般的linux主机上缺省值为0。从安全性角度出发，建议关闭该功能。 2) /proc/sys/net/ipv4//secure_redirects其实所谓的“安全重定向”就是只接受来自网关的“重定向”icmp包。该参数就是用来设置“安全重定向”功能的。参数值为布尔值，1表示启用，0表示禁止，缺省值为启用。 3) /proc/sys/net/ipv4//proxy_arp设置是否对网络上的arp包进行中继。参数值为布尔值，1表示中继，0表示忽略，缺省值为0。该参数通常只对充当路由器的linux主机有用。 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-12-28 10:38:51 "},"Linux_high_avaliability.html":{"url":"Linux_high_avaliability.html","title":"高可用汇总","keywords":"","body":"LVS 概念与原理https://blog.csdn.net/weixin_43314056/article/details/86674517https://blog.csdn.net/Running_free/article/details/77981201https://blog.csdn.net/shudaqi2010/article/details/58594501https://www.imooc.com/article/21560 LVS+keepalived的例子https://blog.51cto.com/renlifeng/1276234https://blog.51cto.com/beyondhdf/1331874https://blog.csdn.net/u012852986/article/details/52386306https://blog.csdn.net/u012852986/article/details/52412174 有关LVS的4种模式---NAT, DR, tunnel 加上后出现的Full-NAT: NAT适用于有端口转换(映射)需求的场景,NAT模式下的Director 成为real_server的网关,real_server将自己的gateway指向Director , 同时流入的请求包与从real_server应答包都由NAT模式的Director 进出. DR模式只处理流入的请求包,real_server应答包直接返回给来源.不可转换端口.Director 和 real_server需要在同一vlan下,且不可由一台机器同时扮演Director 和 real_server Tunnel 模式只处理流入的请求包,real_server应答包直接返回给来源.不可转换端口.可以跨越 lan / wan 10种算法 加权最少连接优先wlc是默认算法,其余算法介绍已足够详细 ipvsadm是LVS配置管理工具ipvsadm -ln 列出当前工作的条目ipvsadm -C 清除当前配置ipvsadm -S 用于列出当前配置,其内容可以重定向写入文件中,用于ipvsadm启动时的恢复设置所用 keepalived 官网和手册( 实际上也就是man里的内容,比较欠缺实例结合 )https://www.keepalived.org/download.htmlhttps://www.keepalived.org/manpage.html 适合入手的文章https://blog.51cto.com/xuweitao/1953167http://www.voidcn.com/article/p-bnfpdubt-vm.htmlhttps://blog.csdn.net/LL845876425/article/details/82084560https://my.oschina.net/hncscwc/blog/158746https://peiqiang.net/2014/11/21/keepalived-and-redis.htmlhttps://blog.csdn.net/qq_26545305/article/details/79957992https://blog.51cto.com/lansgg/1179636 keepalived的配置文件实际包含对LVS的配置,如果先行单独配置ipvsadm,则keepalived进程在启动时也会根据keepalived配置文件中定义的LVS配置对ipvsadm进行覆盖 关于vrrp_script配置vrrp_script只能用于检测vrrp_instance, 是对Director 的操作,而非real_server keepalived对real_server的几种健康检查方式在帮助文档给出了以下方式HTTP_GET|SSL_GET|TCP_CHECK|SMTP_CHECK|DNS_CHECK|MISC_CHECK HTTP|SSL_GET和TCP方式都给出了一定的例子, 如果可以满足需求, 则帮助文档基本够用 MISC_CHECK 则是外部检查脚本, 针对real_server的健康检查方式 其中misc_dynamic项, 在帮助文档中给出了以下说明exit status 0: svc check success, weight unchanged.exit status 1: svc check failed.exit status 2-255: svc check success, weight changed to 2 less than exit status.退出值为0: 权重不变退出值为1: 检查失败退出值为2-255: 检查成功,但权重改变为2到退出值之间的值 MISC_CHECK 除此之外还有warmup 可选项,进行健康检查前的延迟时间user USERNAME [GROUPNAME] 运行健康检查脚本的用户身份 比较繁琐的在于MISC_CHECK脚本在Director上,对后端real_server的健康检查涉及配置文件简化脚本文件数量---则需要传参形式定义健康检查脚本文件的调度,涉及在keepalived配置文件中的配置简化keepalived配置文件---则需要对健康检查脚本文件作不同对象的配置. 另外一个思路就是,详细的健康检查只在real_server自身上进行,keepalived的Director上只作简单的服务可用性检查 关于LVS Nginx HAProxy 对比的文章 http://www.ha97.com/5646.htmlhttps://www.cnblogs.com/yangmingxianshen/p/8426847.htmlhttps://blog.csdn.net/u010285974/article/details/86750527http://www.linkedkeeper.com/135.htmlhttp://www.magedu.com/74265.htmlhttps://www.cnblogs.com/kevingrace/p/5892169.html 观点足够丰富了, 再作进一步提炼:LVS 分发TCP/UDP流量,决定了它可以支撑更大的负载量; 同时也决定了它无法满足应用层更精细的控制HAproxy 可以工作在第四/七层,可以实现更精细的控制; 承载能力弱于LVS, 但也足够优秀.高于nginx.Nginx 纯粹工作于第七层应用层, 对web程序员更友好, 适用于web服务内部的流转与控制. HAproxy http://www.haproxy.org/http://cbonte.github.io/haproxy-dconv/1.9/intro.html 质量较高的文章https://blog.51cto.com/leejia/1421882 有讲到统计页面的配置方法https://www.cnblogs.com/f-ck-need-u/p/8502593.html#1-1-https://segmentfault.com/a/1190000007532860 一般上手的文章https://blog.51cto.com/jerry12356/1858243https://www.howtoing.com/install-and-configure-haproxy-on-centoshttps://blog.csdn.net/a355586533/article/details/54345958 HAproxy的8种算法与Session保持https://blog.csdn.net/hexieshangwang/article/details/49617273https://www.cnblogs.com/f-ck-need-u/p/8553190.html HAproxy的ACLhttps://www.cnblogs.com/f-ck-need-u/p/8502593.html#1-5-aclhttps://www.jianshu.com/p/cd80f5f9ec1b因为支持正则,所以可以实现网站应用动静分离等场景.关于ACL的配置语句 这一示例是其中一种语法,语法有多种 HAproxy的健康检查方式https://www.cnblogs.com/breezey/p/4680418.html有3种内置的健康检查方式,不支持外部脚本方式.其中:通过监听端口进行健康检测——粒度太粗, 实用性太低通过URI获取进行健康检测——检测方式, 是用过去GET后端server的的web页面. 相比上一种算是好点通过request获取的头部信息进行匹配进行健康检测----感觉也只能和GET页面的方式半斤八两除此以外, 自定义的检查方式如下:http://cbonte.github.io/haproxy-dconv/1.9/configuration.html#3.1-external-check 手册http://www.loadbalancer.org/blog/how-to-write-an-external-custom-healthcheck-for-haproxy/https://codeday.me/bug/20181128/413167.htmlhttps://www.liurongxing.com/haprox-external-check.html传参的问题https://serverfault.com/questions/889424/haproxy-external-check-with-arguments 手册给出的操作步骤也并不是很完整, 缺乏相应示例, 脚本如何返回值等细节也没篇文章完全覆盖到, 有机会再后补 HAproxy的当前工作状态HAproxy内置一个stats的功能,通过web页面可以展示当前HAproxy的一些统计信息. 如下图: 在配置文件的frontend中配置--backend亦可,除配置在gloabl段启动会报错以外,实际也可以配置在listen段.也即可以分离一个虚拟服务一个监控页面 HAproxy自身的高可用HAproxy有不少使用keepalived来做防止单点故障的文章,需要明确的是,无论是keepalived还是heartbeat都是主备模型,并不存在双主一说,如VIP等资源始终都是其中一台持有.使用keepalived来实现HAproxy自身的高可用则与其他keepalived应用场景相比并无特殊,大多数情况下都需要将LVS+keepalived的机器放置在HAproxy机器的前端.在拓扑图上的结构就是 LVS+keepalived --> HAproxy --> 业务应用使用heartbeat可以实现HAproxy与heartbeat都在同一台机器---虽然也是通过组播来进行心跳通告.满足有这一需求的场景. HAproxy+heartbeat的方式https://www.cnblogs.com/kevingrace/p/10206731.html heartbeat的获取方式1) EPEL源2) http://linux-ha.org/wiki/Downloads yum安装的heartbeat, 在 /etc/ha.d/ 下有: ha.cf： heartbeat主配置文件 haresources： 本地资源文件 authkeys： 认证文件 在介绍HAproxy+heartbeat的文章中讲到heartbeat会监控HAproxy服务,在heartbeat接管服务时也会带起HAproxy haresources配置文件中有如下示例配置语句: ha-master IPaddr::172.16.60.229/24/eth0 haproxy 上面设置ha-maser为主节点, 集群VIP为172.16.60.229, haproxy为所指定需要监视的应用服务. 对HAproxy的监控与需要启动时的启动操作的具体实现方法有待进一步验证--因为haproxy只是一个名称,具体如何关联对应的执行程序,执行程序不同的人如何对应,未做验证. 核心思想仍然是主机持有服务资源(VIP等) , 主机宕机,备机接管. 主机恢复后,是否抢回资源可配置. LVS+keepalived 和 heartbeat都会面临的脑裂问题 针对脑裂这一问题,要实现高可靠性, 仲裁节点 / 设备 是必不可少的,以下这两个思路都不错 https://www.zhihu.com/question/50997425针对LVS,使用vrrp_script的方式简单易行,不过只对网关的检测,可靠性是否足够高存疑. https://www.cnblogs.com/kevingrace/p/7205846.html前半部分提了一个自行实现争用锁来实现对服务资源的竞争方式.后半部分与前一篇内容相同.摘录他提的思路:如何防止HA集群脑裂一般采用2个方法1）仲裁当两个节点出现分歧时，由第3方的仲裁者决定听谁的。这个仲裁者，可能是一个锁服务，一个共享盘或者其它什么东西。 2）fencing当不能确定某个节点的状态时，通过fencing把对方干掉，确保共享资源被完全释放，前提是必须要有可靠的fence设备。 理想的情况下，以上两者一个都不能少。但是，如果节点没有使用共享资源，比如基于主从复制的数据库HA，也可以安全的省掉fence设备，只保留仲裁。而且很多时候我们的环境里也没有可用的fence设备，比如在云主机里。 那么可不可以省掉仲裁，只留fence设备呢？不可以。因为，当两个节点互相失去联络时会同时fencing对方。如果fencing的方式是reboot，那么两台机器就会不停的重启。如果fencing的方式是power off，那么结局有可能是2个节点同归于尽，也有可能活下来一个。但是如果两个节点互相失去联络的原因是其中一个节点的网卡故障，而活下来的正好又是那个有故障的节点，那么结局一样是悲剧。所以，单纯的双节点，无论如何也防止不了脑裂。 如何实现上面的策略可以自己完全从头开始实现一套符合上述逻辑的脚本。推荐使用基于成熟的集群软件去搭建，比如Pacemaker+Corosync+合适的资源Agent。Keepalived不太适合用于有状态服务的HA，即使把仲裁和fence那些东西都加到方案里，总觉得别扭。 使用Pacemaker+Corosync的方案也有一些注意事项1）了解资源Agent的功能和原理了解资源Agent的功能和原理，才能知道它适用的场景。比如pgsql的资源Agent是比较完善的，支持同步和异步流复制，并且可以在两者之前自动切换，并且可以保证同步复制下数据不会丢失。但目前MySQL的资源Agent就很弱了，没有使用GTID又没有日志补偿，很容易丢数据，还是不要用的好，继续用MHA吧（但是，部署MHA时务必要防范脑裂）。 2）确保法定票数(quorum)quorum可以认为是Pacemkaer自带的仲裁机制，集群的所有节点中的多数选出一个协调者，集群的所有指令都由这个协调者发出，可以完美的杜绝脑裂问题。为了使这套机制有效运转，集群中至少有3个节点，并且把no-quorum-policy设置成stop，这也是默认值。（很多教程为了方便演示，都把no-quorum-policy设置成ignore，生产环境如果也这么搞，又没有其它仲裁机制，是很危险的！） 但是，如果只有2个节点该怎么办？ 一是拉一个机子借用一下凑足3个节点，再设置location限制，不让资源分配到那个节点上。二是把多个不满足quorum小集群拉到一起，组成一个大的集群，同样适用location限制控制资源的分配的位置。但是如果你有很多双节点集群，找不到那么多用于凑数的节点，又不想把这些双节点集群拉到一起凑成一个大的集群（比如觉得不方便管理）。那么可以考虑第三种方法。第三种方法是配置一个抢占资源，以及服务和这个抢占资源的colocation约束，谁抢到抢占资源谁提供服务。这个抢占资源可以是某个锁服务，比如基于zookeeper包装一个，或者干脆自己从头做一个，就像下面这个例子。这个例子是基于http协议的短连接，更细致的做法是使用长连接心跳检测，这样服务端可以及时检出连接断开而释放锁）但是，一定要同时确保这个抢占资源的高可用，可以把提供抢占资源的服务做成lingyig高可用的，也可以简单点，部署3个服务，双节点上个部署一个，第三个部署在另外一个专门的仲裁节点上，至少获取3个锁中的2个才视为取得了锁。这个仲裁节点可以为很多集群提供仲裁服务（因为一个机器只能部署一个Pacemaker实例，否则可以用部署了N个Pacemaker实例的仲裁节点做同样的事情。但是，如非迫不得已，尽量还是采用前面的方法，即满足Pacemaker法定票数，这种方法更简单，可靠。 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-09-28 11:48:45 "},"Linux_ansible.html":{"url":"Linux_ansible.html","title":"ansible","keywords":"","body":"手册资料 Ansible中文权威指南http://ansible-tran.readthedocs.io/en/latest/index.html 介绍了ansible配置中的各参数含义https://micorochio.github.io/2017/05/31/ansible-learning-01/ 免密连接受控端 实际上就是配置ssh免密码的操作1) ansible控制端ssh-keygen生成密钥对---密钥打开口令为空(没有特殊要求的情况下)2) ansible控制端ssh-copy-id把自己的公钥上传到受控客户端 或 复制pub公钥里的文本内容到 /${HOME}/.ssh/authorized_keys3) 此时ansible控制端sshh登录受控客户端已不需要验证口令.再配置ansible上的hosts项,在条目中指明ansible控制端生成的私钥位置至此,ansible免密操作受控客户端完成 有密码连接受控端 实际的生产环境中, 极大概率是普通用户连接, 需要切换为root提权的情况 以下是使用ansible的su方式, 成为root身份的配置方式之一, 写入inventory清单里的内容 [lab] 192.168.10.101 ansible_ssh_user=\"user\" ansible_ssh_port=22 ansible_ssh_pass=user用户的密码 ansible_become=true ansible_become_method=su ansible_become_user=root ansible_become_pass=root用户的密码 192.168.10.102 ansible_ssh_user=\"user\" ansible_ssh_port=22 ansible_ssh_pass=user用户的密码 ansible_become=true ansible_become_method=su ansible_become_user=root ansible_become_pass=root用户的密码 在命令行下执行su的操作方式 https://lvii.github.io/system/2020-02-26-ansible-run-command-with-su-root/ ansible -i /etc/ansible/lab lab -m shell -a 'id' --become --become-user=root --become-method=su --ask-become-pass --ask-become-pass 是交互方式输入 首次连接免去回答是否添加key到konwn_hosts 在ansible的默认配置文件/etc/ansible/ansible.cfg中方法一:取消ssh_args 的注释,并且添加 StrictHostKeyChecking＝nossh_args = -o ControlMaster=auto -o ControlPersist=60s -o StrictHostKeyChecking＝no 方法二:取消注释host_key_checking = False playbook的一个简单示例 一个简单的yaml文件的内容 - hosts: lab gather_facts: no tasks: - name: \"test_command\" shell: id; ip a hosts: lab 是执行的对象, lab是预先在inventory定义的分组 gather_facts: no 不执行ansible的fact信息收集, fact信息收集的耗时可达10几秒乃至更高. 有关fact的内容单独列出 tasks 下的name 任务名称, 用于后续了解进度时的显示tasks 下的shell 执行的模块名称, 这里选择的是ansible的shell模块 playbook将执行回显显示出来 https://www.codenong.com/20563639/ - hosts: lab gather_facts: no tasks: - name: \"test_command\" shell: id; ip a register: output - debug: var=output.stdout_lines 在目标任务增加一项register: output register是使用变量来存放输出, output是自定义的变量名称   接下另起一行, 精简内容就不用起任务名debug: var=output.stdout_linesdebug 是模块名称, 将output的stdout_lines赋给var, 而这个过程就能触发debug打印其内容. 显示的内容样式如下: playbook 加速执行的几个技巧 http://github.com/jlafon/ansible-profile 关闭 gathering factsyaml执行对象下添加 gather_facts: no 启用SSH PIPElinINGSSH PIPElinING 是一个加速 Ansible 执行速度的简单方法它ansible.cfg里的注释如下: Enabling pipelining reduces the number of SSH operations required to execute a module on the remote server. This can result in a significant performance improvement when enabled, however when using \"sudo:\" you must first disable 'requiretty' in /etc/sudoers By default, this option is disabled to preserve compatibility with sudoers configurations that have requiretty (the default on many distros). 启用ControlPersistControlPersist 即持久化 socket，一次验证，多次通信 注意是ssh客户端, 也就是ansible的server所在机器上的ssh_config cat ~/.ssh/config Host * Compression yes ServerAliveInterval 60 ServerAliveCountMax 5 ControlMaster auto ControlPath ~/.ssh/sockets/%r@%h-%p ControlPersist 4h 新增的是 ControlPersist 4h 为playbook 增加一个显示执行时间的插件 https://github.com/jlafon/ansible-profile ansible 2.0 已内置, 只需要在ansible.cfg 中启用 callback_whitelist = profile_tasks ansible 1.x 里的用法是, 下载这个python脚本, 在你的playbook所在的目录下, 新建一个callback_plugins 目录, 并放入这个python脚本 mkdir callback_plugins cd callback_plugins wget https://raw.githubusercontent.com/jlafon/ansible-profile/master/callback_plugins/profile_tasks.py ansible配置文件ansible.cfg参数含义 # (扩展插件存放目录) action_plugins = /usr/share/ansible_plugins/action_plugins # (插入Ansible模板的字符串) ansible_managed = Ansible managed: {file} modified on %Y-%m-%d %H:%M:%S by {uid} on {host} # （PlayBook是否需要提供密码，默认为No） # ask_pass=True # （PlayBook是否需要提供sudo 密码） # ask_sudo_pass=True # （回调函数插件存放路径） action_plugins = /usr/share/ansible_plugins/action_plugins # （连接插件存放路径） action_plugins = /usr/share/ansible_plugins/action_plugins # （是否展示警告信息） deprecation_warnings = True # （是否展示跳过的主机的信息） # display_skipped_hosts=True # （执行错误时候赋予的变量） # error_on_undefined_vars=True # （默认的Shell） # executable = /bin/bash # （拦截器插件） action_plugins = /usr/share/ansible_plugins/action_plugins # （最大进程数） forks=5 # （哈希特性，没事不用去动它） # hash_behavior=replace # （资产文件存放位置） hostfile = /etc/ansible/hosts # （是否检查SSH key） host_key_checking=True # （JinJa扩展） jinja2_extensions = jinja2.ext.do,jinja2.ext.i18n # （PlayBook变量） legacy_playbook_variables = no # （Ansible默认库） library = /usr/share/ansible # （日志路径） log_path=/var/log/ansible.log # （插件路径） action_plugins = /usr/share/ansible_plugins/action_plugins # （默认模块名称） module_name = command # (输出样式) nocolor=0 # (是否使用cowsay打印) nocows=0 # （主机） hosts=* # （pool间隔） poll_interval=15 # （私钥的存放路径） private_key_file=/path/to/file.pem # （远程连接端口号） remote_port = 22 # (远程目录临时文件夹) remote_temp = $HOME/.ansible/tmp # （远程用户） remote_user = root # （角色路径） roles_path = /opt/mysite/roles # （SUDO执行） sudo_exe=sudo # （SUDO标记） sudo_flags=-H # （sudo用户） sudo_user=root # （重连次数） timeout = 10 # （传输模式） 默认用的smart transport # （变量插件存放路径） action_plugins = /usr/share/ansible_plugins/action_plugins # SSH变量 # (SSH连接参数) ssh_args = -o ControlMaster=auto -o ControlPersist=60s # （采用SCP还是SFTP进行文件传输） scp_if_ssh=False Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-10-12 16:38:07 "},"Linux_bond_config.html":{"url":"Linux_bond_config.html","title":"bond配置","keywords":"","body":"Red Hat 目前主推的nmcli 命令行方式 文章链接 使用 NETWORKMANAGER 命令行工具 NMCLI nmcli 命令方式配置bond 与 team模式的bond 文章链接文章链接文章链接文章链接文章链接 nmcli 最大的理念变化是将物理网卡的配置文件与相应的IP配置分离开, 方便在各种配置中切换. nmcli 配置bond 模式, 与传统的手工配置方式并无多少不同, 由nmcli 写出来的配置文件也一样, 唯一就是device 与 NAME 两项上的不同. nmcli 配置team 模式最大的区别据称是 team将这个组合出来的设备当作一个对象 team方式操作基本步骤 # nmcli 查看管理对象 nmcli connection show # 添加一个配置文件的实例对象,con-name 可以理解为别名,ifname是接口文件名称,需要与物理设备保持 nmcli connection add con-name team0 type team ifname team0 config '{\"runner\":{\"name\":\"lacp\"}}' # IP设置,关于ipv4.method 可以将manual 换为不存在的如help 之类的以查看帮助 nmcli connection mod team0 ipv4.addresses 192.168.0.111/24 ipv4.gateway 192.168.0.1 ipv4.method manual # 检查添加出来的设备信息 nmcli connection show team0 nmcli connection show team0 | grep method # 检查写出来的配置文件 ll /etc/sysconfig/network-scripts/ifcfg-team0 cat /etc/sysconfig/network-scripts/ifcfg-team0 # 添加从属的slave网卡进team组 nmcli connection add con-name team0-ens37 ifname ens37 type team-slave master team0 autoconnect yes nmcli connection add con-name team0-ens38 ifname ens38 type team-slave master team0 autoconnect yes # 激活配置,team对象与其slave都得手动激活 nmcli connection down team0; nmcli connection up team0 nmcli connection up team0-ens37 nmcli connection up team0-ens38 # 从teamctl 查看 team组的状态--传统方式从/proc/net/bonding/xxx 查看 teamdctl team0 state # 必要的,否则设置autoconnect yes 依然在重启后不会自动加载 nmcli connection reload 简版--双网卡bond配置 红帽6系http://blog.51cto.com/lixin15/1769338 红帽7系在6系基础上多一点内容 http://blog.51cto.com/12259095/1869795 https://www.cnblogs.com/gaohong/p/4900744.html 总结归纳: /etc/modprobe.conf 需要添加的内容 alias bond0 bonding options bond0 miimon=100 mode=0 加载bond module modprobe bonding 但模块即使加载后,重启一次依然无法避免 bond下的slave网卡的配置文件需要的字段 MASTER=bond0 SLAVE=yes bond自身的配置文件 DEVICE=bond0 IPADDR=10.0.0.10 NETMASK=255.255.255.0 GATEWAY=10.0.0.2 # 红帽7系还多以下两条 -- 必须有此两项,否则bond配置依旧存在问题 BONDING_OPTS=\"miimon=100 mode=1\" BONDING_MASTER=yes miimon是用来进行链路监测的。比如：miimon=100，单位是ms(毫秒)这边的100，是100ms，即是0.1秒那么系统每100ms监测一次链路连接状态，如果有一条线路不通就转入另一条线路； mode共有七种(0~6)，这里解释两个常用的选项。 mode=0：表示load balancing (round-robin)为负载均衡方式，两块网卡都在工作。 mode=1：表示fault-tolerance (active-backup)提供冗余功能，工作方式是主备的工作方式，其中一块网卡在工作（若eth0断掉），则自动切换到另一个块网卡（eth1做备份）。 内核里的bond状态 /proc/net/bonding/bond0 bond的7种模式 1、mode=0(balance-rr)(平衡抡循环策略) 链路负载均衡，增加带宽，支持容错，一条链路故障会自动切换正常链路。交换机需要配置聚合口，思科叫port channel。 特点：传输数据包顺序是依次传输（即：第1个包走eth0，下一个包就走eth1….一直循环下去，直到最后一个传输完毕），此模式提供负载平衡和容错能力；但是我们知道如果一个连接 或者会话的数据包从不同的接口发出的话，中途再经过不同的链路，在客户端很有可能会出现数据包无序到达的问题，而无序到达的数据包需要重新要求被发送，这样网络的吞吐量就会下降 2、mode=1(active-backup)(主-备份策略) 这个是主备模式，只有一块网卡是active，另一块是备用的standby，所有流量都在active链路上处理，交换机配置的是捆绑的话将不能工作，因为交换机往两块网卡发包，有一半包是丢弃的。 特点：只有一个设备处于活动状态，当一个宕掉另一个马上由备份转换为主设备。mac地址是外部可见得，从外面看来，bond的MAC地址是唯一的，以避免switch(交换机)发生混乱。 此模式只提供了容错能力；由此可见此算法的优点是可以提供高网络连接的可用性，但是它的资源利用率较低，只有一个接口处于工作状态，在有 N 个网络接口的情况下，资源利用率为1/N 3、mode=2(balance-xor)(平衡策略) 表示XOR Hash负载分担，和交换机的聚合强制不协商方式配合。（需要xmit_hash_policy，需要交换机配置port channel） 特点：基于指定的传输HASH策略传输数据包。缺省的策略是：(源MAC地址 XOR 目标MAC地址) % slave数量。其他的传输策略可以通过xmit_hash_policy选项指定，此模式提供负载平衡和容错能力 4、mode=3(broadcast)(广播策略) 表示所有包从所有网络接口发出，这个不均衡，只有冗余机制，但过于浪费资源。此模式适用于金融行业，因为他们需要高可靠性的网络，不允许出现任何问题。需要和交换机的聚合强制不协商方式配合。 特点：在每个slave接口上传输每个数据包，此模式提供了容错能力 5、mode=4(802.3ad)(IEEE 802.3ad 动态链接聚合) 表示支持802.3ad协议，和交换机的聚合LACP方式配合（需要xmit_hash_policy）.标准要求所有设备在聚合操作时，要在同样的速率和双工模式，而且，和除了balance-rr模式外的其它bonding负载均衡模式一样，任何连接都不能使用多于一个接口的带宽。 特点：创建一个聚合组，它们共享同样的速率和双工设定。根据802.3ad规范将多个slave工作在同一个激活的聚合体下。 外出流量的slave选举是基于传输hash策略，该策略可以通过xmit_hash_policy选项从缺省的XOR策略改变到其他策略。需要注意的 是，并不是所有的传输策略都是802.3ad适应的， 尤其考虑到在802.3ad标准43.2.4章节提及的包乱序问题。不同的实现可能会有不同的适应 性。 必要条件： 条件1：ethtool支持获取每个slave的速率和双工设定 条件2：switch(交换机)支持IEEE 802.3ad Dynamic link aggregation 条件3：大多数switch(交换机)需要经过特定配置才能支持802.3ad模式 6、mode=5(balance-tlb)(适配器传输负载均衡) 是根据每个slave的负载情况选择slave进行发送，接收时使用当前轮到的slave。该模式要求slave接口的网络设备驱动有某种ethtool支持；而且ARP监控不可用。 特点：不需要任何特别的switch(交换机)支持的通道bonding。在每个slave上根据当前的负载（根据速度计算）分配外出流量。如果正在接受数据的slave出故障了，另一个slave接管失败的slave的MAC地址。 必要条件： ethtool支持获取每个slave的速率 7、mode=6(balance-alb)(适配器适应性负载均衡) 在5的tlb基础上增加了rlb(接收负载均衡receive load balance).不需要任何switch(交换机)的支持。接收负载均衡是通过ARP协商实现的. 特点：该模式包含了balance-tlb模式，同时加上针对IPV4流量的接收负载均衡(receive load balance, rlb)，而且不需要任何switch(交换机)的支持。接收负载均衡是通过ARP协商实现的。bonding驱动截获本机发送的ARP应答，并把源硬件地址改写为bond中某个slave的唯一硬件地址，从而使得不同的对端使用不同的硬件地址进行通信。 来自服务器端的接收流量也会被均衡。当本机发送ARP请求时，bonding驱动把对端的IP信息从ARP包中复制并保存下来。当ARP应答从对端到达 时，bonding驱动把它的硬件地址提取出来，并发起一个ARP应答给bond中的某个slave。 使用ARP协商进行负载均衡的一个问题是：每次广播 ARP请求时都会使用bond的硬件地址，因此对端学习到这个硬件地址后，接收流量将会全部流向当前的slave。这个问题可以通过给所有的对端发送更新 （ARP应答）来解决，应答中包含他们独一无二的硬件地址，从而导致流量重新分布。 当新的slave加入到bond中时，或者某个未激活的slave重新 激活时，接收流量也要重新分布。接收的负载被顺序地分布（round robin）在bond中最高速的slave上 当某个链路被重新接上，或者一个新的slave加入到bond中，接收流量在所有当前激活的slave中全部重新分配，通过使用指定的MAC地址给每个 client发起ARP应答。下面介绍的updelay参数必须被设置为某个大于等于switch(交换机)转发延时的值，从而保证发往对端的ARP应答 不会被switch(交换机)阻截。 必要条件： 条件1：ethtool支持获取每个slave的速率； 条件2：底层驱动支持设置某个设备的硬件地址，从而使得总是有个slave(curr_active_slave)使用bond的硬件地址，同时保证每个bond 中的slave都有一个唯一的硬件地址。如果curr_active_slave出故障，它的硬件地址将会被新选出来的 curr_active_slave接管 其实mod=6与mod=0的区别：mod=6，先把eth0流量占满，再占eth1，….ethX；而mod=0的话，会发现2个口的流量都很稳定，基本一样的带宽。而mod=6，会发现第一个口流量很高，第2个口只占了小部分流量。 归纳 mode5和mode6不需要交换机端的设置，网卡能自动聚合。mode4需要支持802.3ad。mode0，mode2和mode3理论上需要静态聚合方式。 但实测中mode0可以通过mac地址欺骗的方式在交换机不设置的情况下不太均衡地进行接收。 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-09-25 11:16:45 "},"Linux_zombie_process.html":{"url":"Linux_zombie_process.html","title":"僵尸进程","keywords":"","body":"引用:https://www.cnblogs.com/Anker/p/3271773.html https://www.cnblogs.com/yuxc/archive/2012/11/04/2753391.html https://blog.csdn.net/LEON1741/article/details/78142269 https://blog.csdn.net/davion_zhang/article/details/48268319 产生的原因 孤儿进程：一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。 僵尸进程：一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。 如果进程不调用wait / waitpid的话， 那么保留的那段信息就不会释放，其进程号就会一直被占用，但是系统所能使用的进程号是有限的，如果大量的产生僵死进程，将因为没有可用的进程号而导致系统不能产生新的进程. 此即为僵尸进程的危害，应当避免。 任何一个子进程(init除外)在exit()之后，并非马上就消失掉，而是留下一个称为僵尸进程(Zombie)的数据结构，等待父进程处理。这是每个 子进程在结束时都要经过的阶段。如果子进程在exit()之后，父进程没有来得及处理，这时用ps命令就能看到子进程的状态是“Z”。如果父进程能及时 处理，可能用ps命令就来不及看到子进程的僵尸状态，但这并不等于子进程不经过僵尸状态。 如果父进程在子进程结束之前退出，则子进程将由init接管。init将会以父进程的身份对僵尸状态的子进程进行处理。 查找方式 ps命令查找参数里多一个大写S, 即给进程的stat位标志 ps auxS ps efS 只显示僵尸状态的进程 ps -ef | grep defunct 从/proc下查看状态通过cat /proc/进程PID/status 进行查看[root@docker ~]# cat /proc/11/status Name: watchdog/0 Umask: 0000 State: S (sleeping) 批量获取僵尸进程awk 可以实现指定的内容匹配才输出, 完整命令会比较冗长.相对简单一点的正则表达式, 利用ps 自定义输出列字段:ps -eo stat,pid,cmd | grep -E \"^[Zz]+ +\" 处理 僵尸进程无法被kill, 因为它本身就一个要exit的进程, 只是依赖的事件未发生之前, 被标记为zombie.由孤儿进程的定义, 如需要清理已有的僵尸进程, 则需要将僵尸进程的父进程结束掉, 使僵尸进程成为孤儿进程, 被init进程接管, 由init进程进行清理. 根治的途径 引用的4篇文章的文章都有用代码演示, 根治的途径不外乎以下几种方式 在父进程创建子进程之前，就向系统申明自己并不会对这个子进程的exit 动作进行任何关注行为，这样的话，子进程一旦退出后，系统就不会去等待父进程的操作，而是直接将该子进程的资源回收掉，也就不会出现僵尸进程了。具体的办法就是，在父进程的初始化函数中，调用这个函数：signal(SIGCHLD,SIG_IGN)； 如果上述语句没来得及调用，也有另外一个办法。那就是在创建完子进程后，用waitpid等待子进程返回，也能达到上述效果； 如果上述两个办法都不愿意采用，那还有一招：在父进程创建子进程的时候，连续调用两次fork()，而且使紧跟的子进程直接退出，使其孙子进程成为孤儿进程，从而init进程将代替父进程来接手，负责清除这个孤儿进程。于是，父进程就无需进行任何的清理行为，系统会自动处理； Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-04 16:00:47 "},"Linux_ulimit_relates.html":{"url":"Linux_ulimit_relates.html","title":"关于ulimit设置","keywords":"","body":"http://jameswxx.iteye.com/blog/2096461 总结得最详细 http://blog.ihipop.info/2011/01/2053.html 简单概括为 1) 修改/etc/security/limits.conf 里的值 2) sshd的配置文件(例: /etc/ssh/sshd_config)应有以下两条 UsePAM yes UseLogin yes 3) 检查以下三个文件(通常 /etc/pam.d/sshd就应有效) /etc/pam.d/login /etc/pam.d/system-auth /etc/pam.d/sshd 是否已有以下内容 session required pam_limits.so (必要时也可以指定详细路径,如/lib64/security/pam_limits.so) 另外确保/etc/pam.d/system-auth文件有下面内容 session required /lib/security/$ISA/pam_limits.so 这一行确保系统会执行这个限制。 4) 最后,不要在其他文件写死了ulimit，比如:ulimit -n 65535 字段含义 https://www.ibm.com/developerworks/cn/linux/l-cn-ulimit/index.html /etc/security/limits.conf配置格式如下： domain 代表限制的用户对象，可以是：用户名、@用户组名、*（表示所所有用户的默认配置）、% type 代表限制的资源类型，可以是： hard --硬限制，受限用户不可自己通过ulimit动态修改此项的值 soft --软限制，用户自己可以自己使用ulimit加资源对应的参数动态修改此项的值（但其范围要在hard限制范围以内不然无效） --代表软硬两种限制 关于修改了/etc/security/limits.conf, 从会话可见新设置的值,但程序仍可能会引起问题的情况 https://access.redhat.com/solutions/30316 红帽官方文档提到 90-nproc.conf, 但感觉依然没有足够强调 90-nproc.conf 对生效值的机制. In Red Hat Enterprise Linux 6, there's a default setting in /etc/security/limits.d/90-nproc.conf. Change the default limit for all users or add a new limit for the affected user. Root Cause The user fails to log in because an EAGAIN error occurs if the user's number of executing threads has reached the nproc resource limit. Note: Despite the name, this is a limit on threads, not processes. This error may occur if user's nproc limit is set to /etc/security/limits.conf. In Red Hat Enterprise Linux 6, this error occurs even if the limit is not explicitly set because the default configuration for all users is set in /etc/security/limits.d/90-nproc.conf. https://www.cnblogs.com/lsdb/p/7526448.html RHEL6.x版本后引入/etc/security/limits.d/90-nproc.conf用于限制用户打开进程数，与limits.conf的关系是： 如果90-nproc.onf与limits.conf存在相同条目的配置那么90-nproc覆盖limits.conf的配置 但是如果90-nproc.conf用的是*没有指定用户而limits.conf指定用户那么90-nproc的限制不生效. 其实90-nproc.conf除了限制nproc其他资源一样可以限制，生效原则与nproc一样 其实在/etc/security/limit.d目录下你还可以创建其他任意名字的.conf文件，这些文件中首字母ACSII大的覆盖首字母ASCII小的（首字母一样大的比较第二个字母以此类推） 亲测的几个结论 https://www.cnblogs.com/lsdb/p/7526448.html 对此文章观点的验证 结论1: 在RHEL 6上, 90-nproc.conf的存在 * soft nproc 1024 的情况下, 在/etc/security/limits.conf文件中添加 * - nproc 65535 不会改变普通用户的\"max user processes\"即nproc值,此时sshd进程和操作系统分别进行过重启,结果都相同. 此点与我们在生产环境看到的效果不同, 生产环境同样的配置方法,su到weblogic下,ulimit -u看到的max user processes的值是生效的,为65535,但依然出现can not set id: resource temporarily unavilable, 使用ps -u weblogic -L 统计weblogic用户总的线程数为1025 结论2: nproc, 即ulimit命令看到的max user processes的值,对应的是该用户的所有进程+线程的总数,不能只以ps看进程数为参考,要以ps -u 用户名 -L统计该用户的计数为准. 测试方法 1) python代码创建一个无限循环的函数,使其永远不结束2) 主函数以多线程方式调用该函数,数量1300个---为超过10243) 执行python代码---代码抛出异常: thread.error: can't start new thread4) 此时统计该用户的线程总数, ps -u test -L | wc -l, 值为1025. 与生产环境所见结果相同. python代码截图 执行过程抛异常截图 此时统计”test”用户的线程数截图 结论3: /etc/security/limits.conf 与 /etc/security/limits.d/90-nproc.conf 的相互关系 1) 说法: 如果90-nproc.onf与limits.conf存在相同条目的配置那么90-nproc覆盖limits.conf的配置 测试结论: 说法正确 测试方法 /etc/security/limits.conf 与 /etc/security/limits.d/90-nproc.conf 都配置 “* -nproc”项, 但值不同,一个2048,一个65535 此时重新su 到 test用户,会话可见值为2048 python代码实测,创建线程数为2500---为超过2048 2) 说法: 但是如果90-nproc.conf用的是*没有指定用户而limits.conf指定用户, 那么90-nproc的限制不生效 测试结论: 说法正确 测试方法 /etc/security/limits.d/90-nproc.conf 保持 “* soft nproc 2048” 不变 /etc/security/limits.conf 同时存在两条 * -nproc 65535 test -nproc 10240 此时,su到test用户,可见值为10240 python代码实测,线程数13000---为超过10240 此时test用户的线程总数10241 综上: 1) 如果不希望改变/etc/security/limits.d/90-nproc.conf的内容, 则需要改大nproc时,在/etc/security/limits.conf 中就必须明确指明用户名, 如: weblogic -nproc 65535 2) 反之, 注释 /etc/security/limits.d/90-nproc.conf 中的 “ * soft nproc 1024” 和 删除(重命名) /etc/security/limits.d/90-nproc.conf 文件 都可以使 /etc/security/limits.conf 中 以” * -nproc 65535”方式配置的值生效 3) RHEL 7不存在90-nproc.conf,但存在/etc/security/limits.d/20-nproc.conf, 机制相同,默认值由1024变为了4096 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-02-08 10:33:16 "},"Linux_tcpdump_and_wireshark.html":{"url":"Linux_tcpdump_and_wireshark.html","title":"tcpdump与wireshark在排错中的应用","keywords":"","body":"tcpdump参数介绍: http://www.ha97.com/4550.html https://blog.51cto.com/victor1980/701764 示例 tcpdump -i any src host 192.168.10.2 and dst host 192.168.10.3 and dst port 22 -e -v -tttt -n -nn -c 10 -S 选用的参数含义介绍: -c 在收到指定的数量的分组后，tcpdump就会停止。-e 在输出行打印出数据链路层的头部信息。-i 指定监听的网络接口。-n 不把网络地址转换成名字。-nn 不进行端口名称的转换。-v 输出一个稍微详细的信息，例如在ip包中可以包括ttl和服务类型的信息-tttt 在每一行中输出由date处理的默认格式的时间戳。-S 输出tcp窗口序号的绝对值而不是相对值 (man手册: Print absolute, rather than relative, TCP sequence numbers.) 其中:tcpdump中的 源 / 目标 地址, 源 / 目标 端口, 协议 使用与 / 或 / 非 关键词连接, 关于tcpdump的表达式介绍如下 tcpdump的表达式介绍 表达式是一个正则表达式，tcpdump利用它作为过滤报文的条件，如果一个报文满足表 达式的条件，则这个报文将会被捕获。如果没有给出任何条件，则网络上所有的信息包 将会被截获。在表达式中一般如下几种类型的关键字：第一种是关于类型的关键字，主要包括host，net，port，例如 host 210.27.48.2， 指明 210.27.48.2是一台主机，net 202.0.0.0指明202.0.0.0是一个网络地址，port 23 指明端口号是23。如果没有指定类型，缺省的类型是host。第二种是确定传输方向的关键字，主要包括src，dst，dst or src，dst and src， 这些关键字指明了传输的方向。举例说明，src 210.27.48.2 ，指明ip包中源地址是 210.27.48.2 ， dst net 202.0.0.0 指明目的网络地址是202.0.0.0。如果没有指明 方向关键字，则缺省是src or dst关键字。第三种是协议的关键字，主要包括fddi，ip，arp，rarp，tcp，udp等类型。Fddi指明是在FDDI (分布式光纤数据接口网络)上的特定的网络协议，实际上它是”ether”的别名，fddi和ether 具有类似的源地址和目的地址，所以可以将fddi协议包当作ether的包进行处理和分析。 其他的几个关键字就是指明了监听的包的协议内容。如果没有指定任何协议，则tcpdump 将会 监听所有协议的信息包。除了这三种类型的关键字之外，其他重要的关键字如下：gateway， broadcast，less， greater， 还有三种逻辑运算，取非运算是 ‘not ‘ ‘! ‘， 与运算是’and’，’&&’;或运算是’or’ ，’||’； 这些关键字可以组合起来构成强大的组合条件来满足人们的需要。 tcpdump的输出 将tcpdump输出到文件(输出到文件时，不会同时输出到屏幕)：有两种选择：输出为二进制文件，输出为文本文件。 二进制文件：tcpdump -w 例如：tcpdump -w dump1.bin 文本文件： tcpdump > 例如：tcpdump >dump1.txt 查看tcpdump生成的文件，加上-r参数： tcpdump -r 例如：tcpdump -r dump1.bin 应用实例https://blog.csdn.net/cbbbc/article/details/48897367 例子不错,字小得发指https://arthurchiao.github.io/blog/tcpdump-practice-zh/ Wireshark 下载地址和UserGuidehttps://www.wireshark.org/download.htmlhttps://www.wireshark.org/docs/wsug_html/#ChUseFileMenuSection 另外比较有意思的应用https://blog.csdn.net/lvshaorong/article/details/51382911https://4hou.win/wordpress/?p=14421 Wireshark更改时间显示格式 将显示时间更改为\"年-月-日 时:分:秒.微秒\"---absoulute date ,它称之为绝对时间. 另外还可以选择UTC标准时间 将显示时间更改为相对时间, 时间值是从第1个被捕获的包算起的间隔时间 过滤显示 https://blog.csdn.net/lixiangminghate/article/details/81663628 与在tcpdump中等价的过滤 源 /目标 主机地址和端口的使用同样使用 与 / 或 / 非 运算符以下示例包含 非 运算符的使用---成对小括号 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-09-28 11:59:49 "},"Linux_sftp_and_vsftp_config_chroot.html":{"url":"Linux_sftp_and_vsftp_config_chroot.html","title":"vsftpd和sftp的chroot设置","keywords":"","body":"vsftpd设置chroot https://blog.csdn.net/bluishglc/article/details/42398811 chroot_local_user #是否将所有用户限制在主目录,YES为启用 NO禁用.(该项默认值是NO,即在安装vsftpd后不做配置的话，ftp用户是可以向上切换到要目录之外的) chroot_list_enable #是否启动限制用户的名单 YES为启用 NO禁用(包括注释掉也为禁用) chroot_list_file=/etc/vsftpd/chroot_list #是否限制在主目录下的用户名单，至于是限制名单还是排除名单，这取决于chroot_local_user的值，我们可以这样记忆： chroot_local_user总是一个全局性的设定，其为YES时，全部用户被锁定于主目录，其为NO时，全部用户不被锁定于主目录。那么我们势必需要在全局设定下能做出一些“微调”，即，我们总是需要一种“例外机制\"，所以当chroot_list_enable=YES时，表示我们“需要例外”。而”例外“的含义总是有一个上下文的，即，当”全部用户被锁定于主目录“时（即chroot_local_user=YES），\"例外\"就是：不被锁定的用户是哪些；当\"全部用户不被锁定于主目录\"时（即chroot_local_user=NO），\"例外\"“就是：要被锁定的用户是哪些。这样解释和记忆两者之间的关系就很清晰了！ 此处有坑https://ma.ttias.be/vsftpd-linux-500-oops-vsftpd-refusing-run-writable-root-inside-chroot/问题现象 解决办法 用户可以使用 ftp, 但用户shell 是/sbin/nologin 的需求在 /etc/shells 里添加/sbin/nologin SFTP设置chroot https://www.cnblogs.com/wish123/p/7071317.html 可以细化到每个用户的单独设置 设置该用户不能逃逸出的目录为 /home/sftp则 /home/sftp 这一级目录属主为 root权限mode 最多为 755 --- 该用户如果不能对这一级目录进行查看也无法切换到子目录在这一级建立各子目录, 该用户对这些子目录有完全操作权限 ChrootDirectory 的所有父目录的权限最高只能是755 ，否则会抛出下述错误！ Read from remote host 172.16.xx.xxx: Connection reset by peer Couldn't read packet: Connection reset by peer SFTP Permission denied处理 com.jcraft.jsch.SftpException: Permission denied 问题的原因是，SFTP服务器的SELINUX在阻止 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-09-28 11:58:37 "},"Linux_clock_sync_chrony_and_ntpd_config.html":{"url":"Linux_clock_sync_chrony_and_ntpd_config.html","title":"时钟同步","keywords":"","body":"导航--点击跳转 Chrony 部分ntpd 部分   Chrony部分 Fedora官方guidehttps://docs.fedoraproject.org/en-US/Fedora/18/html/System_Administrators_Guide/sect-Understanding_the_chrony_configuration_commands.html 比较好的文章https://cloud.tencent.com/developer/article/1546322 man手册https://chrony.tuxfamily.org/doc/3.4/chrony.conf.html 其他参考https://tswblog.com/article/linux/chrony/   早期的RHEL 7.x 系列, 以及由此升级而来的最新的几个7.x版本, 可能不会包含chrony的软件包, yum自行安装即可.   配置文件与参数 chrony的默认配置文件/etc/chrony.conf内容如下: [root@localhost ~]# cat /etc/chrony.conf # Use public servers from the pool.ntp.org project. # Please consider joining the pool (http://www.pool.ntp.org/join.html). server 0.centos.pool.ntp.org iburst server 1.centos.pool.ntp.org iburst server 2.centos.pool.ntp.org iburst server 3.centos.pool.ntp.org iburst # Record the rate at which the system clock gains/losses time. driftfile /var/lib/chrony/drift # Allow the system clock to be stepped in the first three updates # if its offset is larger than 1 second. makestep 1.0 3 # Enable kernel synchronization of the real-time clock (RTC). rtcsync # Enable hardware timestamping on all interfaces that support it. #hwtimestamp * # Increase the minimum number of selectable sources required to adjust # the system clock. #minsources 2 # Allow NTP client access from local network. #allow 192.168.0.0/16 # Serve time even if not synchronized to a time source. #local stratum 10 # Specify file containing keys for NTP authentication. #keyfile /etc/chrony.keys # Specify directory for log files. logdir /var/log/chrony # Select which information is logged. #log measurements statistics tracking 与 ntpd.conf 的内容相似度极高 参数含义解释: server hostname [option] server 指令用于指定要同步的 NTP 服务器。 server 0.centos.pool.ntp.org iburst其中的 0.centos.pool.ntp.org 是 NTP 服务器的地址，默认有四组官方的 NTP 服务器。你也可以修改为自定义的时间服务器，例如：ntp1.aliyun.com。 iburst 是参数, 一般用此参数即可。该参数的含义是在头四次 NTP 请求以 2s 或者更短的间隔，而不是以 minpoll x 指定的最小间隔，这样的设置可以让 chronyd 启动时快速进行一次同步。 其他的参数有 minpoll x 默认值是 6，代表 64s。maxpoll x 默认值是 9，代表 512s。 这里的x是2的幂次. 根据man手册里的解释:minpoll 默认值是6 , 即64秒.maxpoll 默认值是10, 即1024秒.这两者的最小值可到 -6, 即1/64秒. 最大值是24, 即6个月. 示例: server ntp1.aliyun.com iburst minpoll 4 maxpoll 9   driftfile file Chrony 会根据实际时间计算修正值，并将补偿参数记录在该指令指定的文件里，默认为 driftfile /var/lib/chrony/drift。 与 ntpd 或者 ntpdate 最大的区别就是，Chrony 的修正是连续的，通过减慢时钟或者加快时钟的方式连续的修正。而 ntpd 或者 ntpdate 搭配 Crontab 的校时工具是直接调整时间，会出现间断，并且相同时间可能会出现两次。因此，请放弃使用 ntpd、ntpdate 来校时。   makestep threshold limit 此指令使 Chrony 根据需要通过加速或减慢时钟来逐渐校正任何时间偏移。例如：makestep 1.0 3，就表示当头三次校时，如果时间相差 1.0s, 则跳跃式校时。   rtcsync 启用内核时间与 RTC 时间同步 (自动写回硬件)。   logdir 该参数用于指定 Chrony 日志文件的路径。   stratumweight 该参数用于设置当 chronyd 从可用源中选择同步源时，每个层应该添加多少距离到同步距离。默认情况下设置为 0，让 chronyd 在选择源时忽略源的层级。 可以参考 ntpd.conf 里的stratum的概念 以上是作为客户端的常用参数   用作server端 至少应包含的是 allow, 以允许来自指定客户端的连接--特定的主机 / 网段 / IPv6地址形式.Optionally specify a host, subnet, or network from which to allow NTP connections to a machine acting as NTP server. The default is not to allow connections.Examples:Use this form to specify a particular host, by its host name, to be allowed access. allow server1.example.com   Use this form to specify a particular network to be allowed access. allow 192.0.2.0/24   Use this form to specify an IPv6 address to be allowed access. allow 2001:db8::/32   检查客户端的同步状况 chronyc tracking 显示时钟的详细信息 [root@localhost ~]# chronyc tracking Reference ID : C1B66F0E (ntp5.flashdance.cx) Stratum : 3 Ref time (UTC) : Mon Dec 28 08:36:52 2020 System time : 0.000000059 seconds slow of NTP time Last offset : -0.017252956 seconds RMS offset : 0.017252956 seconds Frequency : 138.891 ppm slow Residual freq : +1868.784 ppm Skew : 1000000.000 ppm Root delay : 0.312753052 seconds Root dispersion : 2.573378563 seconds Update interval : 0.0 seconds Leap status : Normal Update interval这个参数, 说明最后两次更新的时间间隔是64.1s   chronyc sources -v 显示被chronyd加载的所有NTP源的信息 [root@localhost ~]# chronyc sources -v 210 Number of sources = 4 .-- Source mode '^' = server, '=' = peer, '#' = local clock. / .- Source state '*' = current synced, '+' = combined , '-' = not combined, | / '?' = unreachable, 'x' = time may be in error, '~' = time too variable. || .- xxxx [ yyyy ] +/- zzzz || Reachability register (octal) -. | xxxx = adjusted offset, || Log2(Polling interval) --. | | yyyy = measured offset, || \\ | | zzzz = estimated error. || | | \\ MS Name/IP address Stratum Poll Reach LastRx Last sample =============================================================================== ^* 202.118.1.130 1 6 125 45 -4266us[-7802us] +/- 43ms ^- undefined.hostname.local> 2 6 17 48 -2582us[-6056us] +/- 129ms ^- ntp5.flashdance.cx 2 6 377 47 -17ms[ -20ms] +/- 176ms ^+ tock.ntp.infomaniak.ch 1 6 377 47 +5493us[+2002us] +/- 104ms   其他chrony相关命令 查看 NTP 服务器的在线和离线状态 $ chronyc activity 查看 Chrony 服务的日志 $ journalctl -u chronyd 检查 NTP 访问是否对特定主机可用 $ chronyc accheck 该命令会显示有多少 NTP 源在线/离线 $ chronyc activity 手动添加一台新的 NTP 服务器 $ chronyc add server 在客户端报告已访问到服务器 $ chronyc clients 手动移除 NTP 服务器或对等服务器 $ chronyc delete 手动设置守护进程时间 $ chronyc settime 校准时间服务器，显示系统时间信息 $ chronyc tracking 检查 NTP 访问是否对特定主机可用 $ chronyc accheck 查看时间同步源 $ chronyc sources -v 查看时间同步源状态 $ chronyc sourcestats -v   chrony在超大时间偏差下停止工作的问题 https://serverfault.com/questions/819467/chrony-time-synchronization-on-huge-time-diff chrony一次性修正时间的日志记录 ntpd部分 使用ntpdate命令同步,存在的问题是如果时间偏差过大,一次性修正过猛,会对应用产生不可接受的影响关于此问题更详细的描述http://www.cnblogs.com/liuyou/archive/2012/07/29/2614330.html 对NTP服务端的配置 https://my.oschina.net/myaniu/blog/182959http://blog.163.com/little_yang@126/blog/static/2317559620091019104019991/ 对配置的解析也比较详细http://blog.csdn.net/wzyzzu/article/details/46515129 配置样例 指定日志位置 用 logfile /path/to/xxx.log 进行定义, 日志内容如下 层的概念 这些问题主要涉及到NTP的层（stratum）的概念，顶层是1，值为0时表示层数不明，层的值是累加的，比如NTP授时方向是A-〉B-〉C，假设A的stratum值是3，那么B从A获取到时间，B的stratum置为4，C从B获取到时间，C的值被置为5。一般只有整个NTP系统最顶层的服务器stratum才设为1。NTP同步的方向是从stratum值较小的节点向较大的节点传播，如果某个NTP客户端接收到stratum比自己还要大，那么NTP客户端认为自己的时间比接受到的时间更为精确，不会进行时间的更新。对于大部分NTP软件系统来说，服务启动后，stratum值初始是0，一旦NTP服务获取到了时间，NTP层次就设置为上级服务器stratum+1。对于具备卫星时钟、原子钟的专业NTP设备，一般stratum值初始是1。 NTPD的运行过程 NTPD启动后，stratum值初始是0，此时NTPD接收到NTP请求，回复stratum字段为0的NTP包，客户端接收后，发现stratum字段无效，拒绝更新时间，造成时间更新失败。几分钟后，NTPD从上级服务器获取到了更新，设置了正确的stratum，回复stratum字段为n+1的NTP包，客户端接收后，确认stratum有效，成功进行时间更新。在NTPD上级服务器不可用的情况下，NTPD将本机时钟服务模拟为一个上级NTP服务器，地址使用环回127.127.1.0，服务启动几分钟后，NTPD从127.127.1.0更新了时钟，设置了有效的stratum，客户端接收后，成功进行时间更新。 关于排错 http://www.tuicool.com/articles/Iv2QNf在使用 ntpq -p 查询的过程中，出现如下的 error log: # ntpq -p localhost: timed out, nothing received ***Request timed out 原因很简单，ntpd 需要有 loopback 的参与，而默认是拒绝所有，将 loopback 放行就好了: restrict 127.0.0.1 补充:同样的,ipv6的环回地址同样可能需要添加进配置文件,否则在启用了ipv6的机器上也可能ntpq -p看不到上级服务器的信息,在suse上就是如此 restrict -6 ::1 NTP版本升级 编译安装, 下载地址http://www.ntp.org/downloads.htmlntp的软件包编译安装本身不涉及太多判断要处理, 只是编译参数的选择, 以及原有配置文件的备份工作可能需要涉及 我自己所使用的编译参数 ./configure \\ --prefix=/usr/local/ntp \\ --bindir=/usr/sbin \\ --sysconfdir=/etc \\ --enable-linuxcaps \\ --with-lineeditlibs=readline \\ --docdir=/usr/share/doc/${ntp_version} \\ --with-openssl-incdir=/usr/local/openssl/include \\ --enable-all-clocks \\ --enable-parse-clocks \\ --disable-ipv6 \\ --without-ntpsnmpd \\ --enable-clockctl make -j 4 && make install -j 4 NTP服务的解析得较深入的文章 http://www.happyworld.net.cn/post/6.html以下摘抄文中部分内容,原文后面还有几种时间偏差范围的对比测试 ntpdate就是执行该命令的时候就将客户端的时钟与服务器端的时钟做下同步，不管差异多大，都是一次调整到位。而ntpd服务的方式，又有两种策略，一种是平滑、缓慢的渐进式调整（adjusts the clock in small steps所谓的微调）；一种是步进式调整（跳跃式调整）。两种策略的区别就在于，微调方式在启动NTP服务时加了个“-X”的参数，而默认的是不加“-X”参数。假如使用了-x选项，那么ntpd只做微调，不跳跃调整时间，但是要注意，-x参数的负作用：当时钟差大的时候，同步时间将花费很长的时间。-x也有一个阈值，就是600s，当系统时钟与标准时间差距大于600s时，ntpd会使用较大“步进值”的方式来调整时间，将时钟“步进”调整到正确时间。假如不使用-x选项，那么ntpd在时钟差距小于128ms时，使用微调方式调整时间，当时差大于128ms时，使用“跳跃”式调整。这两种方式都会在本地时钟与远端的NTP服务器时钟相差大于1000s时，ntpd会停止工作。在启动NTP时加了参数“-g”就可以忽略1000S的问题。 以下是man ntpd里关于加参数“-X”的描述：-XNormally, the time is slewed if the offset is less than the step threshold, which is 128 ms by default, and stepped if above the threshold. This option sets the threshold to 600 s, which is well within the accuracy window to set the clock manually. Note: Since the slew rate of typical Unix kernels is limited to 0.5 ms/s, each second of adjustment requires an amortization interval of 2000 s. Thus, an adjustment as much as 600 s will take almost 14 days to complete. This option can be used with the -g and -q options. See the tinker command for other options. Note: The kernel time discipline is disabled with this option. 只有对于跳跃式的校正时间，系统日志才会记录。 同步系统时间同时同步硬件时钟 https://blog.51cto.com/xjsunjie/1895760 在/etc/sysconfig/ntpd文件中，添加 SYNC_HWCLOCK=yes OPTIONS=\"-x -u ntp:ntp -p /var/run/ntpd.pid -g\" Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-19 10:43:59 "},"Linux_firewalld_and_iptables.html":{"url":"Linux_firewalld_and_iptables.html","title":"firewalld和iptables","keywords":"","body":"导航--点击跳转 firewalld 部分 iptables 部分 firewalld部分 iptables部分 1) Linux操作系统中永久性生效，重启后不会复原开启： chkconfig iptables on关闭： chkconfig iptables off 2) 即时生效，重启后复原开启： service iptables start关闭： service iptables stop 比较详细的说明http://www.vpser.net/security/linux-iptables.htmlhttp://www.lampbo.org/linux-xuexi/linux-advance/iptables-options.htmlhttp://blog.51yip.com/linux/1404.html -A 参数默认是添加到INPUT方向的规则链尾部，默认的配置文件通常最后一条是拒绝所有请求，因此，添加在其后的规则实际上无法起作用。使用-I 参数插入规则链顶部。 最简单的开放端口示例iptables -I INPUT -p tcp --dport 22 -j ACCEPT 保存规则service iptables save 添加ip段范围的用法以及直接写入 /etc/sysconfig/iptables 文件中的示例 # Generated by iptables-save v1.4.7 on Wed Oct 26 09:29:01 2016 *filter :INPUT ACCEPT [18:1824] :FORWARD ACCEPT [0:0] :OUTPUT ACCEPT [159:58904] -A INPUT -s 127.0.0.1/32 -j ACCEPT -A INPUT -s 10.191.20.137/32 -j ACCEPT -A INPUT -s 10.191.20.138/32 -j ACCEPT -A INPUT -p tcp -m iprange --src-range 10.191.16.84-10.191.16.91 -m tcp --dport 10073 -j ACCEPT -A INPUT -p tcp -m iprange --src-range 10.191.28.130-10.191.28.146 -m tcp --dport 10073 -j ACCEPT -A INPUT -p tcp -m iprange --src-range 10.191.19.1-10.191.19.3 -m tcp --dport 10073 -j ACCEPT -A INPUT -p tcp -m iprange --src-range 10.191.28.130-10.191.28.132 -m tcp --dport 10073 -j ACCEPT -A INPUT -p tcp -m iprange --src-range 10.191.28.141-10.191.28.142 -m tcp --dport 10073 -j ACCEPT -A INPUT -s 10.191.19.2/32 -p tcp -m tcp --dport 10073 -j ACCEPT -A INPUT -p tcp -m tcp --dport 10073 -j DROP COMMIT # Completed on Wed Oct 26 09:29:01 2016 端口范围的另一种写法红帽iptables文件 /etc/sysconfig/iptables -A RH-Firewall-1-INPUT -m state --state NEW -m tcp -p tcp --dport 700:800 -j ACCEPT 一、 700:800 表示700到800之间的所有端口 二、 :800 表示800及以下所有端口 三、 700: 表示700以及以上所有端口 多地址多端口的写法 iptables的保存 RHEL / CentOS 使用service iptables save即可 SuSE 11 只有iptables-save将输出重定向到文件, iptables-restore 文件名 命令进行恢复 SuSE上配置iptables 按其官方的配置方式,配置文件：/etc/sysconfig/SuSEfirewall2 可填写23:65535形式,冒号为连续端口号 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-08 11:03:29 "},"Linux_disk_management.html":{"url":"Linux_disk_management.html","title":"磁盘管理","keywords":"","body":"导航 目录 文件系统层次结构标准 通过UUID挂载分区 LVM逻辑磁盘卷管理 parted命令 fdisk命令 文件系统层次结构标准 http://zh.wikipedia.org/wiki/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E6%A0%87%E5%87%86 目录 描述 / 第一层次结构 的根、 整个文件系统层次结构的根目录。 /bin/ 需要在单用户模式可用的必要命令（可执行文件）；面向所有用户，例如： cat、 ls、 cp。 /boot/ 引导程序文件，例如： kernel、initrd；时常是一个单独的分区 /dev/ 必要设备, 例如：/dev/null. /etc/ 特定主机，系统范围内的配置文件。关于这个名称目前有争议。在贝尔实验室关于UNIX实现文档的早期版本中，/etc 被称为etcetera， 这是由于过去此目录中存放所有不属于别处的所有东西（然而，FHS限制/etc只能存放静态配置文件，不能包含二进制文件）。 自从早期文档出版以来，目录名称已被以各种方式重新称呼。最近的解释包括反向缩略语如：\"可编辑的文本配置\"（英文 \"Editable Text Configuration\"）或\"扩展工具箱\"（英文 \"Extended Tool Chest\"）。   /etc/opt/ /opt/的配置文件   /etc/X11/ X窗口系统(版本11)的配置文件   /etc/sgml/ SGML的配置文件   /etc/xml/ XML的配置文件 /home/ 用户的家目录，包含保存的文件、个人设置等，一般为单独的分区。 /lib/ /bin/ 和 /sbin/中二进制文件必要的库文件。 /media/ 可移除媒体(如CD-ROM)的挂载点 (在FHS-2.3中出现)。 /mnt/ 临时挂载的文件系统。 /opt/ 可选应用软件 包。 /proc/ 虚拟文件系统，将内核与进程状态归档为文本文件。例如：uptime、 network。在Linux中，对应Procfs格式挂载。 /root/ 超级用户的家目录 /sbin/ 必要的系统二进制文件，例如： init、 ip、 mount。 /srv/ 站点的具体数据，由系统提供。 /tmp/ 临时文件(参见 /var/tmp)，在系统重启时目录中文件不会被保留。 /usr/ 用于存储只读用户数据的第二层次； 包含绝大多数的(多)用户工具和应用程序，注意不是user的缩写，而是\"Unix Software Resource\"的缩写。   /usr/bin/ 非必要可执行文件 (在单用户模式中不需要)；面向所有用户。   /usr/include/ 标准包含文件。   /usr/lib/ /usr/bin/和/usr/sbin/中二进制文件的库。   /usr/sbin/ 非必要的系统二进制文件，例如：大量网络服务的守护进程。   /usr/share/ 体系结构无关（共享）数据。   /usr/src/ 源代码,例如:内核源代码及其头文件。   /usr/X11R6/ X窗口系统 版本 11, Release 6.   /usr/local/ 本地数据的第三层次， 具体到本台主机。通常而言有进一步的子目录， 例如：bin/、lib/、share/. /var/ 变量文件——在正常运行的系统中其内容不断变化的文件，如日志，脱机文件和临时电子邮件文件。有时是一个单独的分区。   /var/cache/ 应用程序缓存数据。这些数据是在本地生成的一个耗时的I/O或计算结果。应用程序必须能够再生或恢复数据。缓存的文件可以被删除而不导致数据丢失。   /var/lib/ 状态信息。 由程序在运行时维护的持久性数据。 例如：数据库、包装的系统元数据等。   /var/lock/ 锁文件，一类跟踪当前使用中资源的文件。   /var/log/ 日志文件，包含大量日志文件，为了防止日志占满根分区，生产环境中一般是单独分区。   /var/mail/ 用户的电子邮箱。   /var/run/ 自最后一次启动以来运行中的系统的信息，例如：当前登录的用户和运行中的守护进程、一些守护进程的pid文件、socket文件。现已经被/run代替。   /var/spool/ 等待处理的任务的脱机文件，例如：打印队列和未读的邮件。   /var/spool/mail/ 用户的邮箱(不鼓励的存储位置)   /var/tmp/ 在系统重启过程中可以保留的临时文件。 /run/ 代替/var/run目录。 partprobe 不重启的情况重读分区 https://www.bookstack.cn/read/linux-command-1.6.0/command-partprobe.md [root@localhost ~]# partprobe 通过UUID挂载分区> https://my.oschina.net/leejun2005/blog/290073UUID 全称是 Universally Unique Identifier，也就是说，每个分区有一个唯一的 UUID 值，这样就不会发生分区识别混乱的问题了。在 fstab 中用 UUID 挂载分区，看起来向这样：UUID=1234-5678 /mnt/usb vfat utf8,umask=0 0 0在 UUID= 后面填入分区相应的 UUID 值，就可以正确挂载分区了。那么，我们如何知道一个分区的 UUID 呢？有 3 种方法：1 通过浏览 /dev/disk/by-uuid/ 下的设备文件信息 # ls -l /dev/disk/by-uuid/ ------ lrwxrwxrwx 1 root root 10 10-13 09:14 0909-090B -> ../../sdb5 lrwxrwxrwx 1 root root 10 10-13 09:13 7c627a81-7a6b-4806-987b-b5a8a0a93645 -> ../../sda4 ..... 2 通过 vol_id 命令 # vol_id /dev/sdb5 ID_FS_USAGE=filesystem ID_FS_TYPE=vfat ID_FS_VERSION=FAT32 ID_FS_UUID=0909-090B ID_FS_UUID_ENC=0909-090B ID_FS_LABEL=SWAP ID_FS_LABEL_ENC=SWAP ID_FS_LABEL_SAFE=SWAP 3 通过 blkid 命令 # blkid /dev/sdb5 /dev/sdb5: LABEL=\"SWAP\" UUID=\"0909-090B\" TYPE=\"vfat\" 通过这三种方法都可以获得分区的 UUID，UUID 依据分区不同，长度和格式都不相同。 比如我最后把 /dev/sdb 挂载在了 /data1 目录下（不放心的话重启或者生成文件测试下，看挂载分区的空间被占用没）： LVM逻辑磁盘卷管理 关于LVM的概念：http://molinux.blog.51cto.com/2536040/518441http://wqmsl.blog.51cto.com/847418/4717843层结构——物理卷（pv），卷组（vg），逻辑卷（lv） 操作http://hi.baidu.com/voostar/item/6aaeca5b779a1b948c12edf2操作流程： 建立LVM类型的分区(如果是裸盘直接创建PV则没有此步) 建立LVM物理卷PV 建立LVM卷组VG 建立LVM逻辑卷LV 建立文件系统 挂载文件系统 fdisk -l 查看已被系统识别的磁盘 fdisk对磁盘进行划分，使用fdisk命令的 t 选项将物理磁盘卷ID修改8e（LVM的物理卷） pv，vg，lv分别对应物理卷，卷组，逻辑卷前三者加上create，extend，remove，display关键字分别对应创建，拓展，移除，查看。pvcreate将该磁盘或分区创建成pv 裸磁盘也可以直接创建,如 pvcreate /dev/sdbvgextend加入已存在的卷组vg中，新增则是vgcreate 卷组名 lvextend有了空闲空间的卷组则可以扩容lvcreate -L 10G -n 卷名 卷组名关于大小写的L , -L指定size ,小写 l 指定的是PE数使用剩余的全部空间的形式为 -l +100%FREE从卷组的剩余空间为某个LV扩容,不需要给出卷组名,命令格式如lvcreate -L 10G -n 卷名在-L 后面给的size,带+号为在原基础上增加多少,不带+号为总大小为多少 带-r参数为在调整大小之后执行resize , 可省去后续的resize2fs那一步 lvdisplay查看完整的卷路径resize2fs最后重新生成大小----设备完整路径,如 /dev/mapper/rootvg 解释得更为详细http://h2olyu.blog.51cto.com/1490267/1181547 xfs文件系统LVM扩容https://my.oschina.net/Jalo/blog/804412 df -hP fdisk -l vgdisplay pvcreate /dev/sdc gextend centos /dev/sdc vgdisplay lvextend -l +5G /dev/centos/var xfs_growps /dev/centos/var df -hP 以上是有新磁盘的时候扩容到已有的逻辑卷上的9个步骤如果逻辑卷还有剩余空间可以使用vgs 查看剩余了多少然后使用1、7、8、9这4个命令 LVM的缩减标准步骤1.umount filesystem2.e2fsck filesystem3.resize2fs filesystem4.lvredurehttp://blog.itpub.net/32980/viewspace-1123851/http://bbs.chinaunix.net/thread-1925323-1-1.html LVM从VG中删除PV及删除未知PV比如： 先创建了PV，加入了VG，再mkfs.ext4去格式化掉这个PV，就出现了以下情况 VG中去除PV unknown device： [root@bogon ~]# vgreduce --removemissing VolGroup Couldn't find device with uuid OBTOlS-4Gol-YOEY-ybJ1-8HSh-dA2E-yNtZWx. Wrote out consistent volume group VolGroup 从VG中去除特定PV： vgreduce VolGroup00 /dev/xvdb1 parted命令 http://www.cnblogs.com/zhangpengme/archive/2011/12/29/2305963.html执行parted进入parted的交互环境，不同的是help打在前面（如help mkpart），获取帮助；与fdisk相同的是，同样应当跟设备文件名，如不加，将会自动寻找首个磁盘设备； 另外，parted里的分区是即时执行，而fdisk是被缓存parted对磁盘置标志位，使用set parted 非交互模式https://blog.51cto.com/qq862228267/2046392parted 使用-s参数, 即script, 可以非交互模式下完成操作 parted 对齐问题遇到提示:Warning: The resulting partition is not properly aligned for best performance.https://blog.hqcodeshop.fi/archives/273-GNU-Parted-Solving-the-dreaded-The-resulting-partition-is-not-properly-aligned-for-best-performance.html 也就是该磁盘第一个分区, 起始点设为0% GPT分区表分区个数不受限 [root@localhost ~]# parted -s /dev/sdb print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdb: 4398GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 2 100GB 200GB 100GB primary 3 200GB 300GB 100GB primary 4 300GB 400GB 100GB primary 5 400GB 500GB 100GB primary 6 500GB 600GB 100GB primary 在MBR分区表上, 逻辑分区是建立在扩展分区之上的 [root@localhost ~]# parted -s /dev/sdb mklabel msdos [root@localhost ~]# parted -s /dev/sdb print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdb: 4398GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags [root@localhost ~]# parted -s /dev/sdb mkpart extend 100G 2000G [root@localhost ~]# parted -s /dev/sdb print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdb: 4398GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 100GB 100GB primary 2 100GB 2000GB 1900GB extended lba [root@localhost ~]# parted -s /dev/sdb mkpart logic 100G 200G [root@localhost ~]# parted -s /dev/sdb print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdb: 4398GB Sector size (logical/physical): 512B/512B Partition Table: msdos Disk Flags: Number Start End Size Type File system Flags 1 1049kB 100GB 100GB primary 2 100GB 2000GB 1900GB extended lba 5 100GB 200GB 100GB logical 而在GPT分区表上, 先划扩展分区, 再在扩展分区之上创建逻辑分区, 这一流程, 是错误的 [root@localhost ~]# parted -s /dev/sdb mkpart extend 100G 100% [root@localhost ~]# parted -s /dev/sdb print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdb: 4398GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 1049kB 100GB 100GB primary 2 100GB 4398GB 4298GB extend [root@localhost ~]# parted -s /dev/sdb mkpart logic 100G 50% Error: You requested a partition from 100GB to 2199GB (sectors 195312500..4294967295). The closest location we can manage is 4398GB to 4398GB (sectors 8589932544..8589932544). GPT分区表依旧可以建立扩展分区和逻辑分区, 但与主分区已不存在任何不同之处 https://www.eassos.cn/jiao-cheng/ying-pan/mbr-gpt-fenqubiao.php [root@localhost ~]# parted -s /dev/sdb print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdb: 4398GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags [root@localhost ~]# parted -s /dev/sdb mkpart primary 0% 100G [root@localhost ~]# parted -s /dev/sdb mkpart extend 100G 200G [root@localhost ~]# parted -s /dev/sdb mkpart logic 100G 200G Error: You requested a partition from 100GB to 200GB (sectors 195312500..390625000). The closest location we can manage is 200GB to 200GB (sectors 390625280..390625280). [root@localhost ~]# parted -s /dev/sdb mkpart logic 200G 300G [root@localhost ~]# parted -s /dev/sdb print Model: VMware, VMware Virtual S (scsi) Disk /dev/sdb: 4398GB Sector size (logical/physical): 512B/512B Partition Table: gpt Disk Flags: Number Start End Size File system Name Flags 1 1049kB 100GB 100GB primary 2 100GB 200GB 100GB extend 3 200GB 300GB 100GB logic fdisk的详解 http://linux008.blog.51cto.com/2837805/548711在fdisk里的操作，在没有使用wq保存更改操作以前，不会生效，但相应的操作指令会被缓存。 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-19 13:31:44 "},"Linux_gcc_upgrade.html":{"url":"Linux_gcc_upgrade.html","title":"gcc的升级操作","keywords":"","body":"出处: https://www.vpser.net/manage/centos-6-upgrade-gcc.html 升级到gcc 7.3： yum -y install centos-release-scl yum -y install devtoolset-7-gcc devtoolset-7-gcc-c++ devtoolset-7-binutils scl enable devtoolset-7 bash 需要注意的是scl命令启用只是临时的，退出shell或重启就会恢复原系统gcc版本。 如果要长期使用gcc 7.3的话： echo \"source /opt/rh/devtoolset-7/enable\" >>/etc/profile 升级到gcc 8.3： yum -y install centos-release-scl yum -y install devtoolset-8-gcc devtoolset-8-gcc-c++ devtoolset-8-binutils scl enable devtoolset-8 bash 需要注意的是scl命令启用只是临时的，退出shell或重启就会恢复原系统gcc版本。 如果要长期使用gcc 8.3的话： echo \"source /opt/rh/devtoolset-8/enable\" >>/etc/profile 升级到gcc 9.3： yum -y install centos-release-scl yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutils scl enable devtoolset-9 bash 需要注意的是scl命令启用只是临时的，退出shell或重启就会恢复原系统gcc版本。 如果要长期使用gcc 9.3的话： echo \"source /opt/rh/devtoolset-9/enable\" >>/etc/profile 再说一下已经停止支持的devtoolset4(gcc 5.2)及之前版本的安装方法 升级到gcc 4.8： wget http://people.centos.org/tru/devtools-2/devtools-2.repo -O /etc/yum.repos.d/devtoolset-2.repo yum -y install devtoolset-2-gcc devtoolset-2-gcc-c++ devtoolset-2-binutils scl enable devtoolset-2 bash 升级到gcc 4.9： wget https://copr.fedoraproject.org/coprs/rhscl/devtoolset-3/repo/epel-6/rhscl-devtoolset-3-epel-6.repo -O /etc/yum.repos.d/devtoolset-3.repo yum -y install devtoolset-3-gcc devtoolset-3-gcc-c++ devtoolset-3-binutils scl enable devtoolset-3 bash 升级到gcc 5.2 wget https://copr.fedoraproject.org/coprs/hhorak/devtoolset-4-rebuild-bootstrap/repo/epel-6/hhorak-devtoolset-4-rebuild-bootstrap-epel-6.repo -O /etc/yum.repos.d/devtoolset-4.repo yum install devtoolset-4-gcc devtoolset-4-gcc-c++ devtoolset-4-binutils -y scl enable devtoolset-4 bash 升级完成后一定要运行：gcc --version 看一下版本号变成升级后的gcc版本才算升级成功。 升级到gcc 6.3 devtoolset-6已经结束支持，请安装devtoolset-7 yum -y install centos-release-scl yum -y install devtoolset-6-gcc devtoolset-6-gcc-c++ devtoolset-6-binutils scl enable devtoolset-6 bash 需要注意的是scl命令启用只是临时的，退出shell或重启就会恢复原系统gcc版本。 如果要长期使用gcc 6.3的话： echo \"source /opt/rh/devtoolset-6/enable\" >>/etc/profile 这样退出shell重新打开就是新版的gcc了 以下其他版本同理，修改devtoolset版本号即可。 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-09-22 16:07:30 "},"Linux_PXE_config.html":{"url":"Linux_PXE_config.html","title":"PXE Server端的配置","keywords":"","body":"需要用到的软件包 yum -y install dhcp tftp-server nfs-utils syslinux vsftpd kickstart的图形配置界面，system-config-kickstart yum -y install system-config-kickstart.noarch PXE网络安装 参考： http://my.oschina.net/alanlqc/blog/147649 重点看这个, 原理和多菜单都给出来了; 多菜单可以配置成有多个可选ISO的环境 http://www.it165.net/os/html/201306/5331.html http://my.oschina.net/emolee/blog/196165 用到4样东西，DHCP，TFTP，kickstart, vsftpd 配置DHCP 是为在安装RHEL的客户机在启动过程中获取IP地址，并由获取指定的启动文件——Linux安装环境。注意这一版本的dhcp配置文件位置应该是/etc/dhcp/dhcpd.conf。 配置TFTP 传送启动环境的文件 配置kickstart 给出自动安装的相应参数。 配置vsftpd 以传送安装ISO的文件 配置DHCP 在/etc/dhcp/dhcpd.conf中添加的内容 default-lease-time 600; # 默认租期600秒 max-lease-time 7200; # 最大租期7200秒 allow booting; allow bootp; authoritative; subnet 192.168.0.0 netmask 255.255.255.0 # 指定子网和掩码 { range 192.168.0.80 192.168.0.90; # 分配IP的地址范围 next-server 192.168.0.3; # 指明tftp服务器地址 filename \"pxelinux.0\"; # 指明PXE客户端访问时候获取的启动环境的文件 } 配置TFTP 只需要将/etc/xinetd.d/tftp中 disable = no yes改为no 修改后的文本内容 service tftp { socket_type= dgram protocol= udp wait= yes user= root server= /usr/sbin/in.tftpd server_args= -s /var/lib/tftpboot disable= no per_source= 11 cps= 100 2 flags= IPv4 } 注意点： 整个流程梳理下来就是 PXE客户端开机启动, 进入网络启动环节 从DHCP服务器获得了IP地址, 以及要获取的启动环境文件(在tftp配置里的filename \"pxelinux.0\") 启动环境文件的菜单项里指明要获取的kickstart文件的位置(即示例中的ks.cfg) kickstart文件指明了安装过程中ISO文件从哪里获取, 可以是ftp, 可以是NAS 开始自动应答安装 在FTP默认目录下/var/ftp/pub/创建目录，挂载ISO镜像到此处，文中是创建/var/ftp/pub/rhel6 然后拷贝了 /var/ftp/pub/rhel6/isolinux/* 到----> /var/lib/tftpboot/ 这一目录下是PXE启动时获取的启动环境的内容。 创建/var/lib/tftpboot/pxelinux.cfg/ 目录， 并拷贝 /var/lib/tftpboot/isolinux.cfg 到----> /var/lib/tftpboot/pxelinux.cfg/default 这就是进入linux安装菜单选项里的设定修改以下两处   安装过程停在storage device warning处 安装中会遇到的情况，即使有clearpart --all initlabel参数亦无效。   解决办法: http://www.andrewzammit.com/blog/install-centos-6-with-anaconda-kickstart-esxi-vmware-tools/ 在kickstart配置文件ks.cfg里另加一行 zerombr yes     DHCP和TFTP以及FTP服务的功能也可以用其他工具代替 DHCP中的启动文件及指定TFTP服务器的设置，也可以在思科交换机等其他网管型交换机内完成。前提只要也能指定TFP和启动文件名   TFTP也可以由Windows上的TFTP32等程序来完成替代，只需要将所需要的文件的复制到相应设置的目录下即可。 同理FTP也是，因此，并非一定要linux来做 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-10-10 10:04:49 "},"category_3_Container.html":{"url":"category_3_Container.html","title":"容器","keywords":"","body":"容器分类文章 容器分类文章的合集 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-09-27 15:20:47 "},"Container_etcd.html":{"url":"Container_etcd.html","title":"kubernetes 之 etcd","keywords":"","body":"etcd集群初始化出现cluster ID mismatch的情况 初始化的情况https://www.cnops.xyz/archives/1658https://www.cnblogs.com/dukuan/p/8671345.html删除etcd数据文件, 在配置文件/etc/etcd/etcd.conf 的 [Member] 段的 ETCD_DATA_DIR 定义的位置,默认值 /var/lib/etcd/default.etcd所有节点都删除一遍 etcd 集群新增节点 https://www.centos.bz/2018/04/etcd%E9%9B%86%E7%BE%A4%E5%A2%9E%E5%8A%A0%E8%8A%82%E7%82%B9/先在集群已有节点上add 新节点,再在新节点上操作 在集群已有节点上add 新节点,无论是否为Leader节点皆可示例: etcdctl member add etcd-node3 http://192.168.10.152:2380 etcd-node3 为 etcd-namehttp://192.168.10.152:2380 为 ETCD_LISTEN_PEER_URLS  然后在新节点上修改etcd.conf 唯一不同的是 ETCD_INITIAL_CLUSTER_STATE=\"existing\"有些文档说的exist, 应是版本迭代关键字已失效.  同样的,遇到cluster ID mismatch , 删除新增节点上的/var/lib/etcd/default.etcd 重启服务尝试 etcd 删除节点 https://github.com/k8sp/sextant/issues/333 etcdctl cluster-health # 查看各节点健康状态 etcdctl member remove 66b087520c48d825 # 从cluster中删除有问题节点 清空问题节点的etcd数据目录, 再添加回有问题节点, 操作步骤与新增节点相同. etcd 集群整体的灾难恢复 https://github.com/etcd-io/etcd/blob/master/Documentation/v2/admin_guide.md#disaster-recovery etcd 配置TLS认证 又一巨坑--配置https认证后出现的, 服务虽然启动,但是systemctl是activting状态,并且有大量报错 error \"tls: first record does not look like a TLS handshake https://blog.crazytaxii.com/posts/trap_in_etcds_https_deploying/解决办法同样是删除etcd的数据 /var/lib/etcd/default.etcd 重启服务尝试   启用TLS认证, etcd的service文件参数需要修改 ExecStart=/bin/bash -c \"GOMAXPROCS=$(nproc) /usr/bin/etcd --name=\\\"${ETCD_NAME}\\\" --data-dir=\\\"${ETCD_DATA_DIR}\\\" --listen-peer-urls=\\\"${ETCD_LISTEN_PEER_URLS}\\\" --listen-client-urls=\\\"${ETCD_LISTEN_CLIENT_URLS}\\\" --advertise-client-urls=\\\"${ETCD_ADVERTISE_CLIENT_URLS}\\\" --initial-advertise-peer-urls=\\\"${ETCD_INITIAL_ADVERTISE_PEER_URLS}\\\" --initial-cluster=\\\"${ETCD_INITIAL_CLUSTER}\\\" --initial-cluster-token=\\\"${ETCD_INITIAL_CLUSTER_TOKEN}\\\" --initial-cluster-state=\\\"${ETCD_INITIAL_CLUSTER_STATEN}\\\" --cert-file=\\\"${ETCD_CERT_FILE}\\\" --key-file=\\\"${ETCD_KEY_FILE}\\\" --peer-cert-file=\\\"${ETCD_PEER_CERT_FILE}\\\" --peer-key-file=\\\"${ETCD_PEER_KEY_FILE}\\\" --trusted-ca-file=\\\"${ETCD_TRUSTED_CA_FILE}\\\" --peer-trusted-ca-file=\\\"${ETCD_PEER_TRUSTED_CA_FILE}\\\"\" 参数值应从配置文件中读取, 而不是直接赋值. 另外注意命令中的双引号需要转义 \\\" 启用后, 检查集群健康状况的命令也发生变化, 需要设置环境变量指明版本是v3, 同时提供pem证书位置 export ETCDCTL_API=3 etcdctl --cacert=/etc/etcd/ssl/ca.pem --cert=/etc/etcd/ssl/etcd.pem --key=/etc/etcd/ssl/etcd-key.pem --endpoints=https://192.168.1.161:2379,https://192.168.1.162:2379,https://192.168.1.163:2379,https://192.168.1.164:2379 endpoint health 关于CA自签名认证 https://github.com/Donyintao/Kubernetes-install/blob/master/%E5%88%9B%E5%BB%BATLS%E8%AF%81%E4%B9%A6%E5%92%8C%E7%A7%98%E9%92%A5.mdhttps://www.cnblogs.com/wjoyxt/p/9946680.htmlhttps://blog.51cto.com/phospherus/2445742https://blog.csdn.net/weixin_42350212/article/details/84930255 第一步, CA自签名中心初始化, 签发自身的证书 第二步, 创建证书, 证书分3种类型: client certificate： 用于服务端认证客户端,例如etcdctl、etcd proxy、fleetctl、docker客户端 server certificate: 服务端使用，客户端以此验证服务端身份,例如docker服务端、kube-apiserver peer certificate: 双向证书，用于etcd集群成员间通信 这里证书的创建需要用到CA的证书, 以及profile, 因此在csr文件可以自定义一个适合的profile方便引用 etcd会用到的是为etcd生成的xxx.pem, xxx-key.pem, 以及CA自己的pem Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-10-10 10:04:49 "},"category_4_Database.html":{"url":"category_4_Database.html","title":"数据库","keywords":"","body":"数据库分类文章 数据库分类文章的合集 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-09-27 15:21:10 "},"Database_MySQL_HA.html":{"url":"Database_MySQL_HA.html","title":"MySQL高可用--主主 / 主从","keywords":"","body":"MySQL主从、主主结构的配置 配置 http://www.cnblogs.com/zhoujie/p/mysql1.htmlhttp://blog.csdn.net/mycwq/article/details/17136001http://blog.csdn.net/testcs_dn/article/details/51423861 注意MySQL 5.7是start 或 stop slave，而不是slave start 或 stop.要使主库的Position列的值不发生改变，将主库进入只读模式. MySQL 5.7需要在MySQL中执行命令 mysql>CHANGE MASTER TO MASTER_HOST='192.168.0.30', MASTER_PORT=3306, MASTER_USER='rep1', MASTER_PASSWORD='123456', MASTER_LOG_FILE='mysql-bin.000009', MASTER_LOG_POS=154; master_host=主服务器IP master_user=在主服务器上创建的备份用户名 master_password=备份用户密码 master_log_file=查询master(主服务器)的状态得到的File列的值 master_log_pos=Position列的值 start slave：启动从服务器复制功能 示例： change master to master_host='120.136.129.89',master_user='root',master_password='xinhong',master_log_file='mysql-bin.000001',master_log_pos=33578; 其中MASTER_LOG_FILE和MASTER_LOG_POS是在主MySQL中执行 show master status; 查看 查看server-id show variables like 'server_id'; 删除主从信息 查看同步状态 show slave status \\G; 进入mysql mysql>stop slave; mysql>reset slave; mysql>change master to master_user='', master_host=' ', master_password=''; 结果报错如下：ERROR 1210 (HY000): Incorrect arguments to MASTER_HOST 解决办法如下： mysql>change master to master_host=' '; 即可成功删除同步用户信息。注意：上面的命令报错的原因，为master_host=' ' 里面必须有内容，即使为空，也应该用空格代替，而不能什么都不写。 主从排错一则 http://storysky.blog.51cto.com/628458/259280/path/to/ mysql-error.log至关重要，需要查看 我所遇到的问题是配置文件里有server-id=2，但启动服务后仍为1，导致查看show slave status \\G有报错： Last_IO_Error: Fatal error: The slave I/O thread stops because master and slave have equal MySQL server ids; these ids must be different for replication to work (or the --replicate-same-server-id option must be used on slave but this does not always make sense; please check the manual before using it). 也是通过 mysql> SET GLOBAL server_id=2; 即可正常 但重启是不保存的，重启以后继续出现问题，发现问题所在： 真正的问题所在找到排除以后，再重启从MySQL所在服务器，slave进程也会跟随启动。 主主结构 原有的文档链接已GG 概念差别不太大，只是由主服务器通告二进制文件给从服务器改成相互通告。配置my.cnf参数有区别。增加的内容： log-bin = mysql-bin expire-logs-days = 100 replicate-do-db = school binlog-ignore-db = mysql binlog-ignore-db = information_schema auto-increment-increment = 2 auto-increment-offset = 1 需说明的：log-bin参数只给出了文件名格式，并未指定位置，实际在mysqld启动参数中指定的--datadir=/data/mysql 下 原作者的备注：二者都只有server-id不同和 auto-increment-offset不同auto-increment-offset是用来设定数据库中自动增长的起点的，回为这两台服务器都设定了一次自动增长值2，所以它们的起点必须得不同，这样才能避免两台服务器数据同步时出现主键冲突replicate-do-db 指定同步的数据库，我们只在两台服务器间同步test数据库另：auto-increment-increment的值应设为整个结构中服务器的总数，本案例用到两台服务器，所以值设为2 相互通告：使用对端的show slave status\\G看到file和position信息来进行通告 mysql> change master to master_host='192.168.0.42',master_user='mysync',master_password='mysync',master_log_file='mysql-bin.000004',master_log_pos=769; 整个思路与主从结构大同小异，不过使用中遇到以下现象。最初作为两台独立的服务器进行配置时， file和position信息完全一样，进行通告，并start slave;后报错： 以为通告反了用户名，各种排错，并无效果。期间，Position发生了变化，可能由stop slave之后引起的。 此时，两台服务器之间的Position不再相同，重新通告，成功。 数据库测试，两台数据库各插入一条数据，相互同步无误。 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-02-08 10:33:16 "},"category_5_Virtualization.html":{"url":"category_5_Virtualization.html","title":"虚拟化","keywords":"","body":"虚拟化分类文章 虚拟化分类文章的合集 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-09-27 10:59:39 "},"Virtualization_vcenter_relates.html":{"url":"Virtualization_vcenter_relates.html","title":"vCenter操作相关","keywords":"","body":"vcenter批量克隆虚拟机 首次运行powershell, 需要执行 Set-ExecutionPolicy RemoteSigned 以配置powercli可以执行远程脚本, 否则启动时会错误提示   需要用到PowerCLI, 下载地址: https://my.vmware.com/web/vmware/downloads/details?downloadGroup=PCLI650R1&productId=614 普通注册帐号即可下载, 无需付费用户权限 安装后, 有两个快捷方式 需要双击运行, 后续操作要在此窗口环境下执行, 否则会缺少必要的vmware模块   PowerCLI 是在 Windows Powershell上开发的, 想用python直接操控PowerCLI似乎无法绕过 只有寻找第3方lib是否有实现 https://www.reddit.com/r/learnpython/comments/cyma26/i_prefer_python_over_powershell_but_can_i_use_it/   在此环境下执行ps1脚本文件的示例 powershell -File \"D:\\临时存储\\vCenter批量克隆\\批量克隆 - 修改.ps1\" -FileName \"D:\\临时存储\\vCenter批量克隆\\info.csv\" 第1个 -File    参数是powershell 传参你的ps1脚本文件的位置 第2个 -FileName  参数是ps1脚本内部要求的传参   PowerCLI 有哪些命令 全部的命令在VMware-PowerCLI-6.5.0-上有592个 常用的有以下: get-vicommand 显示所有命令列表 Connect-VIServer 连接虚拟化平台 get-vmhost 显示ESXi主机列表 get-cluster 显示群集列表 get-datastore 显示存储列表 get-resourcepool 显示资源池 get-vm 显示虚拟机列表 get-virtualswitch 显示虚拟交换机列表 start-vm\\stop -vm 启动或关闭虚拟机 new -vm 创建虚拟机 get-template 显示模板列表 get-oscustomizationspec 显示自定义规范列表 get-vapp 显示vapp 应用列表 get-folder 显示文件夹列表 创建虚拟机 https://developer.aliyun.com/article/530985 PowerCLI 创建虚拟机命令New-VM, 用到的最基础的信息: 虚拟机名称 -- 在阿里这篇文档里变量定义为: name 模板名称 -- 在阿里这篇文档里变量定义为: template esxi主机，也就是在vcenter清单里显示的名称 -- 在阿里这篇文档里变量定义为: host 数据存储名称 -- 在阿里这篇文档里变量定义为: datastore 只提供以上4个信息即可完成一个虚拟机的创建 更丰富的参数选择以完成自定义的需求, 通过 Get-Help New-VM 查看内置帮助 在New-VM命令其中也有 NetworkName和Portgroup 两个参数可选   自动配置IP和计算机名称 自动配置IP和计算机名称的实现, 涉及到几个命令配合 虚拟机规范文件:New-OSCustomizationSpec 和 Set-OSCustomizationSpec前者创建新的, 后者设置已有的虚拟机规范文件用来提供虚拟机的IP和计算机名称信息 创建虚拟机和设置虚拟机属性:New-VM 和 Set-VMCPU数量, 内存大小, 备注等规则 获取当前新建出来的虚拟机的指向Get-VM -Name 虚拟机名称 获取指定虚拟机的网卡指向 结合上一条就是 ```Get-VM -Name 虚拟机名称 | Get-NetworkAdapter 设置虚拟机网卡属性Set-NetworkAdapter用于指定虚拟机使用vCenter上的哪个虚拟端口组(或分布式交换机, 参数不同) 完整的命令示例: # 创建虚拟机规范文件 New-OSCustomizationSpec -Name 虚拟机规范文件名称 -OSType 操作系统类型(Windows / Linux) -Workgroup 工作组名称 -FullName 全名 -OrgName 组织名称 # 修改虚拟机规范文件, -ChangeSid是windows类型特有的参数 Set-OSCustomizationSpec -NamingScheme Fixed -NamingPrefix 主机名 -ChangeSid:$true # 创建虚拟机 New-VM -Name 虚拟机名称 -VMHost Exsi主机名称 -Template 虚拟机模板名称 -Datastore 数据存储名称 -OSCustomizationspec 虚拟机规范名称 或 New-VM -Name 虚拟机名称 -ResourcePool 集群名称 -Template 虚拟机模板名称 -Datastore 数据存储名称 -OSCustomizationspec 虚拟机规范名称 # 设置虚拟机属性, 指向某个虚拟机的指针 在powershell中可以用变量存储, 如: $vm = Get-VM -Name 虚拟机名称 Set-VM -VM 指向某个虚拟机的指针 -NumCpu CPU核心数量 -MemoryGB 内存大小(GB) -Notes 备注信息 -Confirm:$false # 获取指定的虚拟端口组, 虚拟机所在的宿主机名称用\"指向某个虚拟机的指针\".VMHost 可以获得 Get-VirtualPortGroup -Name 虚拟端口组名称 -VMHost 虚拟机所在的宿主机名称 设置虚拟机网卡属性--指针类都用Get-xxx的方式获取, 再用变量存储引用 Set-NetworkAdapter -NetworkAdapter 指向虚拟机网卡指针 -Portgroup 指向虚拟端口组的指针 -Confirm:$false Set-NetworkAdapter -NetworkAdapter 指向虚拟机网卡指针 -Type E1000 -StartConnected:$true -Confirm:$false # 移除创建的自定义虚拟机规范 Remove-OSCustomizationSpec $osspec -Confirm:$false # 虚拟机开机 Start-VM -VM 指向虚拟机网卡指针 -Confirm:$false Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-10-10 10:04:49 "},"Virtualization_vmware_workstation_summary.html":{"url":"Virtualization_vmware_workstation_summary.html","title":"VMware Workstation汇总","keywords":"","body":"VMware workstation虚拟机空间回收 https://www.howtoforge.com/how-to-shrink-vmware-virtual-disk-files-vmdk 解决的问题:vmdk文件增长得很大, 但在guestOS中查看, 并未实际占有相应多的空间 在Windows宿主机上的操作方法 先对系统垃圾文件进行清理Before we try to shrink the virtual disk files, we should try to remove any unneeded files from the virtual machine to free space.For example, on Debian-based VMs, you can run apt-get clean to clear out the local repository of retrieved package files. 用/dev/zero填0，将虚拟机的磁盘空间全部占满，然后删除 Next, run cat /dev/zero > zero.fill;sync;sleep 1;sync;rm -f zero.fill to fill the unused space with zeros. 最后关闭虚拟机，再在宿主机上用vmware-vdiskmanager.exe命令行工具来收缩Then power down the VM and open the command window on the Windows host: VMware workstation安装路径\\vmware-vdiskmanager.exe -k 虚拟机文件路径\\xxxx.vmdk guestOS是Windows的操作方法 https://www.zhihu.com/question/41707455 windows操作系统的虚拟机 ,用到vmware tools的命令 \"C:\\Program Files\\VMware\\VMware Tools\\VMwareToolboxCmd.exe\" disk shrink c:\\ guestOS是Linux的操作方法 中途可能ssh会中断 vmware-toolbox-cmd disk shrink / VMware workstation虚拟机性能设置 workstation的网卡改为vmxnet3 workstation版本在界面上无法选择网卡类型, 但通过修改.vmx虚拟机配置文件可以替换网卡类型从e1000变为vmxnet3, 以最大化性能 操作步骤, 正则表达式的写法: ethernet[0-9]+.virtualDev = \"e1000\" 替换为 ethernet[0-9]+.virtualDev = \"vmxnet3\" 禁用vmem 虚拟机的配置中 Options 中，Advanced项，启用\"Disable memory page trimming\"，也就是禁止内存剪裁。 虚拟机的配置文件 即 .vmx 文件中，加入 mainMem.useNamedFile = \"FALSE\" http://jyhshin1.blogspot.com/2013/04/vmware-on-windows-7.html 開啟 Disable memory page trimming VM(選單列) → Settings... → 出現 Virtual Machine Settings 對話框 → Options(分頁) → Advanced → 打勾 Disable memory page trimming 等同於修改虛擬機的 .vmx 文件，修改 MemTrimRate = \"0\"。 在此功能啟用時，VMware 會將一些虛擬機未使用的記憶體交給主機，而將虛擬機記憶體保存在硬碟交換文件中。但是這樣做，雖然可以讓主機獲得更多記憶體，同時卻導致硬體性能的下降。如果當 VM Suspend 時，卻發現主機整個卡住，硬碟瘋狂的運轉，持續十分鐘以上，把此功能打勾試試。 開啟 Fit all virtual machine memory into reserved host ram Edit(選單列) → Preferences → 出現 Preferences 對話框 → Memory → Advanced → 選取 Fit all virtual machine memory into reserved host ram 等同於修改 C:/ProgramData/VMware/VMware Workstation/config.ini 文件，修改 prefvmx.minVmMemPct = \"100\"。 如果這個參數是 100 的話，當虛擬機啟動時，VMware 會將該虛擬機的全部記憶體都使用實體記憶體，而不 swap 到檔案系統上；如果這個參數是 50 的話，VMware會將該虛擬機的部份記憶體 swap 到檔案系統上，部份使用實體記憶體。要高效能的話，就設為 100 吧。 開啟 prefvmx.useRecommendedLockedMemSize 修改 C:/ProgramData/VMware/VMware Workstation/config.ini 文件，修改prefvmx.useRecommendedLockedMemSize = \"TRUE\"。 不詳 取消 mainMem.useNamedFile 修改虛擬機的 .vmx 文件，加入 mainMem.useNamedFile = \"FALSE\"。 沒此參數前虛擬機執行時會在本機產生 .vmem 的文件。虛擬機上的記憶體讀寫等於在本機 .vmem 文件讀寫，也就造成虛擬機執行時，硬碟常常運轉不停。但有得必有失，加上這個參數後 Suspend 虛擬機速度就會慢很多，突然斷電就更難保證數據的完整性。 當虛擬機啟動時，VMware 會把部份的虛擬機記憶體存在檔案系統上，以檔案形式存在，這是因為 VMware 使用了 mmap(記憶體映射)的方式來管理虛擬機記憶體。藉由修改 mainMem.useNamedFile，VMware 會將這個檔案由 VM 所在的目錄，改放到主機暫存目錄下，這個異動可能對效能有小小地幫助，特別是暫存目錄是 ramdisk 時，但要注意有可能發生空間不足的問題。 取消 sched.mem.pshare.enable 修改虛擬機的 .vmx 文件，加入 sched.mem.pshare.enable = \"FALSE\"。 停用 memory sharing 後，VM 將不會分享通用記憶體block，VM 也將停止比對記憶體block。強制關閉虛擬機的虛擬記憶體管理分享裝置，需要較高的主系統資源，但提供比較快的虛擬環境。 取消 MemAllowAutoScaleDown 修改虛擬機的 .vmx 文件，加入 MemAllowAutoScaleDown = \"FALSE\"。 這個參數設定成 \"TRUE\" 時，如果虛擬機設定需要 2GB 的記憶體，但實際上主機卻提供給虛擬機的記憶體不到 2GB，虛擬機在啟動時會自動調整縮小記憶體到足夠啟動的範圍。 Windows XP 的 config.ini 放在 C:\\Documents and Settings\\All Users\\Application Data\\VMware\\VMware Workstationg。 关于CPU设置 https://jingyan.baidu.com/article/ed2a5d1f1f96f309f6be17e1.html 这两篇文章都提到了关键性问题，不过关于核心数设置问题，针对CPU核心数逐渐增多的情况，还不足够 以VMware Workstation演示，在VMware vSphere中都有对应选项可找 处理器i5-3570k，已知是双核四线程的处理器，在Workstation设置处理器数量 2x2和1x4皆是正常的，但4x1出现了警告，2x4则告诉你肯定无法运行 2x2和1x4两种设置，经过Cinebench 11.5 64位测试确认，计算能力一致，同样都使4个逻辑处理器满载 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-02-04 19:49:05 "},"category_9_Others.html":{"url":"category_9_Others.html","title":"其他 / 杂项","keywords":"","body":"其他/杂项 分类文章 其他/杂项 分类文章的合集 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-12-24 12:18:00 "},"Others_remote_wake_up_computer.html":{"url":"Others_remote_wake_up_computer.html","title":"远程唤醒计算机","keywords":"","body":"分为对局域网内计算机进行唤醒和通过互联网唤醒计算机通过互联网唤醒计算机, 实际上就是多一步在互联网出口设备上要做端口映射,以及交换机/路由器上可能会需要进行IP与MAC的绑定问题. 分别需要对BIOS，操作系统，以及路由器进行设置。 微星BIOS设置（近几年各大厂商都普及了图形化界面，以微星Z77A-G41为例），不同厂商界面不同，但基本大同小异。关于BIOS和操作系统的设定，youtube的这哥们给出了答案https://www.youtube.com/watch?v=2CGFvLgye3gBIOS方面，只要有wake on PCI-E都是可以的，按早年间的一些文章介绍，还以为一定要wake on lan实际上只需要wake on PCI-E及禁用EuP 2013，如下图 接下来对操作系统进行设定在设备管理器中找到接路由器的物理网卡，先设置电源管理 接下来设置“高级”选项卡，有四项需要确认“魔术封包唤醒”   ====>  需确认处于打开状态“关机 网络唤醒”  ====>  需确认处于打开状态 “环保节能”       ====>  需确认处于关闭状态“节能乙太网路”   ====>  需确认处于关闭状态youtube哥们用的英文操作系统 对操作系统的设定是为了避免关闭Windows时，彻底关闭了网卡，导致无法接受唤醒信号。 最后对路由器进行设定——此时短时间已能进行唤醒，几分钟后会失效原因这两个帖子说到了http://www.gebi1.com/forum.php?mod=viewthread&action=printable&tid=240599http://blog.ashchan.com/archive/2009/08/13/wake-on-lan-over-internet/假如是交换机（比如需要唤醒机房局域网内的某台服务器），在不断电的情况下，此时已可以完成，因为网卡MAC的地址还在。家用路由器，非绑定的MAC-IP地址由于MAC地址时效问题，会进行清理，所以关机后几分钟就无法唤醒了。因此在路由器做一个MAC与IP的绑定，为的是始终保留此MAC的IP，便于路由器接受到唤醒信号知道该传给哪个端口。另外路由器上需建立端口转发（映射关系），唤醒信号（魔术封包）使用UDP的9端口（也有些用7，取决于软件） ，家用路由器也许不分TCP和UDP。 最后，智能手机上寻找wol 或 wake on lan 关键字的软件来安装，大同小异，主要是协议。再一个，动态的公网IP，就借助一下动态域名解析软件来解决了，在不断线重拨的情况下，IP不会发生变化，绝大多数时候都能满足需求了。如果动态解析确实无法满足，向日葵的开机棒几年前也搞起来了。 PS：经过反复测试， 绑定MAC地址可以解决路由器的MAC地址失效问题，以实现唤醒。但前提务必是由操作系统关闭计算机，如电源键关机等会导致网卡处于休眠状态（即使看见指示灯闪烁），也会无法唤醒计算机。 Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2020-12-24 13:19:42 "},"Others_windows_ipsec.html":{"url":"Others_windows_ipsec.html","title":"Windows IPSec实现防火墙功能","keywords":"","body":"图形化的操作 https://blog.51cto.com/yttitan/1571117 命令行操作 rem 创建策略名称 netsh ipsec static add policy name=\"限制3389访问来源\" rem 创建动作名称,指定动作 netsh ipsec static add filteraction name=\"阻止\" action=block netsh ipsec static add filteraction name=\"允许\" action=permit rem 创建IP筛选列表 netsh ipsec static add filterlist name=\"所有IP\" netsh ipsec static add filterlist name=\"白名单IP\" rem 添加IP源地址,目的地址,目的端口,协议到IP筛选列表 netsh ipsec static add filter filterlist=\"所有IP\" srcaddr=any dstaddr=me dstport=3389 description=\"所有IP的3389端口访问控制\" protocol=TCP mirrored=yes netsh ipsec static add filter filterlist=\"白名单IP\" srcaddr=192.168.10.2 dstaddr=me dstport=3389 description=\"白名单IP允许3389端口访问\" protocol=TCP mirrored=yes rem 定义IP筛选列表与动作的对应关联 netsh ipsec static add rule name=\"所有IP的3389端口访问控制\" policy=\"限制3389访问来源\" filterlist=\"所有IP\" filteraction=\"阻止\" netsh ipsec static add rule name=\"白名单IP允许3389端口访问\" policy=\"限制3389访问来源\" filterlist=\"白名单IP\" filteraction=\"允许\" rem 激活该策略 netsh ipsec static set policy name=\"限制3389访问来源\" assign=y rem 确保IPSec服务是启动状态与开机自启动 sc start PolicyAgent sc config PolicyAgent start= auto Copyright & copy tanhuang1985@gmail.com all right reserved，powered by Gitbook该文章修订时间： 2021-01-08 10:17:21 "}}